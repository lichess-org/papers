@inproceedings{adnan:2024:unleashing-artificial-cognition-integrating-multiple-ai-systems,
  title         = {Unleashing Artificial Cognition: Integrating Multiple {AI} Systems},
  author        = {Muntasir Adnan and Buddhi Gamage and Zhiwei Xu and Damith Chandana Herath and Carlos C. N. Kuhn},
  year          = {2024},
  booktitle     = {Australasian Conference on Information Systems, {ACIS} 2024, Canberra, Australia, December 4-6, 2024},
  url           = {https://aisel.aisnet.org/acis2024/31},
  github        = {https://github.com/TheOpenSI/CoSMIC},
  huggingface   = {https://huggingface.co/OpenSI/cognitive\_AI\_chess},
  keywords      = {AI cognition, Chess, large language models, query analysis, retrievable answer generation},
  abstract      = {In this study, we present an innovative fusion of language models and query analysis techniques to unlock cognition in artificial intelligence. The introduced open-source AI system seamlessly integrates a Chess engine with a language model, enabling it to predict moves and provide strategic explanations. Leveraging a vector database to achieve retrievable answer generation, our AI system elucidates its decision-making process, bridging the gap between machine's computational cognition and human-like understanding. Our choice of Chess as the demonstration environment underscores the versatility of our approach. Beyond Chess, our system holds promise for diverse applications, from medical diagnostics to financial forecasting. Our AI system is available at https://github.com/TheOpenSI/CoSMIC},
}

@thesis{adolfsson:2025:self-trained-engine-chess-variant,
  title         = {A self-trained engine for a chess variant},
  author        = {Adolfsson, Hannes and Lewis, David and Rahmn, Anton and Rajam{\"a}e, Sigge and Rungardt, Edvin and Tafani, Marco},
  year          = {2025},
  url           = {http://hdl.handle.net/20.500.12380/310683},
  abstract      = {Chess has long been a benchmark for artificial intelligence (AI) research due to its complexity and well-defined rules. Recent advances, such as AlphaZero, introduced self-learning AI through reinforcement learning and self-play, achieving superhuman performance without prior strategic knowledge, relying solely on the rules of the game. AlphaZero defeated the world-champion chess engine Stockfish after only four hours of training, leveraging large-scale computational resources to rapidly learn and refine its strategies. This thesis presents the development of a chess engine for the chess variant Atomic Chess. The engine was developed in C++ and trained through self-play and reinforcement learning, taking inspiration from AlphaZero's approach. This project explores the extent to which a chess engine with this approach is feasible for the average enthusiast. Cost-effective cloud-based virtual machine instances with powerful hardware were rented to manage training workloads. Given limited computational resources, we opted for a data-centric approach, focusing on refining the training pipeline to maximize the training data that could be produced, rather than hyperparameter tuning and experimenting with neural network architectures. The final engine was trained on approximately 450,000 self-play games in roughly 150 hours. The final engine was deployed on the chess platform Lichess and achieved an ELOrating of 1,729, which corresponded to the top 10th percentile of Atomic Chess players on Lichess. These results demonstrate that it is possible to achieve a competitive Atomic Chess engine within a budget of 3,000 SEK for cloud computation. This shows that strong self-play reinforcement learning agents for niche games can be developed without requiring large-scale computing infrastructure. These results highlight the viability of accessible, low-budget AI research for underexplored game variants.},
  supervisor    = {Abel, Andreas},
  type          = {Bachelor's thesis},
}

@misc{aldea:2024:advancing-chess-engine-design-elo-integrated-evaluation-eie,
  title         = {Advancing Chess Engine Design with Elo-Integrated Evaluation (EIE)},
  author        = {Aldea, Paul-Andrei and Bangarbale, Pranav and Li, Jerry},
  year          = {2024},
  url           = {https://paulaldea.com/project_pictures/chess_elo_file.pdf},
  note          = {Student project paper, CSE 592, University of Michigan},
  github        = {https://github.com/paulxro/cse592\_chess},
  keywords      = {Python; Multi-threaded; Research; Chess},
}

@inproceedings{ambrona:2022:practical-algorithm-chess-unwinnability,
  title         = {A Practical Algorithm for Chess Unwinnability},
  author        = {Miguel Ambrona},
  year          = {2022},
  booktitle     = {11th International Conference on Fun with Algorithms, {FUN} 2022, May 30 to June 3, 2022, Island of Favignana, Sicily, Italy},
  publisher     = {Schloss Dagstuhl - Leibniz-Zentrum f{\"{u}}r Informatik},
  series        = {LIPIcs},
  volume        = {226},
  pages         = {2:1--2:20},
  doi           = {10.4230/LIPICS.FUN.2022.2},
  url           = {https://doi.org/10.4230/LIPIcs.FUN.2022.2},
  editor        = {Pierre Fraigniaud and Yushi Uno},
}

@misc{arora:2022:deep-learning-computer-chess,
  title         = {Deep learning for computer chess (part 1)},
  author        = {Manav Arora},
  year          = {2022},
  publisher     = {Nanyang Technological University},
  url           = {https://dr.ntu.edu.sg/handle/10356/157572?mode=full},
  note          = {Final Year Project (FYP)},
  abstract      = {This report encompasses the implementation of two state-of-the-art machine learning algorithms for evaluating chess positions. The first algorithm makes use of artificial neural networks and manual feature representation thus closely following the implementation and architecture of Matthew Lai's Giraffe.  Giraffe learns to play chess largely by self-play and derives its own rules based on the data [1]. Giraffe was implemented as a 7 class classification problem on a dataset of over 10,000 grandmaster level games. Four different implementations of Giraffe were explored covering two different architectures and the effects of regularization on the model performance. The second algorithm implemented goes through an unsupervised learning phase to perform feature extraction followed by a supervised learning phase thus replicating David Eli's DeepChess. DeepChess evaluates chess positions using a deep neural network without any a priori knowledge regarding the rules of chess. DeepChess is implemented as a siamese network of two disjoint deep belief networks connected to each other by fully connected layers [2]. This architecture was implemented as a binary classification problem on the same dataset as Giraffe and also on a larger dataset of LiChess games. Different implementations of DeepChess covering different training methodologies and parameter sets were executed.},
}

@article{baek:2024:wasm-r3-webassembly-benchmarks,
  title         = {Wasm-R3: Record-Reduce-Replay for Realistic and Standalone WebAssembly Benchmarks},
  author        = {Baek, Doehyun and Getz, Jakob and Sim, Yusung and Lehmann, Daniel and Titzer, Ben L. and Ryu, Sukyoung and Pradel, Michael},
  year          = {2024},
  month         = oct,
  journal       = {Proc. ACM Program. Lang.},
  publisher     = {Association for Computing Machinery},
  address       = {New York, NY, USA},
  volume        = {8},
  number        = {OOPSLA2},
  doi           = {10.1145/3689787},
  url           = {https://doi.org/10.1145/3689787},
  issue_date    = {October 2024},
  abstract      = {WebAssembly (Wasm for short) brings a new, powerful capability to the web as well as Edge, IoT, and embedded systems. Wasm is a portable, compact binary code format with high performance and robust sandboxing properties. As Wasm applications grow in size and importance, the complex performance characteristics of diverse Wasm engines demand robust, representative benchmarks for proper tuning. Stopgap benchmark suites, such as PolyBenchC and libsodium, continue to be used in the literature, though they are known to be unrepresentative. Porting of more complex suites remains difficult because Wasm lacks many system APIs and extracting real-world Wasm benchmarks from the web is difficult due to complex host interactions. To address this challenge, we introduce Wasm-R3, the first record and replay technique for Wasm. Wasm-R3 transparently injects instrumentation into Wasm modules to record an execution trace from inside the module, then reduces the execution trace via several optimizations, and finally produces a replay module that is executable standalone without any host environment-on any engine. The benchmarks created by our approach are (i) realistic, because the approach records real-world web applications, (ii) faithful to the original execution, because the replay benchmark includes the unmodified original code, only adding emulation of host interactions, and (iii) standalone, because the replay benchmarks run on any engine. Applying Wasm-R3 to web-based Wasm applications in the wild demonstrates the correctness of our approach as well as the effectiveness of our optimizations, which reduce the recorded traces by 99.53\% and the size of the replay benchmark by 9.98\%. We release the resulting benchmark suite of 27 applications, called Wasm-R3-Bench, to the community, to inspire a new generation of realistic and standalone Wasm benchmarks.},
  articleno     = {347},
  numpages      = {27},
  keywords      = {Benchmarking, WebAssembly, record and replay},
}

@article{banerjee:2024:skill-vs-chance-quantification-popular-card-board-games,
  title         = {Skill vs. Chance Quantification for Popular Card {\&} Board Games},
  author        = {Tathagata Banerjee and Anushka De and Subhamoy Maitra and Diganta Mukherjee},
  year          = {2024},
  journal       = {CoRR},
  volume        = {abs/2410.14363},
  doi           = {10.48550/ARXIV.2410.14363},
  url           = {https://doi.org/10.48550/arXiv.2410.14363},
  eprinttype    = {arXiv},
  abstract      = {This paper presents a data-driven statistical framework to quantify the role of skill in games, addressing the long-standing question of whether success in a game is predominantly driven by skill or chance. We analyze player level data from four popular games Chess, Rummy, Ludo, and Teen Patti, using empirical win statistics across varying levels of experience. By modeling win rate as a function of experience through a regression framework and employing empirical bootstrap resampling, we estimate the degree to which outcomes improve with repeated play. To summarize these dynamics, we propose a flexible skill score that emphasizes learning over initial performance, aligning with practical and regulatory interpretations of skill. Our results reveal a clear ranking, with Chess showing the highest skill component and Teen Patti the lowest, while Rummy and Ludo fall in between. The proposed framework is transparent, reproducible, and adaptable to other game formats and outcome metrics, offering potential applications in legal classification, game design, and player performance analysis.},
  keywords      = {Chance, Chess, Ludo, Rummy, Skill, Statistical Analysis, Teen Patti},
  eprint        = {2410.14363},
}

@inproceedings{barrish:2023:making-superhuman-ai-more-human,
  title         = {Making Superhuman {AI} More Human in Chess},
  author        = {Daniel Barrish and Steve Kroon and Brink van der Merwe},
  year          = {2023},
  booktitle     = {Advances in Computer Games - 18th International Conference, {ACG} 2023, Virtual Event, November 28-30, 2023, Revised Selected Papers},
  publisher     = {Springer},
  series        = {Lecture Notes in Computer Science},
  volume        = {14528},
  pages         = {3--14},
  doi           = {10.1007/978-3-031-54968-7\_1},
  url           = {https://doi.org/10.1007/978-3-031-54968-7\_1},
  editor        = {Michael Hartisch and Chu{-}Hsuan Hsueh and Jonathan Schaeffer},
  abstract      = {Computer chess research has traditionally focused on creating the strongest possible chess engine. Recently, however, attempts have been made to create engines that mimic the playing strength and style of human players. Our research proposes enhancements of models developed in this vein that more accurately imitate master-level players, as well as improve the prediction accuracy of existing models on weaker players. Our proposed enhancements are simple to apply by post-processing the output of existing chess engines. The performance of our enhancements was evaluated and compared using two metrics, prediction accuracy and average centipawn loss. We found that using an ensemble model over search depths maximised prediction accuracy, while an evaluation window filtering approach was preferable with respect to average centipawn loss.},
  keywords      = {Artificial intelligence, Chess, Action prediction},
}

@article{bart:2023:can-artificial-intelligence-identify-creativity,
  title         = {Can artificial intelligence identify creativity?: An empirical study},
  author        = {William Bart},
  year          = {2023},
  journal       = {Journal of Creativity},
  volume        = {33},
  number        = {2},
  pages         = {100057},
  doi           = {https://doi.org/10.1016/j.yjoc.2023.100057},
  issn          = {2713-3745},
  url           = {https://www.sciencedirect.com/science/article/pii/S271337452300016X},
  keywords      = {Chess, Creative move, Creativity, Stockfish 15, Artificial intelligence},
  abstract      = {This article reports an investigation of the extent to which a chess program with an artificial intelligence component (i.e., Stockfish with NNUE) can identify 10 chess moves that are recognized as outstanding chess moves. Stockfish with NNUE was able to identify seven of the ten moves. Although Stockfish with NNUE is a very powerful chess program, it has some limitations in identifying creative chess moves. There is a discussion of those limitations.},
}

@thesis{beliaev:2024:robust-cooperative-learning-algorithms,
  title         = {Towards Robust and Cooperative Learning Algorithms},
  author        = {Beliaev, Mark},
  year          = {2024},
  note          = {https://escholarship.org/uc/item/6mc2d7q3},
  school        = {UC Santa Barbara},
  abstract      = {
    Recent progress in machine learning has been fueled by increasing scale, enabling breakthroughs in domains such as image generation, natural language understanding, and decision-making. While tremendous improvements have been realized for low-risk applications like chat completion and recommendation, there are fundamental challenges that need to be addressed for high-risk applications like robotics and security. Specifically, this thesis is motivated by the following issues: (1) Collecting large datasets often relies on crowdsourcing, which inevitably introduces heterogeneous and potentially suboptimal data. (2) Applications that require coordination between multiple agents are often coupled with risk, making it challenging to use decentralized learning algorithms. (3) While neural networks have demonstrated tremendous predictive capabilities, they are inherently fragile to adversarial attacks. In this thesis, we present algorithms for combatting these challenges within the domains of Reinforcement Learning and Adversarial Machine Learning.

    The first contribution introduces two algorithms for imitation learning in suboptimal settings, demonstrating that by modeling the suboptimalities present, we can improve the learning framework. The second contribution proposes a mechanism to encourage cooperation in multi-agent reinforcement learning, demonstrating that by allowing agents to gift part of their reward, we can promote prosocial behavior in a decentralized fashion. The third contribution develops a robust classification algorithm designed for sparse attacks, demonstrating that by extending our theoretical insights from idealized settings, we can combat adversarial attacks in neural network classifiers. We test our proposed algorithms across applications in image-classification, game-playing, and robotics. Together, these contributions aim to advance the deployment of machine learning in real-world scenarios by considering practical problem settings, presenting novel theoretical and algorithmic insights, and validating these findings empirically.
  },
  type          = {Doctoral Thesis},
}

@inproceedings{bertrand:2023:limitations-elo-real-world-games-transitive-not-additive,
  title         = {On the Limitations of the Elo, Real-World Games are Transitive, not Additive},
  author        = {Quentin Bertrand and Wojciech Marian Czarnecki and Gauthier Gidel},
  year          = {2023},
  booktitle     = {International Conference on Artificial Intelligence and Statistics, 25-27 April 2023, Palau de Congressos, Valencia, Spain},
  publisher     = {{PMLR}},
  series        = {Proceedings of Machine Learning Research},
  volume        = {206},
  pages         = {2905--2921},
  url           = {https://proceedings.mlr.press/v206/bertrand23a.html},
  abstract      = {The Elo score has been extensively used to rank players by their skill or strength in competitive games such as chess, go, or StarCraft II. The Elo score implicitly assumes games have a strong additive--hence transitive--component. In this paper, we investigate the challenge of identifying transitive components in games. As a starting point, we show that the Elo score provably fails to extract the transitive component of some elementary transitive games. Based on this observation, we propose an alternative ranking system which properly extracts the transitive components in these games. Finally, we conduct an in-depth empirical validation on real-world game payoff matrices: it shows significant prediction performance improvements compared to the Elo score.},
  github        = {https://github.com/QB3/discrating},
  pdf           = {https://proceedings.mlr.press/v206/bertrand23a/bertrand23a.pdf},
  editor        = {Francisco J. R. Ruiz and Jennifer G. Dy and Jan{-}Willem van de Meent},
}

@inproceedings{biemer:2024:solution-path-heuristics-predicting-difficulty-enjoyment-ratings-roguelike-level-segments,
  title         = {Solution Path Heuristics for Predicting Difficulty and Enjoyment Ratings of Roguelike Level Segments},
  author        = {Biemer, Colan and Cooper, Seth},
  year          = {2024},
  booktitle     = {Proceedings of the 19th International Conference on the Foundations of Digital Games},
  location      = {Worcester, MA, USA},
  publisher     = {Association for Computing Machinery},
  address       = {New York, NY, USA},
  series        = {FDG '24},
  doi           = {10.1145/3649921.3659846},
  isbn          = {9798400709555},
  url           = {https://doi.org/10.1145/3649921.3659846},
  abstract      = {When generating levels, algorithmically evaluating the results is essential. In this paper, we looked at predicting a level's difficulty and enjoyment. Past work has approached this problem for puzzle games like Sudoku by analyzing the characteristics of the initial level, the solved level, and the process that led to that solution. In this work, we examined a set of heuristics for Roguelike levels and their solutions, and their relationship to subjective player ratings of the levels. We gathered ratings of difficulty and enjoyment of levels in a study with 143 players. We ran an ablation study on the set of heuristics to find the best combination of heuristics for predicting difficulty and enjoyment with a linear regression model, and found solution path-based heursitics performed well. However, these models did not outperform a simple baseline for predicting enjoyment. Jaccard similarity on paths--a method we have not seen used in the field of game AI--was a useful predictor of difficulty. Testing proximity to enemies across a solution path is the only heuristic needed to predict how enjoyable a level will be.},
  articleno     = {69},
  numpages      = {8},
  keywords      = {difficulty, player study, procedural content generation},
}

@inproceedings{bizjak:2021:automatic-recognition-similar-chess-motifs,
  title         = {Automatic Recognition of Similar Chess Motifs},
  author        = {Bizjak, Miha and Guid, Matej},
  year          = {2021},
  booktitle     = {Advances in Computer Games: 17th International Conference, ACG 2021, Virtual Event, November 23–25, 2021, Revised Selected Papers},
  publisher     = {Springer-Verlag},
  address       = {Berlin, Heidelberg},
  pages         = {131–141},
  doi           = {10.1007/978-3-031-11488-5_12},
  isbn          = {978-3-031-11487-8},
  url           = {https://doi.org/10.1007/978-3-031-11488-5_12},
  abstract      = {We present a novel method to find chess positions similar to a given query position from a collection of chess games. We consider not only the static similarity resulting from the arrangement of chess pieces, but also the dynamic similarity involving the recognition of chess motifs and the tactical, dynamic aspects of position similarity. By encoding chess tactical problems as text documents, we use information retrieval techniques to enable efficient approximate searches. We have also developed a method for automatically generating tactical puzzles from a collection of chess games. We have experimentally shown the importance of including both static and dynamic features for successful recognition of similar chess motifs. The experiments have clearly shown that dynamic similarity plays a very important role in the evaluation of the similarity of chess motifs by both the program and chess experts.},
  numpages      = {11},
  keywords      = {Problem solving, Chess motifs, Automatic similarity recognition},
}

@inproceedings{bjorkqvist:2024:estimating-puzzlingness-chess-puzzles,
  title         = {{Estimating the Puzzlingness of Chess Puzzles}},
  author        = {Sebastian Bj\"{o}rkqvist},
  year          = {2024},
  booktitle     = {{IEEE} International Conference on Big Data, Big Data 2024, Washington DC, USA, December 15-18, 2024},
  publisher     = {{IEEE}},
}

@inproceedings{bjorkqvist:2025:estimating-difficulty-chess-puzzles-combining-fine-tuned-maia-2-hand-crafted-engine-features,
  title         = {Estimating the Difficulty of Chess Puzzles by Combining Fine-Tuned Maia-2 with Hand-Crafted and Engine Features},
  author        = {Sebastian Bj\"{o}rkqvist},
  year          = {2025},
  booktitle     = {Proceedings of the 20th Conference on Computer Science and Intelligence Systems (FedCSIS)},
  publisher     = {IEEE},
  series        = {Annals of Computer Science and Information Systems},
  volume        = {43},
  pages         = {801--806},
  doi           = {10.15439/2025F6497},
  url           = {http://dx.doi.org/10.15439/2025F6497},
  editor        = {Marek Bolanowski and Maria Ganzha and Leszek Maciaszek and Marcin Paprzycki and Dominik \'{S}l\k{e}zak},
  abstract      = {A common way for chess players to practice tactical awareness is to solve chess puzzles, consisting of an initial position and a sequence of moves to achieve a winning position. This practice is more effective when puzzles are matched to the player's skill level. In this work, we present an approach for estimating the difficulty of a chess puzzle using only the initial position and the sequence of correct moves. Our approach uses a fine-tuned modification of the Maia-2 model combined with a set of hand-crafted features and features extracted from chess engines such as Leela Chess Zero and Stockfish. All of these features are then used as input to a gradient boosted decision tree model that predicts the final rating of the puzzle. We applied our approach to the FedCSIS 2025 Challenge on Predicting Chess Puzzle Difficulty Part 2, where it achieved first place},
}

@thesis{bos:2021:improving-chess-elo-system-process-mining,
  title         = {Improving the Chess Elo System With Process Mining},
  author        = {Niels Bos},
  year          = {2021},
  month         = {July},
  url           = {http://essay.utwente.nl/88571/},
  type          = {Bachelor's thesis},
  supervisor    = {Faiza Allah Bukhsh},
  abstract      = {Over the last decade, the amount of data generated by software applications e.g. information systems, websites, mobile applications etc. has increased tremendously. Process mining, a subdiscipline of data science, uses this data to analyse and improve processes. In this research, the possibilities of process mining on chess event logs are explored, to ultimately improve the chess Elo system. The chess Elo system is a widely used and well accepted rating system. The Elo system is, however,  flawed in multiple ways. Two major flaws of the Elo system, are its incapability to review a player?s strength and the excessive time needed to gain the appropriate Elo rating. This research explores the potential of process mining to identify chess expertise. To be more specific, multiple process mining techniques are applied on chess event logs, and the generated process models are analysed to identify chess expertise. This research presents a method to analyse the differences between high and low rated players. This is achieved by comparing process models generated from high and low rated chess games. The results show that by comparing the process models differences between high and low rated players can be observed. Process mining is therefore a promising approach to improve the Elo system and might be applicable to other software too. However, only the first twelve moves of a game were used. To gain more insight into the differences between high and low rated players, the mid and end games should be included in the event logs as well. Future research should be conducted with more chess games added to the event logs to increase the validity.},
}

@inproceedings{bread-emoji-team-submission-2025-fedcsis-predicting-chess-puzzle-difficulty-challenge,
  title         = {The bread emoji Team's Submission to the 2025 FedCSIS Predicting Chess Puzzle Difficulty Challenge},
  author        = {Tyler Woodruff and Luke Imbing and Marco Cognetta},
  year          = {2025},
  booktitle     = {Proceedings of the 20th Conference on Computer Science and Intelligence Systems (FedCSIS)},
  publisher     = {IEEE},
  series        = {Annals of Computer Science and Information Systems},
  volume        = {43},
  pages         = {837--842},
  doi           = {10.15439/2025F6771},
  url           = {http://dx.doi.org/10.15439/2025F6771},
  editor        = {Marek Bolanowski and Maria Ganzha and Leszek Maciaszek and Marcin Paprzycki and Dominik \'{S}l\k{e}zak},
  abstract      = {We detail the bread emoji team's submission to the FedCSIS 2025 Predicting Chess Puzzle Difficulty Challenge. Our solution revolved around improving our submission from the previous competition by incorporating a new puzzle metadata feature and optimizing our implementation to allow for larger model ensembles and more stable training. Similar to our submission from last year, our system has two stages: learning a strong predictor for the Lichess dataset and then rescaling the distribution using an empirically-guided post-processing step to fit it to the smaller and noisier competition dataset. Our submission placed second with a ~3.9\% gap in mean squared error (MSE) from first place in the final evaluation.},
}

@inproceedings{cen:2025:multi-stage-framework-chess-puzzle-difficulty-prediction,
  title         = {A Multi-Stage Framework for Chess Puzzle Difficulty Prediction},
  author        = {Ling Cen and Jiahao Cen and Malin Song and Zhuliang Yu},
  year          = {2025},
  booktitle     = {Proceedings of the 20th Conference on Computer Science and Intelligence Systems (FedCSIS)},
  publisher     = {IEEE},
  series        = {Annals of Computer Science and Information Systems},
  volume        = {43},
  pages         = {807--812},
  doi           = {10.15439/2025F4532},
  url           = {http://dx.doi.org/10.15439/2025F4532},
  editor        = {Marek Bolanowski and Maria Ganzha and Leszek Maciaszek and Marcin Paprzycki and Dominik \'{S}l\k{e}zak},
  abstract      = {Accurately estimating the difficulty of the chess puzzle is important for adaptive training systems, personalized recommendations, and large-scale content curation. Unlike engine evaluations optimized for perfect play, this task involves modeling human-perceived solving difficulty, typically expressed by Glicko-2 ratings. We present a multi-stage framework developed for the FedCSIS 2025 Challenge. The method trains four rating-banded neural regression models in different Elo ranges to capture localized difficulty patterns and reduce bias from unbalanced data. Their predictions are combined with statistical attributes, including success probabilities, failure distributions, and solution length, through a feature-based regression stage to improve cross-range generalization. A final calibration step adjusts the output to statistically plausible rating levels, mitigating systematic prediction biases without adding computational complexity. An additional mask selection procedure was explored as part of the competition extension to identify 10\% of the puzzles that are most likely to benefit from the refined evaluation. The proposed solution ranked  in the final standings. These results demonstrate that a lightweight and interpretable regression pipeline can achieve competitive precision in modeling human-perceived chess puzzle difficulty.},
}

@article{chelly:2025:how-relevant-personas-open-source-software-development,
  title         = {How Relevant Are Personas in Open-Source Software Development?},
  author        = {Chelly, Ahmed  and Hamza, Salma  and Khan, Javed Ali},
  year          = {2025},
  journal       = {Frontiers in Computer Science},
  volume        = {Volume 7 - 2025},
  doi           = {10.3389/fcomp.2025.1457563},
  issn          = {2624-9898},
  url           = {https://www.frontiersin.org/journals/computer-science/articles/10.3389/fcomp.2025.1457563},
  github        = {https://github.com/ChellyAhmed/personas-os-resources},
  keywords      = {open-source software, user-centered design, usability, User persona, UX design},
  abstract      = {Open-source software (OSS) projects, characterized by distributed development and volunteer contributions, face challenges in prioritizing user-centered design and usability. This difficulty arises because these projects are primarily driven by developers who focus on technical contributions. As a result, usability and user experience (UX) considerations are often neglected, leading to software that may not meet the needs of its broad and diverse users. To address this issue, we explore the potential of using user personas, which are fictional characters representing real user groups, to enhance user-centered design in OSS projects. Personas promote empathy and a deeper understanding of user needs, thereby improving alignment between developers and users. We conducted an experimental study on three OSS projects: Moodle, Lichess, and Audacity. Personas were created for each project and refined based on feedback from industry experts. Developers rated personas highly for credibility (86\%), consistency(79\%), and friendliness (86\%), highlighting their relevance in OSS projects. A follow-up experiment with students confirmed these findings, with consistency (79\%) demonstrating personas' role in improving usability and aligning developers with user needs. While adoption remains limited due to technical priorities (only 14\% of developers and 34\% of students found personas useful and expressed willingness to adopt them), personas show significant potential to enhance user-centered design in OSS. Further research is needed to understand developers' reluctance to adopt this technique and explore strategies to integrate personas more effectively into OSS workflows. This study's novelty lies in its empirical exploration of personas within OSS, providing quantitative evidence of their effectiveness in improving usability and user-centered design.},
}

@inproceedings{chen:2025:how-to-scale-second-order-optimization,
  title         = {How to Scale Second-Order Optimization},
  author        = {Zixi Chen and Shikai Qiu and Hoang Phan and Qi Lei and Andrew Gordon Wilson},
  year          = {2025},
  booktitle     = {The Thirty-ninth Annual Conference on Neural Information Processing Systems},
  url           = {https://openreview.net/forum?id=Ei6IsmxYrb},
  keywords      = {second order optimization; scaling laws; maximum update paramterization; batch size scaling; depth scaling; critical batch size; compute optimal scaling},
  abstract      = {Several recently introduced deep learning optimizers inspired by second-order methods have shown promising speedups relative to the current dominant optimizer AdamW, particularly in relatively small-scale experiments. However, efforts to validate and replicate their successes have reported mixed results, with some finding quickly diminishing advantage over AdamW with scale. In this work, we investigate how to scale second-order optimizers to achieve optimal performance at scale. Through theoretical and empirical analysis, we derive scaling rules for hyperparameters such as learning rate and weight decay as we scale up model width and depth for a wide range of optimizers, including Shampoo, SOAP, and Muon, accounting for the impact of commonly used techniques such as blocking and grafting. For compute-optimal scaling, we find scaling independent weight decay as 1/width is nearly optimal across optimizers, and that second-order optimizers have a substantially larger optimal model size compared to AdamW for a fixed compute budget. Applying these scaling rules, we show Muon achieves close to 1.4x or higher speedup over AdamW in training transformer language models, while incorrect scaling can decrease the speedup from 1.4x to below 1.1x from 190M to 640M parameter models.},
  tldr          = {We investigate how to scale second-order optimizers effectively, showing they outperform Adam and reduce data needs in compute-optimal transformer training.},
}

@inproceedings{chen:2025:multi-model-deep-learning-residual-structure-guided-refinement-chess-puzzle-difficulty-prediction,
  title         = {Multi-Modal Deep Learning with Residual and Structure-Guided Refinement for Chess Puzzle Difficulty Prediction},
  author        = {Junlin Chen and Cenru Liu and Yujie Gao},
  year          = {2025},
  booktitle     = {Proceedings of the 20th Conference on Computer Science and Intelligence Systems (FedCSIS)},
  publisher     = {IEEE},
  series        = {Annals of Computer Science and Information Systems},
  volume        = {43},
  pages         = {813--818},
  doi           = {10.15439/2025F3227},
  url           = {http://dx.doi.org/10.15439/2025F3227},
  editor        = {Marek Bolanowski and Maria Ganzha and Leszek Maciaszek and Marcin Paprzycki and Dominik \'{S}l\k{e}zak},
  abstract      = {The goal of FedCSIS 2025 Challenge is to build a model to predict the difficulty (measured as Lichess rating) of given chess puzzles. To address this task, we propose a three-stage joint visual–statistical framework for predicting Glicko-based difficulty ratings. In the first stage, a convolutional model based on MobileNetV2 integrates FEN-rendered board images with structured features, including engine-predicted success probabilities, move count, and piece counts, to generate baseline predictions. The second stage employs LightGBM to perform residual refinement, explicitly learning the residual errors of the baseline predictions to correct systematic biases, particularly for extreme difficulty levels. Finally, a domain-informed refinement adjusts the outputs toward interpretable difficulty estimates derived from failure probability distributions and rating-bucket inflection points. Our model ranked 9th in the challenge. Experimental results show that residual refinement and domain-informed adjustment significantly reduce mean squared error compared to the baseline visual–statistical model.},
}

@inproceedings{chen:2025:strength-estimation-human-like-strength-adjustment-games,
  title         = {Strength Estimation and Human-Like Strength Adjustment in Games},
  author        = {Chun Jung Chen and Chung-Chin Shih and Ti-Rong Wu},
  year          = {2025},
  booktitle     = {The Thirteenth International Conference on Learning Representations},
  url           = {https://openreview.net/forum?id=CvjXlsBLCX},
  abstract      = {Strength estimation and adjustment are crucial in designing human-AI interactions, particularly in games where AI surpasses human players. This paper introduces a novel strength system, including a strength estimator (SE) and an SE-based Monte Carlo tree search, denoted as SE-MCTS, which predicts strengths from games and offers different playing strengths with human styles. The strength estimator calculates strength scores and predicts ranks from games without direct human interaction. SE-MCTS utilizes the strength scores in a Monte Carlo tree search to adjust playing strength and style. We first conduct experiments in Go, a challenging board game with a wide range of ranks. Our strength estimator significantly achieves over 80\% accuracy in predicting ranks by observing 15 games only, whereas the previous method reached 49\% accuracy for 100 games. For strength adjustment, SE-MCTS successfully adjusts to designated ranks while achieving a 51.33\% accuracy in aligning to human actions, outperforming a previous state-of-the-art, with only 42.56\% accuracy. To demonstrate the generality of our strength system, we further apply SE and SE-MCTS to chess and obtain consistent results. These results show a promising approach to strength estimation and adjustment, enhancing human-AI interactions in games. Our code is available at https://rlg.iis.sinica.edu.tw/papers/strength-estimator.},
  tldr          = {This paper proposes a strength system that can estimate the strength from games and provide various playing strengths while simultaneously offer a human-like behavior in both Go and chess.},
  keywords      = {Bradley-Terry Model, Strength Estimation, Strength Adjustment, Human-like Playing Style, Monte-Carlo Tree Search, Go, Chess},
  github        = {https://github.com/rlglab/strength-estimator/},
  website       = {https://rlg.iis.sinica.edu.tw/papers/strength-estimator/},
}

@inproceedings{cheong:2025:design-electronic-chess-board-analogue-hall-effect-sensors-piece-identification,
  title         = {Design of Electronic Chess Board Using Analogue Hall-effect Sensors for Piece Identification},
  author        = {Cheong, Justin Julius Chin and Bhatia, Praneel and Krauledat, Matthias and Hartanto, Ronny},
  year          = {2025},
  booktitle     = {2025 7th International Congress on Human-Computer Interaction, Optimization and Robotic Applications (ICHORA)},
  pages         = {1--5},
  doi           = {10.1109/ICHORA65333.2025.11016842},
  keywords      = {Magnetic flux density;Magnetic sensors;Printed circuits;Interference;Sensor phenomena and characterization;Robot sensing systems;Sensor systems;Sensors;Reliability;Magnets;electronic chessboard;analogue object identification;Hall-effect sensors;micro-controller},
}

@misc{choudhary:2025:human-chess-novel-searchless-rl-chess-agent-capable-multi-elo-human-like-play,
  title         = {Human Chess: A Novel Searchless RL-based Chess Agent Capable of Multi-ELO Human-Like Play},
  author        = {Choudhary, Prerit and Vagadia, Rikhil and Dhawan, Ankush},
  year          = {2025},
  url           = {https://cs224r.stanford.edu/projects/pdfs/CS224R_Final_Report__1_%20(3).pdf},
  note          = {Final project for CS 224R Deep Reinforcement Learning, Spring 2025 https://cs224r.stanford.edu/projects/cs224r\_final\_projects.html},
}

@article{chowdhary:2023:quantifying-human-performance-chess,
  title         = {Quantifying human performance in chess},
  author        = {Chowdhary, Sandeep and Iacopini, Iacopo and Battiston, Federico},
  year          = {2023},
  month         = {Feb},
  day           = {06},
  journal       = {Scientific Reports},
  volume        = {13},
  number        = {1},
  pages         = {2113},
  doi           = {10.1038/s41598-023-27735-9},
  issn          = {2045-2322},
  url           = {https://doi.org/10.1038/s41598-023-27735-9},
  abstract      = {From sports to science, the recent availability of large-scale data has allowed to gain insights on the drivers of human innovation and success in a variety of domains. Here we quantify human performance in the popular game of chess by leveraging a very large dataset comprising of over 120 million games between almost 1 million players. We find that individuals encounter hot streaks of repeated success, longer for beginners than for expert players, and even longer cold streaks of unsatisfying performance. Skilled players can be distinguished from the others based on their gaming behaviour. Differences appear from the very first moves of the game, with experts tending to specialize and repeat the same openings while beginners explore and diversify more. However, experts experience a broader response repertoire, and display a deeper understanding of different variations within the same line. Over time, the opening diversity of a player tends to decrease, hinting at the development of individual playing styles. Nevertheless, we find that players are often not able to recognize their most successful openings. Overall, our work contributes to quantifying human performance in competitive settings, providing a first large-scale quantitative analysis of individual careers in chess, helping unveil the determinants separating elite from beginner performance.},
}

@article{chowdhury:2021:predicting-chess-openings-modelling-opponents,
  title         = {Predicting Chess Opening Through Modelling Of Chess Opponents},
  author        = {Chowdhury, Debarpan Bose and Sen, Banashree},
  year          = {2021},
  journal       = {Webology (ISSN: 1735-188X)},
  volume        = {18},
  number        = {6},
}

@inproceedings{comarela:2021:lightweight-approach-prediction-errors-chess,
  title         = {A lightweight approach for predicting errors in chess matches},
  author        = {Giovanni Comarela and Davi Silva},
  year          = {2021},
  booktitle     = {Anais do XVIII Encontro Nacional de Intelig\^{e}ncia Artificial e Computacional},
  location      = {Evento Online},
  publisher     = {SBC},
  address       = {Porto Alegre, RS, Brasil},
  pages         = {703--714},
  doi           = {10.5753/eniac.2021.18296},
  issn          = {2763-9061},
  url           = {https://sol.sbc.org.br/index.php/eniac/article/view/18296},
}

@article{cook:2025:advantage-moving-first-amateur-online-chess,
  title         = {The Advantage of Moving First in Amateur Online Chess},
  author        = {Tyler Cook},
  year          = {2025},
  journal       = {ICGA Journal},
  doi           = {10.1177/13896911251315903},
  url           = {https://doi.org/10.1177/13896911251315903},
  abstract      = {There is a long-held belief in the chess community that the player with the white pieces has an advantage in making the first move. This phenomenon has been observed repeatedly in over-the-board games between high-level players and professionals. However, less is known about the prevalence of white's advantage in games played between amateurs in more casual settings. This article attempts to identify a first-move advantage in chess by examining a large database of amateur games played online on a dedicated chess website. Win rates are calculated for various rating levels, and the influence of opening move choice is also explored. These results can help determine whether there is an inherent first-move advantage in chess observable for all players in multiple settings, or if this effect is exclusively seen with players of high skill during games played in person.},
}

@article{cruz:2025:understanding-learned-look-ahead-behavior-chess-neural-networks,
  title         = {Understanding the learned look-ahead behavior of chess neural networks},
  author        = {Diogo Cruz},
  year          = {2025},
  journal       = {CoRR},
  volume        = {abs/2505.21552},
  doi           = {10.48550/ARXIV.2505.21552},
  url           = {https://doi.org/10.48550/arXiv.2505.21552},
  note          = {keywords from rejected openreview submission: https://openreview.net/forum?id=OcBAd0JPxv\&noteId=ZcMfmDpMpn},
  eprinttype    = {arXiv},
  eprint        = {2505.21552},
  abstract      = {We investigate the look-ahead capabilities of chess-playing neural networks, specifically focusing on the Leela Chess Zero policy network. We build on the work of Jenner et al. (2024) by analyzing the model's ability to consider future moves and alternative sequences beyond the immediate next move. Our findings reveal that the network's look-ahead behavior is highly context-dependent, varying significantly based on the specific chess position. We demonstrate that the model can process information about board states up to seven moves ahead, utilizing similar internal mechanisms across different future time steps. Additionally, we provide evidence that the network considers multiple possible move sequences rather than focusing on a single line of play. These results offer new insights into the emergence of sophisticated look-ahead capabilities in neural networks trained on strategic tasks, contributing to our understanding of AI reasoning in complex domains. Our work also showcases the effectiveness of interpretability techniques in uncovering cognitive-like processes in artificial intelligence systems.},
  keywords      = {model behavior attribution, look-ahead planning, mechanistic interpretability},
}

@article{czech:2020:learning-crazyhouse-above-world-champion-deep-neural-networks-human-data,
  title         = {Learning to Play the Chess Variant Crazyhouse Above World Champion Level With Deep Neural Networks and Human Data},
  author        = {Johannes Czech and Moritz Willig and Alena Beyer and Kristian Kersting and Johannes F{\"{u}}rnkranz},
  year          = {2020},
  journal       = {Frontiers Artif. Intell.},
  volume        = {3},
  pages         = {24},
  doi           = {10.3389/FRAI.2020.00024},
  url           = {https://doi.org/10.3389/frai.2020.00024},
}

@inproceedings{czech:2021:improving-alphazero-monte-carlo-graph-search,
  title         = {Improving AlphaZero Using Monte-Carlo Graph Search},
  author        = {Johannes Czech and Patrick Korus and Kristian Kersting},
  year          = {2021},
  booktitle     = {Proceedings of the Thirty-First International Conference on Automated Planning and Scheduling, {ICAPS} 2021, Guangzhou, China (virtual), August 2-13, 2021},
  publisher     = {{AAAI} Press},
  pages         = {103--111},
  url           = {https://ojs.aaai.org/index.php/ICAPS/article/view/15952},
  editor        = {Susanne Biundo and Minh Do and Robert Goldman and Michael Katz and Qiang Yang and Hankz Hankui Zhuo},
}

@inproceedings{das:2020:leveraging-rationales-human-task-performance,
  title         = {Leveraging rationales to improve human task performance},
  author        = {Das, Devleena and Chernova, Sonia},
  year          = {2020},
  booktitle     = {Proceedings of the 25th International Conference on Intelligent User Interfaces},
  location      = {Cagliari, Italy},
  publisher     = {Association for Computing Machinery},
  address       = {New York, NY, USA},
  series        = {IUI '20},
  pages         = {510–518},
  doi           = {10.1145/3377325.3377512},
  isbn          = {9781450371186},
  url           = {https://doi.org/10.1145/3377325.3377512},
  abstract      = {Machine learning (ML) systems across many application areas are increasingly demonstrating performance that is beyond that of humans. In response to the proliferation of such models, the field of Explainable AI (XAI) has sought to develop techniques that enhance the transparency and interpretability of machine learning methods. In this work, we consider a question not previously explored within the XAI and ML communities: Given a computational system whose performance exceeds that of its human user, can explainable AI capabilities be leveraged to improve the performance of the human? We study this question in the context of the game of Chess, for which computational game engines that surpass the performance of the average player are widely available. We introduce the Rationale-Generating Algorithm, an automated technique for generating rationales for utility-based computational methods, which we evaluate with a multi-day user study against two baselines. The results show that our approach produces rationales that lead to statistically significant improvement in human task performance, demonstrating that rationales automatically generated from an AI's internal task model can be used not only to explain what the system is doing, but also to instruct the user and ultimately improve their task performance.},
  numpages      = {9},
  keywords      = {explainable AI, machine learning},
}

@inproceedings{davis:2024:decoding-chess-mastery-mechanistic-analysis-chess-language-transformer-model,
  title         = {Decoding Chess Mastery: A Mechanistic Analysis of a Chess Language Transformer Model},
  author        = {Davis, Austin L. and Sukthankar, Gita},
  year          = {2024},
  booktitle     = {Artificial General Intelligence: 17th International Conference, AGI 2024, Seattle, WA, USA, August 13–16, 2024, Proceedings},
  location      = {SEATTLE, WA, USA},
  publisher     = {Springer-Verlag},
  address       = {Berlin, Heidelberg},
  pages         = {63–72},
  doi           = {10.1007/978-3-031-65572-2_7},
  isbn          = {978-3-031-65571-5},
  url           = {https://doi.org/10.1007/978-3-031-65572-2_7},
  abstract      = {Mechanistic interpretability (MI) studies aim to identify the specific neural pathways that underlie decision-making in neural networks. Here we analyze both the horizontal and vertical information flows of a chess-playing transformer. This paper introduces a new taxonomy of chessboard attention patterns that synchronize to guide move selection. Our findings show that the early layers of the chess transformer correctly identify moves that are highly ranked by the final layer. Experiments conducted on human chess players laid the foundation for much of our current understanding of human problem-solving, cognition, and visual memory. We believe that the study of chess language transformers may be an equally fruitful research area for AGI systems.},
  numpages      = {10},
  keywords      = {chess cognition, mechanistic interpretability, transformers},
}

@inproceedings{davis:2024:performance-envelopes-linear-probes-latent-representation-edits-gpt-models,
  title         = {Performance Envelopes of Linear Probes for Latent Representation Edits in GPT Models},
  author        = {Davis, Austin L and Sukthankar, Gita},
  year          = {2024},
  booktitle     = {2024 International Conference on Machine Learning and Applications (ICMLA)},
  keywords      = {Representation Engineering; Probing Classifiers; Chess-playing Language Models, GPT},
}

@thesis{davis:2025:interpreation-control-ai-model-behavior-direct-adjustment-latent-representations,
  title         = {Interpretation and Control of AI Model Behavior Through Direct Adjustment of Latent Representations},
  author        = {Davis, Austin},
  year          = {2025},
  url           = {https://stars.library.ucf.edu/etd2024/285},
  institution   = {University of Central Florida},
  type          = {PhD thesis},
  supervisor    = {Sukthankar, Gita},
  keywords      = {Latent Representation Editing; Mechanistic Interpretability; Linear Probes; Chess Language Models; Artificial Intelligence},
  abstract      = {
    This dissertation investigates the structures and mechanisms underpinning the latent space representations that emerge within Generative Pretrained Transformer (GPT) models. Addressing the broader goal of enhancing AI trustworthiness through transparency, accountability, and controllability, we focus on techniques to understand, quantify, and manipulate these latent space representations. Through a series of analyses, we examine several chess-playing GPT models as controlled testbeds, leveraging their structured decision space to explore emergent representations and decision-making processes.

    Key contributions include a mechanistic analysis of the attention heads and latent representations, the development of novel metrics for evaluating intervention outcomes, and the application of linear probe classifiers to decode and edit the model's internal world representations. Analysis of the probe weight vectors reveals that the chess-playing GPT developed an emergent world model of the game that includes pieces, positions, and movement rules, and provides empirical support for the linear representation hypothesis--the idea that abstract concepts are encoded as specific directions in the model's hidden state space. Complementary analysis of the hidden state vectors demonstrates that the model's internal representations honor the Markovian property of chess.

    Experimental results demonstrate that linear interventions can causally steer GPT outputs while preserving their semantic validity. Drawing on the dose-response analogy from medicine, we vary both the strength and position of interventions, showing that output quality is maximized when intervention strength follows an exponentially decaying schedule across token positions. Similar experiments using sparse autoencoders in place of linear probes yielded significantly poorer performance. These results highlight the effectiveness of simple linear probes as valuable tools for interpretability and control.
  },
}

@article{de-marzo:2023:complexity-similarity-chess-openings-community-data,
  title         = {Quantifying the complexity and similarity of chess openings using online chess community data},
  author        = {De Marzo, Giordano and Servedio, Vito D. P.},
  year          = {2023},
  month         = {Apr},
  day           = {01},
  journal       = {Scientific Reports},
  volume        = {13},
  number        = {1},
  pages         = {5327},
  doi           = {10.1038/s41598-023-31658-w},
  issn          = {2045-2322},
  url           = {https://doi.org/10.1038/s41598-023-31658-w},
  abstract      = {Chess is a centuries-old game that continues to be widely played worldwide. Opening Theory is one of the pillars of chess and requires years of study to be mastered. In this paper, we use the games played in an online chess platform to exploit the ``wisdom of the crowd'' and answer questions traditionally tackled only by chess experts. We first define a relatedness network of chess openings that quantifies how similar two openings are to play. Using this network, we identify communities of nodes corresponding to the most common opening choices and their mutual relationships. Furthermore, we demonstrate how the relatedness network can be used to forecast future openings players will start to play, with back-tested predictions outperforming a random predictor. We then apply the Economic Fitness and Complexity algorithm to measure the difficulty of openings and players' skill levels. Our study not only provides a new perspective on chess analysis but also opens the possibility of suggesting personalized opening recommendations using complex network theory.},
}

@inproceedings{de-sa-delgado-neto:2019:chess-position-identification,
  title         = {Chess Position Identification using Pieces Classification Based on Synthetic Images Generation and Deep Neural Network Fine-Tuning},
  author        = {de S\'{a} Delgado Neto, Afonso and Mendes Campello, Rafael},
  year          = {2019},
  booktitle     = {2019 21st Symposium on Virtual and Augmented Reality (SVR)},
  pages         = {152--160},
  doi           = {10.1109/SVR.2019.00038},
  keywords      = {Histograms, Image color analysis, Games, Tracking, Image edge detection, Machine learning, Task analysis, chess, neural networks, piece recognition, synthetic data generation},
}

@misc{deletang:2024:generative-reinforcement-learning-with-transformers,
  title         = {Generative Reinforcement Learning with Transformers},
  author        = {Gregoire Deletang and Anian Ruoss and Li Kevin Wenliang and Elliot Catt and Tim Genewein and Jordi Grau-Moya and Marcus Hutter and Joel Veness},
  year          = {2024},
  url           = {https://openreview.net/forum?id=6qtDu7hVPF},
}

@inproceedings{demeter:2021:probing-learning-representation-language-models-closed-domains,
  title         = {Who{'}s on First?: Probing the Learning and Representation Capabilities of Language Models on Deterministic Closed Domains},
  author        = {Demeter, David  and Downey, Doug},
  year          = {2021},
  month         = nov,
  booktitle     = {Proceedings of the 25th Conference on Computational Natural Language Learning},
  publisher     = {Association for Computational Linguistics},
  address       = {Online},
  pages         = {210--222},
  doi           = {10.18653/v1/2021.conll-1.16},
  url           = {https://aclanthology.org/2021.conll-1.16},
  editor        = {Bisazza, Arianna  and Abend, Omri},
  abstract      = {The capabilities of today{'}s natural language processing systems are typically evaluated using large datasets of curated questions and answers. While these are critical benchmarks of progress, they also suffer from weakness due to artificial distributions and incomplete knowledge. Artifacts arising from artificial distributions can overstate language model performance, while incomplete knowledge limits fine-grained analysis. In this work, we introduce a complementary benchmarking approach based on SimPlified Language Activity Traces (SPLAT). SPLATs are corpora of language encodings of activity in some closed domain (we study traces from chess and baseball games in this work). SPLAT datasets use naturally-arising distributions, allow the generation of question-answer pairs at scale, and afford complete knowledge in their closed domains. We show that language models of three different architectures can answer questions about world states using only verb-like encodings of activity. Our approach is extensible to new language models and additional question-answering tasks.},
}

@inproceedings{diallo:2025:chessmovellm-large-language-models-chess-next-move-prediction,
  title         = {ChessMoveLLM: Large Language Models for Chess Next Move Prediction},
  author        = {Diallo, Kassim B. and Akhloufi, Moulay A.},
  year          = {2025},
  booktitle     = {SoutheastCon 2025},
  pages         = {475--480},
  doi           = {10.1109/SoutheastCon56624.2025.10971611},
  keywords      = {Training, Deep learning, Social networking (online), Large language models, Retrieval augmented generation, Force, Transformers, Logic, Engines, Tuning, Deep learning, Transformers ,LLMs, RAG, FAISS, GPT, Similarity Search, Chess engine, Fine tuning},
}

@inproceedings{ding:2024:easy2hard-bench,
  title         = {Easy2Hard-Bench: Standardized Difficulty Labels for Profiling LLM Performance and Generalization},
  author        = {Ding, Mucong and Deng, Chenghao and Choo, Jocelyn and Wu, Zichu and Agrawal, Aakriti and Schwarzschild, Avi and Zhou, Tianyi and Goldstein, Tom and Langford, John and Anandkumar, A. and Huang, Furong},
  year          = {2024},
  month         = {September},
  booktitle     = {NeurIPS 2024},
  url           = {https://www.microsoft.com/en-us/research/publication/easy2hard-bench-standardized-difficulty-labels-for-profiling-llm-performance-and-generalization/},
  abstract      = {While generalization over tasks from easy to hard is crucial to profile language models (LLMs), the datasets with fine-grained difficulty annotations for each problem across a broad range of complexity are still blank. Aiming to address this limitation, we present Easy2Hard-Bench, a consistently formatted collection of 6 benchmark datasets spanning various domains, such as mathematics and programming problems, chess puzzles, and reasoning questions. Each problem within these datasets is annotated with numerical difficulty scores. To systematically estimate problem difficulties, we collect abundant performance data on attempts to each problem by humans in the real world or LLMs on the prominent leaderboard. Leveraging the rich performance data, we apply well-established difficulty ranking systems, such as Item Response Theory (IRT) and Glicko-2 models, to uniformly assign numerical difficulty scores to problems. Moreover, datasets in Easy2Hard-Bench distinguish themselves from previous collections by a higher proportion of challenging problems. Through extensive experiments with six state-of-the-art LLMs, we provide a comprehensive analysis of their performance and generalization capabilities across varying levels of difficulty, with the aim of inspiring future research in LLM generalization. The datasets are available at https://huggingface.co/datasets/furonghuang-lab/Easy2Hard-Bench.},
}

@inbook{divakaran:2025:data-serializaiton-persistence-deep-dive-python-techniques-best-practices-developers,
  title         = {Data Serialization and Persistence},
  author        = {Divakaran, Adarsh},
  year          = {2025},
  booktitle     = {Deep Dive Python: Techniques and Best Practices for Developers},
  publisher     = {Apress},
  address       = {Berkeley, CA},
  pages         = {531--588},
  doi           = {10.1007/979-8-8688-1261-3_17},
  isbn          = {979-8-8688-1261-3},
  url           = {https://doi.org/10.1007/979-8-8688-1261-3_17},
}

@article{dogra:2025:beyond-perfect-play-combinatorial-probabilistic-approach-chess-endgame-strategy,
  title         = {Beyond Perfect Play: A Combinatorial and Probabilistic Approach to Chess Endgame Strategy},
  author        = {Divij Dogra},
  year          = {2025},
  journal       = {The National High School Journal of Science},
  url           = {https://nhsjs.com/2025/beyond-perfect-play-a-combinatorial-and-probabilistic-approach-to-chess-endgame-strategy/},
  abstract      = {Chess is a complex game that requires deep strategic thinking, pattern recognition, calculations, and creative problem-solving. Modeling strategic decision-making in chess endgames poses a unique challenge due to the game's high complexity and the uncertainty of human play. In this paper, we propose a hybrid analytical framework that combines combinatorial game theory, graph-theoretic game-tree analysis, and probabilistic modeling to explore optimal strategies in simplified endgame positions. Using real examples including games from the 2024 FIDE World Chess Championship match between Gukesh and Ding, we construct and analyze game trees to evaluate strategies under probabilistic distributions of plausible human responses. Our approach extends traditional models by incorporating uncertainty into the decision-making process, allowing for a richer understanding of practical play in high-stakes scenarios. This framework offers a bridge between theoretical rigor and real-world applicability in chess and beyond.},
  keywords      = {combinatorial game theory; CGT; optimal strategy; probabilistic modeling; graph-theoretic game tree analysis; chess},
}

@inproceedings{donoway:2025:quantifying-elicitation-latent-capabilities-language-models,
  title         = {Quantifying Elicitation of Latent Capabilities in Language Models},
  author        = {Elizabeth Donoway and Hailey Joren and Arushi Somani and Henry Sleight and Julian Michael and Michael R DeWeese and John Schulman and Ethan Perez and Fabien Roger and Jan Leike},
  year          = {2025},
  booktitle     = {The Thirty-ninth Annual Conference on Neural Information Processing Systems},
  url           = {https://openreview.net/forum?id=Dkgx2pS4Ww},
  keywords      = {elicitation, large language models, LLMs, latent capabilities, minimum description length},
  abstarct      = {Large language models often possess latent capabilities that lie dormant unless explicitly elicited, or surfaced, through fine-tuning or prompt engineering. Predicting, assessing, and understanding these latent capabilities pose significant challenges in the development of effective, safe AI systems. In this work, we recast elicitation as an information-constrained fine-tuning problem and empirically characterize upper bounds on the minimal number of parameters needed to achieve specific task performances. We find that training as few as 10-100 randomly chosen parameters--several orders of magnitude fewer than state-of-the-art parameter-efficient methods--can recover up to 50\% of the performance gap between pretrained-only and full fine-tuned models, and 1,000s to 10,000s of parameters can recover 95\% of this performance gap. We show that a logistic curve fits the relationship between the number of trained parameters and model performance gap recovery. This scaling generalizes across task formats and domains, as well as model sizes and families, extending to reasoning models and remaining robust to increases in inference compute. To help explain this behavior, we consider a simplified picture of elicitation via fine-tuning where each trainable parameter serves as an encoding mechanism for accessing task-specific knowledge. We observe a relationship between the number of trained parameters and how efficiently relevant model capabilities can be accessed and elicited, offering a potential route to distinguish elicitation from teaching.},
  github        = {https://github.com/edonoway/quantifying-elicitation-neurips25},
}

@article{eisma:2024:turing-tests-chess-human-subjectivity,
  title         = {Turing Tests in Chess: An Experiment Revealing the Role of Human Subjectivity},
  author        = {Yke Bauke Eisma and Robin Koerts and Joost {de Winter}},
  year          = {2024},
  journal       = {Computers in Human Behavior Reports},
  pages         = {100496},
  doi           = {https://doi.org/10.1016/j.chbr.2024.100496},
  issn          = {2451-9588},
  url           = {https://www.sciencedirect.com/science/article/pii/S2451958824001295},
  abstract      = {With the growing capabilities of AI, technology is increasingly able to match or even surpass human performance. In the current study, focused on the game of chess, we investigated whether chess players could distinguish if they were playing against a human or a computer, and how they achieved this. A total of 24 chess players each played eight 5+0 Blitz games from different starting positions. They played against (1) a human, (2) Maia, a neural network-based chess engine trained to play in a human-like manner, (3) Stockfish 16, the best chess engine available, downgraded to play at a lower level, and (4) Stockfish 16 at its maximal level. The opponent's move time was fixed at 10 seconds. During the game, participants verbalized their thoughts, and after each game, they indicated by means of a questionnaire whether they thought they had played against a human or a machine and if there were particular moves that revealed the nature of the opponent. The results showed that Stockfish at the highest level was usually correctly identified as an engine, while Maia was often incorrectly identified as a human. The moves of the downgraded Stockfish were relatively often labeled as `strange' by the participants. In conclusion, the Turing test, as applied here in a domain where computers can perform superhumanly, is essentially a test of whether the chess computer can devise suboptimal moves that correspond to human moves, and not necessarily a test of computer intelligence.},
}

@inproceedings{feng:2023:chessgpt-policy-learning-language-modeling,
  title         = {ChessGPT: Bridging Policy Learning and Language Modeling},
  author        = {Xidong Feng and Yicheng Luo and Ziyan Wang and Hongrui Tang and Mengyue Yang and Kun Shao and David Mguni and Yali Du and Jun Wang},
  year          = {2023},
  booktitle     = {Advances in Neural Information Processing Systems 36: Annual Conference on Neural Information Processing Systems 2023, NeurIPS 2023, New Orleans, LA, USA, December 10 - 16, 2023},
  url           = {http://papers.nips.cc/paper\_files/paper/2023/hash/16b14e3f288f076e0ca73bdad6405f77-Abstract-Datasets\_and\_Benchmarks.html},
  editor        = {Alice Oh and Tristan Naumann and Amir Globerson and Kate Saenko and Moritz Hardt and Sergey Levine},
}

@misc{feng:2025:generating-creative-chess-puzzles,
  title         = {Generating Creative Chess Puzzles},
  author        = {Xidong Feng and Vivek Veeriah and Marcus Chiam and Michael Dennis and Ryan Pachauri and Thomas Tumiel and Federico Barbero and Johan Obando-Ceron and Jiaxin Shi and Satinder Singh and Shaobo Hou and Nenad Toma\v{s}ev and Tom Zahavy},
  year          = {2025},
  url           = {https://arxiv.org/abs/2510.23881},
  eprint        = {2510.23881},
  archiveprefix = {arXiv},
  primaryclass  = {cs.AI},
  abstract      = {While Generative AI rapidly advances in various domains, generating truly creative, aesthetic, and counter-intuitive outputs remains a challenge. This paper presents an approach to tackle these difficulties in the domain of chess puzzles. We start by benchmarking Generative AI architectures, and then introduce an RL framework with novel rewards based on chess engine search statistics to overcome some of those shortcomings. The rewards are designed to enhance a puzzle's uniqueness, counter-intuitiveness, diversity, and realism. Our RL approach dramatically increases counter-intuitive puzzle generation by 10x, from 0.22\% (supervised) to 2.5\%, surpassing existing dataset rates (2.1\%) and the best Lichess-trained model (0.4\%). Our puzzles meet novelty and diversity benchmarks, retain aesthetic themes, and are rated by human experts as more creative, enjoyable, and counter-intuitive than composed book puzzles, even approaching classic compositions. Our final outcome is a curated booklet of these AI-generated puzzles, which is acknowledged for creativity by three world-renowned experts.},
}

@inproceedings{gamal:2025:machine-learning-based-dynamic-difficulty-adaptation-chess,
  title         = {Machine Learning Based Dynamic Difficulty Adaptation for Chess},
  author        = {Gamal, Mohamed and Aboulhassan, Amal and Hassan, Yomna M.I.},
  year          = {2025},
  booktitle     = {2025 International Mobile, Intelligent, and Ubiquitous Computing Conference (MIUCC)},
  pages         = {9--14},
  doi           = {10.1109/MIUCC66482.2025.11196851},
  abstract      = {Chess enhances problem-solving and decisionmaking skills. Traditional chess often features static difficulty, which can frustrate novices or bore masters. Dynamic Difficulty Adaptation (DDA) addresses this by adjusting the game's challenge based on player performance, enabling personalized learning and engagement. DDA relies on game analytics by collecting and interpreting performance data such as move timing, accuracy, and positional evaluations compared to top engines. In chess, the structured gameplay and availability of engines like Stockfish offer an ideal environment for DDA. By integrating game analytics, DDA can apply adjustments responsive to the player's current ability rather than relying on fixed difficulty presets. This approach tailors the gaming experience to individual skill levels, preventing novice frustration and keeping expert players challenged. Thus, game analytics enhances DDA in chess, creating an adaptive environment that caters to a broad spectrum of players.},
  keywords      = {Accuracy;Games;Machine learning;Ubiquitous computing;Timing;Problem-solving;Engines;Game Analytics;Dynamic Difficulty Adaption;Chess;Machine Learning},
}

@misc{gee:2025:investigating-experiential-effects-online-chess-hierarchical-bayesian-analysis,
  title         = {Investigating Experiential Effects in Online Chess using a Hierarchical Bayesian Analysis},
  author        = {Adam Gee and Sydney O. Seese and James P. Curley and Owen G. Ward},
  year          = {2025},
  url           = {https://arxiv.org/abs/2503.21713},
  eprint        = {2503.21713},
  archiveprefix = {arXiv},
  primaryclass  = {stat.AP},
}

@article{ghayebzadeh:2025:effect-transcranial-current-decision-making-chess-personality,
  title         = {The Effect of Transcranial Direct Current Stimulation on Risky Decision-Making of Student Chess Players Based on their Introverted and Extroverted Personality Traits},
  author        = {Ghayebzadeh, Shahrouz and Moharramzadeh, Mehrdad and Zoghi, Maryam},
  year          = {2025},
  journal       = {Sport Psychology Studies},
  publisher     = {Sport Sciences Research institute},
  doi           = {10.22089/spsyj.2025.17731.2546},
  issn          = {2345-2978},
  url           = {https://spsyj.ssrc.ac.ir/article_4394_55f2b660d8300f25206eb52a483e0bb4.pdf},
  eissn         = {2538-1504},
  abstract      = {The aim of this research was to investigate the effects of transcranial direct current stimulation (tDCS) on risky decision-making in student chess players, taking into account their personality traits. In this study, 28 high school students who were active in chess and participated in provincial and national chess leagues were selected. Based on the NEO Five-Factor Inventory of personality traits, they were divided into two groups: 14 extroverted students (17 \pm{} 0.88) and 14 introverted students (16.5 \pm{} 1.02). Each participant attended three separate sessions in the laboratory, with a minimum 72-hour rest period between sessions. In each session, participants performed the Iowa Gambling Task and the Lichess computer game before any stimulation. They were then subjected to one of three conditions: right anodal/left cathodal, right cathodal/left anodal, or sham stimulation, for 20 minutes at 2 mA intensity over the dorsolateral prefrontal cortex. After the stimulation, participants repeated the Iowa Gambling Task and the Lichess computer game. Data analysis using two-way mixed ANOVA revealed a significant difference in the Iowa Gambling Task between right anodal/left cathodal and right cathodal/left anodal stimulation based on personality traits (p = 0.001). The findings of this study indicated that transcranial direct current stimulation had a differential effect on decision-making in chess players based on their personality traits. Specifically, the study's results showed that extroverted players exhibited more risk-taking behaviour, while introverted players acted more cautiously.},
  keywords      = {Extroverted,Brain stimulation,Risky Decision-making,Introverted,Chess},
}

@thesis{giadikiaroglou:2025:investgiating-capabilities-language-models-puzzles,
  title         = {Investigating the capabilities of language models in puzzle reasoning: A survey and experimental analysis},
  author        = {Giadikiaroglou, Panagiotis},
  year          = {2025},
  month         = mar,
  publisher     = {National Technological University of Athens},
  doi           = {http://dx.doi.org/10.26240/heal.ntua.29165},
  url           = {https://dspace.lib.ntua.gr/xmlui/handle/123456789/61469},
  supervisor    = {Giorgos Stamou},
  type          = {Bachelor's thesis},
  keywords      = {Large Language Models; Reasoning; Puzzle Solving; Prompting; Neurosymbolic Methods},
  abstract      = {Puzzle-solving has long served as a benchmark for evaluating artificial intelligence, testing a model's ability to reason, infer, and strategize across complex problem spaces. Traditional AI and machine learning methods, such as symbolic reasoning and reinforcement learning, have made notable strides in structured domains like board games and logic puzzles. However, as neural networks and, more recently, large language models (LLMs) have evolved, new possibilities have emerged for tackling a broader range of puzzle types, including those requiring nuanced commonsense reasoning, abstract pattern recognition, and complex multi-step calculations. LLMs, with their vast data-driven language capabilities, hold unique potential to bridge structured logical tasks and less formal, knowledge-based puzzles. Despite these advances, the current landscape of puzzle-solving with LLMs reveals both achievements and limitations, particularly when models are tasked with problems that demand interpretative reasoning and precise calculation. This thesis explores the evolving role of LLMs in solving such complex reasoning tasks, specifically focusing on their puzzle-solving capabilities. Divided into two main sections, the thesis first provides a comprehensive survey of recent advancements in LLM methodologies, covering diverse prompting techniques, neuro-symbolic approaches, and fine-tuning strategies for puzzles. Using a newly proposed taxonomy, puzzles are categorized into rule-based and rule-less types, with each category examined for its unique cognitive demands on LLMs. The second section presents experimental evaluations conducted on four datasets--two math-based datasets (GSM8K, SVAMP) and two puzzle-focused datasets (Game of 24 and RiddleSense). Various reasoning techniques, including Input-Output (IO) prompting, Chain-of-Thought (CoT), Least-to-Most (LtM), and Faithful-CoT methods, are employed to assess LLM performance. Models of varying scales, particularly smaller LLMs like Llama-3.1 family and Mistral, are tested across settings such as zero-shot, few-shot, and self-consistency to evaluate their efficacy in solving complex and multi-step reasoning tasks. The thesis provides critical insights into the performance limitations of current LLMs in puzzle-solving, particularly noting that advanced reasoning methods like Faithful-CoT and puzzle translation techniques yield inconsistent improvements with smaller models. Finally, it outlines future research directions, advocating for expanded dataset creation, neuro-symbolic integration, and advancements in puzzle generation. This thesis aims to deepen our understanding of LLMs' reasoning abilities and highlight pathways to enhance their performance in complex cognitive tasks.},
}

@thesis{giron:2025:alpha-deep-chess-chess-engine-alpha-beta-pruning,
  title         = {AlphaDeepChess: chess engine based on alpha-beta pruning},
  author        = {Gir{\'o}n Herranz, Juan and Wang Qiu, Yi},
  year          = {2025},
  doi           = {20.500.14352/123857},
  url           = {https://hdl.handle.net/20.500.14352/123857},
  institution   = {Universidad Complutense de Madrid},
  type          = {Grado en Ingenier\'{\i}a de Computadores y Grado en Desarrollo de Videojuegos},
  supervisor    = {F\'{a}bregas Alfaro, Ignacio and Rubio Cu\'{e}llar, Rub\'{e}n Rafael},
  keywords      = {Articial Intelligence, Chess Engine, Alpha-beta pruning, Iterative deepening, Quiescence search, Move ordering, Transposition table, Zobrist hashing, Magic bitboards},
  abstract      = {Chess engines have played a fundamental role in the advancement of articial intelligence applied to the game since the mid-20th century. Today, Stocksh, the most powerful and open source chess engine, still relies on alpha-beta pruning, but also incorporates machine learning techniques. The goal of this project is to develop a chess engine capable of competing againstboth other engines and human players, using minimax with alpha-beta pruning as its core. Additionally, we analyze the impact of other classical algorithmic techniquessuch as transposition tables, iterative deepening, and a move generator based on magic bitboards. The chess engine has been uploaded to the Lichess platform, where AlphaDeepChess achieved an Elo rating of 1900 while running on a Raspberry Pi 5 equipped with a 2GB transposition table.},
  github        = {https://github.com/LauraWangQiu/AlphaDeepChess},
}

@inproceedings{guntz:2018:role-emotion-problem-solving,
  title         = {The role of emotion in problem solving: first results from observing chess},
  author        = {Thomas Guntz and James L. Crowley and Dominique Vaufreydaz and Raffaella Balzarini and Philippe Dessus},
  year          = {2018},
  booktitle     = {Proceedings of the Workshop on Modeling Cognitive Processes from Multimodal Data, MCPMD\@ICMI 2018, Boulder, CO, USA, October 16, 2018},
  publisher     = {{ACM}},
  pages         = {12},
  url           = {http://dl.acm.org/citation.cfm?id=3279846},
}

@article{gupta:2023:determining-chess-piece-values-machine-learning,
  title         = {Determining Chess Piece Values Using Machine Learning},
  author        = {Gupta, Aditya and Grattoni, Christopher and Gupta, Arnav},
  year          = {2023},
  month         = {Feb.},
  journal       = {Journal of Student Research},
  volume        = {12},
  number        = {1},
  doi           = {10.47611/jsrhs.v12i1.4356},
  url           = {https://www.jsr.org/hs/index.php/path/article/view/4356},
  place         = {Houston, USA},
  abstract      = {This paper attempts to generate point values for chess pieces, as alternatives to the commonly accepted chess piece values. We use a database of over a million online chess games to heuristically determine the value of a chess piece, by using material imbalances to predict game results. We then explore how piece values change when we analyze material imbalances at various stages of a chess game. As further exploration, we determine what practical values chess pieces and imbalances have at various rating ranges. This creates practical data that players of varying rating can use to aid in chess calculation, as opposed to the rigid values that are typically accepted.\&lt;/p\&gt;},
}

@article{helfenstein:2024:checkmating-one-many-mixture-of-experts-mcts-improve-chess,
  title         = {Checkmating One, by Using Many: Combining Mixture of Experts with {MCTS} to Improve in Chess},
  author        = {Felix Helfenstein and Jannis Bl{\"{u}}ml and Johannes Czech and Kristian Kersting},
  year          = {2024},
  journal       = {CoRR},
  volume        = {abs/2401.16852},
  doi           = {10.48550/ARXIV.2401.16852},
  url           = {https://doi.org/10.48550/arXiv.2401.16852},
  eprinttype    = {arXiv},
  eprint        = {2401.16852},
}

@inproceedings{holdaway:2021:risk-taking-adversarial-games-what-billion-chess-games-tell-us,
  title         = {Risk-taking in adversarial games: What can 1 billion online chess games tell us?},
  author        = {Cameron Holdaway and Ed Vul},
  year          = {2021},
  booktitle     = {Proceedings of the 43rd Annual Meeting of the Cognitive Science Society, CogSci 2021, virtual, July 26-29, 2021},
  publisher     = {cognitivesciencesociety.org},
  url           = {https://escholarship.org/uc/item/403764rd},
  editor        = {W. Tecumseh Fitch and Claus Lamm and Helmut Leder and Kristin Te{\ss}mar{-}Raible},
}

@mastersthesis{hoque:2022:classification-anomaly-detection-chess,
  title         = {Classification of Chess Games: An Exploration of Classifiers for Anomaly Detection in Chess},
  author        = {Hoque, Masudul},
  year          = {2021},
  note          = {https://cornerstone.lib.mnsu.edu/etds/1119/},
  school        = {Minnesota State University, Mankato},
  type          = {Master's thesis},
  annote        = {Chess is a strategy board game with its inception dating back to the 15th century. The Covid-19 pandemic has led to a chess boom online with 95,853,038 chess games being played during January, 2021 on lichess.com. Along with the chess boom, instances of cheating have also become more rampant. Classifications have been used for anomaly detection in different fields and thus it is a natural idea to develop classifiers to detect cheating in chess. However, there are no specific examples of this, and it is difficult to obtain data where cheating has occurred. So, in this paper, we develop 4 machine learning classifiers, Linear Discriminant Analysis, Quadratic Discriminant Analysis, Multinomial Logistic Regression, and K-Nearest Neighbour classifiers to predict chess game results and explore predictors that produce the best accuracy performance. We use Confusion Matrix, K Fold Cross-Validation, and Leave-One-Out Cross-Validation methods to find the accuracy metrics. There are three phases of analysis. In phase I, we train classifiers using 1.94 million over the board game as training data and 20 thousand online games as testing data and obtain accuracy metrics. In phase II, we select a smaller pool of 212 games, select additional predictor variables from chess engine evaluation of the moves played in those games and check whether the inclusion of the variables improve performance. Finally, in phase III, we investigate for patterns in misclassified cases to define anomalies. From phase I, the models are not performing at a utilizable level of accuracy (44-63\%). For all classifiers, it is no better than deciding the class with a coin toss. K-Nearest Neighbour with K = 7 was the best model. In phase II, adding the new predictors improved the performance of all the classifiers significantly across all validation methods. In fact, using only significant variables as predictors produced highly accurate classifiers. Finally, from phase III, we could not find any patterns or significant differences between the predictors for both correct classifications and misclassifications. In conclusion, machine learning classification is only one useful tool to spot instances that indicates anomalies. However, we cannot simply judge anomalous games using only this method.},
}

@misc{hull:2025:beyond-evaluation-learning-contextual-chess-position-representations,
  title         = {Beyond Evaluation: Learning Contextual Chess Position Representations},
  author        = {Ben Hull},
  year          = {2025},
  note          = {Technical report},
  howpublished  = {Accessed via \url{[https://bluehood.github.io/](https://bluehood.github.io/)}},
}

@article{huseynova:2025:methods-tools-teaching-chess-higher-education,
  title         = {Methods and Tools for Teaching Chess in Higher Education},
  author        = {Huseynova, Kifayet and Novruzova, Aide},
  year          = {2025},
  month         = {Dec.},
  journal       = {Porta Universorum},
  volume        = {1},
  number        = {10},
  pages         = {176–186},
  doi           = {10.69760/portuni.0110018},
  url           = {https://egarp.lt/index.php/JPURM/article/view/460},
  keywords      = {chess education, higher education, pedagogy, constructivism, blended learning, assessment, chess engines,digital boards, transferable skills},
  abstract      = {This paper examines pedagogical approaches and instructional tools for teaching chess in higher education. Chess instruction in universities can serve disciplinary goals (e.g., sport sciences, cognitive psychology), cross-curricular goals (critical thinking, problem solving), and extra-curricular objectives (wellness, student engagement). Drawing on theoretical frameworks from constructivist and experiential learning, and on empirical literature about cognitive and educational effects of chess training, the paper presents a structured course design, recommended teaching methods, practical activities, digital and physical tools, assessment strategies, and implementation considerations. The aim is to provide instructors and programme designers with an evidence-informed, practical roadmap to develop effective, measurable, and scalable chess courses or modules that align with higher-education learning outcomes.},
}

@misc{hwang:2025:can-large-language-models-develop-strategic-reasoning-post-training-insights-learning-chess,
  title         = {Can Large Language Models Develop Strategic Reasoning? Post-training Insights from Learning Chess},
  author        = {Dongyoon Hwang and Hojoon Lee and Jaegul Choo and Dongmin Park and Jongho Park},
  year          = {2025},
  url           = {https://arxiv.org/abs/2507.00726},
  eprint        = {2507.00726},
  archiveprefix = {arXiv},
  primaryclass  = {cs.AI},
}

@inproceedings{iavich:2024:detecting-fair-play-violations-chess-neural-networks,
  title         = {Detecting Fair Play Violations in Chess Using Neural Networks},
  author        = {Iavich, Maksim and Kevanishvili, Zura},
  year          = {2024},
  booktitle     = {Proceedings of 29th International Conference Information Society and University Studies},
  publisher     = {CEUR-WS.org},
  series        = {{CEUR} Workshop Proceedings},
  volume        = {3341},
  pages         = {121--127},
  url           = {https://ceur-ws.org/Vol-3885/paper13.pdf},
}

@inproceedings{jakub:2026:chessformer-modeling-human-decision-making-chess,
  title         = {ChessFormer - Modeling Human Decision Making in Chess},
  author        = {Zeman, Jakub and {\v{C}}epek, Miroslav},
  year          = {2026},
  booktitle     = {Modeling Decisions for Artificial Intelligence},
  publisher     = {Springer Nature Switzerland},
  address       = {Cham},
  pages         = {42--53},
  isbn          = {978-3-032-00891-6},
  editor        = {Torra, Vicen{\c{c}} and Narukawa, Yasuo and Domingo-Ferrer, Josep},
  abstract      = {ChessFormer introduces a novel searchless chess engine leveraging transformer architecture to approximate human decision-making in chess. Trained on a vast dataset of 3 billion chess positions, our model learns its entire decision-making process directly from training data. Evaluations show an improvement in human move-matching accuracy over prior models in high-Elo ranges and the model's ability to distinguish between human and algorithmic decision-making, offering potential applications in chess analysis or cheat detection.},
}

@article{jenner:2024:evidence-lookahead-chess-neural-network,
  title         = {Evidence of Learned Look-Ahead in a Chess-Playing Neural Network},
  author        = {Erik Jenner and Shreyas Kapur and Vasil Georgiev and Cameron Allen and Scott Emmons and Stuart Russell},
  year          = {2024},
  journal       = {CoRR},
  volume        = {abs/2406.00877},
  doi           = {10.48550/ARXIV.2406.00877},
  url           = {https://doi.org/10.48550/arXiv.2406.00877},
  eprinttype    = {arXiv},
  eprint        = {2406.00877},
}

@misc{jiang:2023:building-natural-language-chess-engine-pretraining-instruction-finetunine,
  title         = {Building a Natural Language Chess Engine with Pretraining and Instruction Fine-Tuning},
  author        = {Bowen Jiang},
  year          = {2023},
  url           = {https://web.stanford.edu/class/archive/cs/cs224n/cs224n.1234/final-reports/final-report-169466939.pdf},
  note          = {Stanford CS224N Custom Project, Winter 2023 (https://web.stanford.edu/class/archive/cs/cs224n/cs224n.1234/project.html)},
  abstract      = {Although pretrained large language models (LLMs) can generate convincing natural language about games like chess, they lack positional and contextual knowledge and as such are poor game-playing agents. In this project, I utilize language pretaining; instruction fine-tuning, an additional training regimen with chess-specific tasks presented in natural language; and chain-of-thought prompting, a natural language description of problem reasoning prepended to the answer of a problem, to improve the performance of LLMs at chess move generation (validity/legality and quality of moves). I show that fine-tuned GPT-2-XL, a 1.5B parameter LLM, performs favorably well at move generation compared to ChatGPT with few-shot learning; I also validate the additional benefits of chain-of-thought prompting compared to plain prompts in ChatGPT while highlighting tradeoffs between the quality of natural language and the quality of chess when more verbose prompts are used in the smaller GPT-2-XL.},
}

@misc{kapla:2025:generalized-multi-linear-models-dimension-reduction-tensor-valued-predictors,
  title         = {Generalized Multi-Linear Models for Sufficient Dimension Reduction on Tensor Valued Predictors},
  author        = {Daniel Kapla and Efstathia Bura},
  year          = {2025},
  url           = {https://arxiv.org/abs/2502.20216},
  eprint        = {2502.20216},
  archiveprefix = {arXiv},
  primaryclass  = {stat.ME},
}

@inproceedings{karn:2024:personalized-recommendation-chess-puzzles,
  title         = {Personalized recommendation of chess puzzles},
  author        = {Karn, Aryan and Biradar, Chinmay Anil and Puranik, Aryan and Kireeti, Attili Krishna and Jayashree, R},
  year          = {2024},
  booktitle     = {Computer Science Engineering: Proceedings of the 1st International Conference on Computing and Intelligent Information Systems (ICCIIS 2024), Bangalore, India, 19-20th April, 2024 Volume 1},
  pages         = {29},
  organization  = {CRC Press},
}

@inproceedings{karvonen:2024:dictionary-learning-board-games,
  title         = {Measuring Progress in Dictionary Learning for Language Model Interpretability with Board Game Models},
  author        = {Adam Karvonen and Benjamin Wright and Can Rager and Rico Angell and Jannik Brinkmann and Logan Riggs Smith and Claudio Mayrink Verdun and David Bau and Samuel Marks},
  year          = {2024},
  booktitle     = {ICML 2024 Workshop on Mechanistic Interpretability},
  url           = {https://openreview.net/forum?id=qzsDKwGJyB},
}

@article{karvonen:2024:emergent-world-models-latent-variable-estimation-chess-playing,
  title         = {Emergent World Models and Latent Variable Estimation in Chess-Playing Language Models},
  author        = {Adam Karvonen},
  year          = {2024},
  journal       = {CoRR},
  volume        = {abs/2403.15498},
  doi           = {10.48550/ARXIV.2403.15498},
  url           = {https://doi.org/10.48550/arXiv.2403.15498},
  eprinttype    = {arXiv},
  eprint        = {2403.15498},
}

@thesis{keusch:2025:binary-matching-android-ios-apps,
  title         = {Binary Matching of Android and iOS Apps},
  author        = {Keusch, Alexander},
  year          = {2025},
  doi           = {https://doi.org/10.34726/hss.2025.128603},
  url           = {http://hdl.handle.net/20.500.12708/217584},
  school        = {Technische Universit\"{a}t Wien},
  supervisor    = {Lindorfer, Martina and Bleier, Jakob},
  type          = {Diploma Thesis},
  keyword       = {Mobile Security; Android; iOS; Binary Analysis; Cross-Platform Analysis},
  abstract      = {Android and iOS are the two dominant mobile operating systems in the rapidly expanding smartphone market, serving billions of users worldwide. Both platforms feature extensive app stores with millions of applications available for download. While security measures are in place to prevent the distribution of malicious or vulnerable apps, instances of malware have still been discovered in both stores. These incidents highlight a significant security risk that threatens user privacy and highlights the urgent need for advanced research in detecting malicious code and security vulnerabilities in mobile applications. As a step toward addressing this challenge, this thesis explores the feasibility of using binary similarity detection techniques to identify similarities between Android and iOS applications. To achieve this, we designed and implemented a novel analysis pipeline specifically tailored for comparing Android apps (compiled into binary OAT files) with iOS binaries. This pipeline enables the automatic identification of matches between corresponding applications across both platforms. The pipeline comprises several key stages, including preparing the apps and their third-party libraries for binary analysis, disassembling the binaries using both IDA Pro and Ghidra to account for potential variations introduced by different disassemblers, and conducting similarity analysis on the disassembly results. To assess the effectiveness of our pipeline, we conducted a comprehensive analysis on a dataset of 100 cross-platform apps. Our findings indicate that current binary similarity analysis methods have limitations in directly identifying cross-platform similarities between applications. However, we demonstrated that incorporating third-party libraries into the analysis significantly enhances similarity detection and can help to provide meaningful insights. This highlights the crucial role that third-party libraries play in cross-platform app analysis. Additionally, we found that the choice of disassembler has a significant impact on analysis results. Notably, no single disassembler proved to be clearly superior, as both exhibited their own strengths and limitations. Ultimately, this study offers valuable insights into the challenges and potential of cross-platform binary app analysis using traditional binary diffing techniques, laying a strong foundation for future research in this evolving field.},
}

@online{knopps:collaborative-vs-individual-chess-puzzle-solving,
  title         = {Collaborative versus Individual Chess Puzzle Solving},
  author        = {Knopps, Alex},
  year          = {2025},
  month         = {Feb},
  url           = {https://www.chessable.com/blog/collaborative-versus-individual-chess-puzzle-solving/},
  urldate       = {2025-03-14},
}

@inproceedings{kolasani:2025:llm-chess-benchmarking-reasoning-instruction-following-llms-through-chess,
  title         = {LLM CHESS: Benchmarking Reasoning and Instruction-Following in LLMs through Chess},
  author        = {Kolasani, Sai and Saplin, Maxim and Crispino, Nicholas and Montgomery, Kyle and Davis, Jared and Zaharia, Matei and Wang, Chi and Wang, Chenguang},
  year          = {2025},
  booktitle     = {Workshop on Foundations of Reasoning in Language Models at NeurIPS 2025},
  github        = {https://github.com/LLM-CHESS/llm\_chess\_minimal, https://github.com/maxim-saplin/llm\_chess/},
  website       = {https://maxim-saplin.github.io/llm\_chess/},
  abstract      = {We introduce LLM CHESS, an evaluation framework designed to probe the generalization of reasoning and instruction-following abilities in large language models (LLMs) through extended agentic interaction in the domain of chess. We rank over 50 open and closed source models by playing against a random opponent using a range of behavioral metrics, including win and loss rates, move quality, move legality, hallucinated actions, and game duration. For a subset of models, we derive an Elo estimate by playing against a chess engine with variably configured skill. Despite the simplicity of the instruction-following task and the weakness of the opponent, many state-of-the-art models struggle to complete games or achieve consistent wins. Similar to other benchmarks on complex reasoning tasks, our experiments reveal a clear separation between reasoning and non-reasoning models. However, unlike existing static benchmarks, the stochastic and dynamic nature of LLM CHESS uniquely reduces overfitting and memorization while preventing benchmark saturation. To support future work on evaluating reasoning and instruction-following in LLMs, we release our experimental framework, a public leaderboard, and a dataset of associated games. Our code is available athttps://github.com/LLM-CHESS/llm\_chess.},
}

@inproceedings{krishnan:2022:automatic-synthesis-interpretable-chess-tactics,
  title         = {Towards the automatic synthesis of interpretable chess tactics},
  author        = {Krishnan, Abhijeet and Martens, Chris},
  year          = {2022},
  month         = {03},
  booktitle     = {Proceedings of the Explainable Agency in Artificial Intelligence Workshop, 36th AAAI Conference on Artificial Intelligence},
  publisher     = {American Association of Artificial Intelligence},
  pages         = {91--97},
}

@inproceedings{krishnan:2022:synthesizing-interpretable-chess-tactics-player-games,
  title         = {Synthesizing interpretable chess tactics from player games},
  author        = {Krishnan, Abhijeet and Martens, Chris},
  year          = {2022},
  month         = {10},
  booktitle     = {Proceedings of the Workshop on Artificial Intelligence for Strategy Games (SG) and Esports Analytics (EA), 18th AAAI Conference on Artificial Intelligence and Interactive Digital Entertainment},
  publisher     = {American Association for Artificial Intelligence},
}

@misc{kruger:2025:synthetic-data-generation-screen-time-app-usage,
  title         = {Synthetic Data Generation for Screen Time and App Usage},
  author        = {Gustavo Kruger and Nikhil Sachdeva and Michael Sobolev},
  year          = {2025},
  url           = {https://arxiv.org/abs/2509.13892},
  eprint        = {2509.13892},
  archiveprefix = {arXiv},
  primaryclass  = {cs.HC},
  abstract      = {Smartphone usage data can provide valuable insights for understanding interaction with technology and human behavior. However, collecting large-scale, in-the-wild smartphone usage logs is challenging due to high costs, privacy concerns, under representative user samples and biases like non-response that can skew results. These challenges call for exploring alternative approaches to obtain smartphone usage datasets. In this context, large language models (LLMs) such as Open AI's ChatGPT present a novel approach for synthetic smartphone usage data generation, addressing limitations of real-world data collection. We describe a case study on how four prompt strategies influenced the quality of generated smartphone usage data. We contribute with insights on prompt design and measures of data quality, reporting a prompting strategy comparison combining two factors, prompt level of detail (describing a user persona, describing the expected results characteristics) and seed data inclusion (with versus without an initial real usage example). Our findings suggest that using LLMs to generate structured and behaviorally plausible smartphone use datasets is feasible for some use cases, especially when using detailed prompts. Challenges remain in capturing diverse nuances of human behavioral patterns in a single synthetic dataset, and evaluating tradeoffs between data fidelity and diversity, suggesting the need for use-case-specific evaluation metrics and future research with more diverse seed data and different LLM models.},
  data          = {https://osf.io/u2h3d/},
}

@misc{kuboki:2025:policies-multiple-skill-levels-better-strength-estimation-games,
  title         = {Policies of Multiple Skill Levels for Better Strength Estimation in Games},
  author        = {Kyota Kuboki and Tatsuyoshi Ogawa and Chu-Hsuan Hsueh and Shi-Jim Yen and Kokolo Ikeda},
  year          = {2025},
  url           = {https://arxiv.org/abs/2505.00279},
  eprint        = {2505.00279},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG},
}

@inproceedings{kumar:2025:optimizing-ai-driven-chess-bots-strategies-balancing-performance-accuracy-computational-efficiency,
  title         = {Optimizing AI-Driven Chess Bots: Strategies for Balancing Performance, Accuracy, and Computational Efficiency},
  author        = {D, Girish Kumar and Shiva Kumar, K S and Rama Prasad, P Pani and Jalade, Sangamesh C and Praveen Kumar, C T M and D C, Subhashree},
  year          = {2025},
  booktitle     = {2025 4th International Conference on Distributed Computing and Electrical Circuits and Electronics (ICDCECE)},
  pages         = {1--5},
  doi           = {10.1109/ICDCECE65353.2025.11035271},
  keywords      = {Accuracy;Monte Carlo methods;Computational modeling;Decision making;Reinforcement learning;Transformers;Computational efficiency;Artificial intelligence;Optimization;Engines;AI chess engine;reinforcement learning;monte carlo tree search (MCTS);deep learning;transformer-based models;proximal policy optimization (PPO)},
}

@article{kuperwajs:2024:learning-from-rewards-social-information-strategic-behavior,
  title         = {Learning from rewards and social information in naturalistic strategic behavior},
  author        = {Kuperwajs, Ionatan and van Opheusden, Bas and Russek, Evan and Griffiths, Tom},
  year          = {2024},
  month         = {Aug},
  publisher     = {PsyArXiv},
  doi           = {10.31234/osf.io/d8zje},
  url           = {osf.io/preprints/psyarxiv/d8zje},
}

@article{kuperwajs:2025:exploring-resource-rational-planning-time-pressure-online-chess,
  title         = {Exploring resource-rational planning under time pressure in online chess},
  author        = {Kuperwajs, Ionatan and Russek, Evan and Schut, Lisa and Sagiv, Yotam and Mattar, Marcelo G and Ma, Wei Ji and Griffiths, Tom},
  year          = {2025},
  journal       = {Proceedings of the Annual Meeting of the Cognitive Science Society},
  volume        = {47},
  url           = {https://escholarship.org/uc/item/75b4m9c2},
  abstract      = {Human planning is incredibly efficient. Even in complex situations with many possible courses of action, people are able to make good decisions. Recent proposals suggest that a primary contributor to this efficiency is the intelligent use of cognitive resources, but how people allocate these resources under time constraints is not fully understood. In this work, we conduct a resource-rational analysis of planning in a large data set of online chess games. We first demonstrate that players spent more time thinking when they had more time to do so, and that this effect was especially prevalent when computation was more valuable. Then, we show that additional time spent planning resulted in better selected moves when one existed, and compare between signals of general and immediate time pressure. Finally, we highlight the role of expertise in this setting. Our results provide evidence that people make resource-rational choices when planning under time pressure.},
}

@inproceedings{laarhoven:2022:transparent-cheat-detection-online-chess,
  title         = {Towards Transparent Cheat Detection in Online Chess: An Application of Human and Computer Decision-Making Preferences},
  author        = {Thijs Laarhoven and Aditya Ponukumati},
  year          = {2022},
  booktitle     = {Computers and Games - International Conference, {CG} 2022, Virtual Event, November 22-24, 2022, Revised Selected Papers},
  publisher     = {Springer},
  series        = {Lecture Notes in Computer Science},
  volume        = {13865},
  pages         = {163--180},
  doi           = {10.1007/978-3-031-34017-8\_14},
  url           = {https://doi.org/10.1007/978-3-031-34017-8\_14},
  editor        = {Cameron Browne and Akihiro Kishimoto and Jonathan Schaeffer},
}

@inproceedings{le-louedec:2019:chess-player-attention-prediction,
  title         = {Deep learning investigation for chess player attention prediction using eye-tracking and game data},
  author        = {Justin Le Louedec and Thomas Guntz and James L. Crowley and Dominique Vaufreydaz},
  year          = {2019},
  booktitle     = {Proceedings of the 11th {ACM} Symposium on Eye Tracking Research {\&} Applications, {ETRA} 2019, Denver , CO, USA, June 25-28, 2019},
  publisher     = {{ACM}},
  pages         = {1:1--1:9},
  doi           = {10.1145/3314111.3319827},
  url           = {https://doi.org/10.1145/3314111.3319827},
  editor        = {Krzysztof Krejtz and Bonita Sharif},
}

@inproceedings{lemes:2025:computer-vision-chess-game-automation,
  title         = {Computer Vision for Chess Game Automation},
  author        = {Leme{\v{s}}, Samir and Koli{\'{c}}, Mirhad and Tabak, Edin},
  year          = {2025},
  booktitle     = {New Technologies, Development and Application VIII},
  publisher     = {Springer Nature Switzerland},
  address       = {Cham},
  pages         = {21--30},
  isbn          = {978-3-031-95197-8},
  editor        = {Karabegovi{\'{c}}, Isak and Kova{\v{c}}evi{\'{c}}, Ahmed and Mand{\v{z}}uka, Sadko},
  abstract      = {In the modern age of computing and technology, computer vision has become a key aspect of numerous innovations and solutions that make everyday life easier. Object recognition in images is one area where computer vision can contribute to significant improvements. Playing chess, one of the oldest and most challenging intellectual games requires concentration and tactical thinking. In computer vision, automating the recognition of chessboards and figures can contribute to developing advanced chess applications, help users analyse games, or even enable a game with a computer based on real-world chess setups. This paper describes how the system for recognising chessboards and figures using computer vision techniques was developed and implemented. Through analysing existing methods, designing a new algorithm, and experimental evaluation, the goal is to create an accurate and efficient system that can recognise chess positions and individual figures based on images.},
}

@thesis{lennart:2024:few-shot-embedding-learning-approach-predicting-behvaior-individual-chess-players,
  title         = {A Few-Shot Embedding Learning Approach for Predicting the Behavior of Individual Chess Players},
  author        = {August, Lennart},
  year          = {2024},
  url           = {https://fse.studenttheses.ub.rug.nl/id/eprint/34065},
  institution   = {University of Groningen},
  type          = {Bachelor's thesis},
  supervisor    = {Abreu, Steven and Jaeger, Herbert},
  abstract      = {This study presents a few-shot embedding learning approach to predict the behavior of individual chess players, based on only 100 games. Traditional models have relied on extensive datasets, often requiring thousands of games to achieve accurate move predictions. In contrast, our method leverages a limited number of games to generate dense vector representations, or embeddings, that capture a player's unique style. We trained a neural network to create these embeddings and used them to predict subsequent moves. Our results indicate that the embedding model performs well across various player sets and can accurately identify players even at scale among a great player population, picking out players with 84\% accuracy from among 100k candidates. There are indications that including information on the clock situation during the game improves the embedding process, although our findings are inconclusive. Despite these limitations, our approach shows promise in making personalized chess training more accessible and highlights the potential for embedding learning in human-centered AI applications. Future work will aim to refine both the embedding and move prediction models and explore its application in other domains.},
}

@thesis{lequenne:2025:characterizing-chess-player-styles-neural-networks-embeddings-stockfish,
  title         = {Characterizing Chess Player Styles with Neural Network Embeddings from Stockfish},
  author        = {Lequenne, Victor},
  year          = {2025},
  url           = {https://hdl.handle.net/2078.2/42841},
  institution   = {\'{E}cole polytechnique de Louvain, Universit\'{e} catholique de Louvain},
  type          = {Master's thesis},
  supervisor    = {Delvenne, Jean-Charles},
  keywords      = {neural network, chess, PCA, t-SNE, MDS, Kmeans, kde},
  abstract      = {This thesis investigates how neural networks can be used to analyze and compare chess player styles. Using the last layer of Stockfish's neural network, we process positions from historical World Chess Championships (1886–2024), as well as the 2024 World Blitz and Rapid Championships. We apply dimensionality reduction (PCA, t-SNE, MDS) and clustering (K-means) to build style-based player maps, measuring similarities through Jensen–Shannon divergence. Results show consistent stylistic signatures for some players--such as Firouzja and Dubov but may fail with others e.g. Nepomniachtchi. We also confirmed the evolution of chess player's still accros time. Though the approach is promising, limitations remain, especially in data size and the influence of forced lines. Still, this work lays a foundation for future stylometry studies and applications in AI driven chess training},
}

@inproceedings{liang:2025:stacking-based-ensemble-approach-predicting-chess-puzzle-difficulty,
  title         = {A Stacking-Based Ensemble Approach for Predicting Chess Puzzle Difficulty},
  author        = {Alan Liang and Cenzhi Liu and Kai Wang and Ethan Liu},
  year          = {2025},
  booktitle     = {Proceedings of the 20th Conference on Computer Science and Intelligence Systems (FedCSIS)},
  publisher     = {IEEE},
  series        = {Annals of Computer Science and Information Systems},
  volume        = {43},
  pages         = {819--824},
  doi           = {10.15439/2025F1698},
  url           = {http://dx.doi.org/10.15439/2025F1698},
  editor        = {Marek Bolanowski and Maria Ganzha and Leszek Maciaszek and Marcin Paprzycki and Dominik \'{S}l\k{e}zak},
  abstract      = {FedCSIS 2025 competition is to predict the difficulty of chess puzzles, we present a structured multi-stage regression pipeline developed for the FedCSIS 2025 Challenge. The approach consists of three stages: (i) four Elo-banded base models trained on separate rating ranges to capture localized difficulty semantics and mitigate bias in imbalanced datasets; (ii) a feature-level stacking ensemble combining base predictions with structural attributes, such as success probabilities, failure distributions, and solution length, to enhance cross-band generalization; and (iii) a lightweight post-hoc residual correction to reduce systematic prediction biases. Additionally, an uncertainty-aware mask-based evaluation is introduced to identify the 10\% most challenging puzzles for extended scoring. Our method achieved competitive results, ranking 7th in the final leaderboard, while maintaining low computational cost. These findings demonstrate that lightweight, interpretable models, when combined with structural reasoning and uncertainty estimation, can rival more complex deep-learning approaches. This study highlights the potential of structured machine learning pipelines for scalable, human-centric chess puzzle analytics.},
}

@misc{liu:2025:chessarena-chess-testbed-evaluating-strategic-reasoning-capabilities-large-language-models,
  title         = {ChessArena: A Chess Testbed for Evaluating Strategic Reasoning Capabilities of Large Language Models},
  author        = {Jincheng Liu and Sijun He and Jingjing Wu and Xiangsen Wang and Yang Chen and Zhaoqi Kuang and Siqi Bao and Yuan Yao},
  year          = {2025},
  url           = {https://arxiv.org/abs/2509.24239},
  eprint        = {2509.24239},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG},
  abstract      = {Recent large language models (LLMs) have shown strong reasoning capabilities. However, a critical question remains: do these models possess genuine reasoning skills particularly complex strategic reasoning or are they primarily excelling at sophisticated pattern recognition within their training data? To address this question, this paper presents a chess testbed, ChessArena, to evaluate the strategic reasoning capabilities of LLMs. Chess requires complex strategic reasoning capabilities including long-term planning, strict rule comprehension, and multi-turn conversation memorization. Specifically, ChessArena is a competitive framework where LLMs play against each other, under four different play modes. The testbed is equipped with a ranking algorithm and a leaderboard. The testbed can also evaluate fine-grained capabilities including basic understanding, move selection, and puzzle solving. Over 13 LLMs with different modes are evaluated in ChessArena, playing over 800 games. The results reveal significant shortcomings in current LLMs: no model can beat Maia-1100 (a chess engine at human amateur level), while some even failed to defeat a random player that selects moves arbitrarily. We also present a strong baseline to the testbed: our fine-tuned Qwen3-8B substantially improved performance, approaching much larger state-of-the-art reasoning models.},
}

@inproceedings{liu:2025:hybrid-boosting-multi-modal-fusion-chess-puzzle-difficulty-prediction,
  title         = {Hybrid Boosting and Multi-Modal Fusion for Chess Puzzle Difficulty Prediction},
  author        = {Ming Liu and Junye Wang and Yinghan Hu and Xiaolin Yang and Defu Lin},
  year          = {2025},
  booktitle     = {Proceedings of the 20th Conference on Computer Science and Intelligence Systems (FedCSIS)},
  publisher     = {IEEE},
  series        = {Annals of Computer Science and Information Systems},
  volume        = {43},
  pages         = {825--830},
  doi           = {10.15439/2025F3675},
  url           = {http://dx.doi.org/10.15439/2025F3675},
  editor        = {Marek Bolanowski and Maria Ganzha and Leszek Maciaszek and Marcin Paprzycki and Dominik \'{S}l\k{e}zak},
  abstract      = {The FedCSIS 2025 Challenge on Predicting Chess Puzzle Difficulty tasked participants with estimating puzzle ratings directly from board states and solution sequences, without relying on human solver statistics. We propose a three-stage hybrid framework integrating gradient-boosting regressors, a multi-modal neural network, and an XGBoost stacking ensemble. The boosting stage modeled handcrafted structural features derived from FEN and engine metadata, while the multi-modal network jointly learned from structured features and image-rendered chessboards to capture positional and tactical patterns. The residual-based stacking stage explicitly modeled prediction errors to correct systematic biases and enhance performance, particularly for high-difficulty puzzles. Our method achieved a competitive performance, ranking 7th in the preliminary stage and 8th in the final leaderboard. These results demonstrate that combining interpretable boosting models with visual-tactical deep representations and meta-learning provides a robust and computationally efficient alternative to large-scale transformer-based approaches.},
}

@article{maharaj:2022:gambits-theory-evidence,
  title         = {Gambits: Theory and evidence},
  author        = {Maharaj, Shiva and Polson, Nick and Turk, Christian},
  year          = {2022},
  journal       = {Applied Stochastic Models in Business and Industry},
  volume        = {38},
  number        = {4},
  pages         = {572--589},
  doi           = {https://doi.org/10.1002/asmb.2684},
  url           = {https://onlinelibrary.wiley.com/doi/abs/10.1002/asmb.2684},
  keywords      = {adversarial risk analysis, AI, AlphaZero, behavioral economics, behavioral game theory, behavioral science, chess gambits, decision-making, deep learning, neural network, Q learning, rationality, skewness preference, Stafford Gambit, Stockfish 14},
  eprint        = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/asmb.2684},
  abstract      = {Abstract Gambits are central to human decision-making. Our goal is to provide a theory of Gambits. A Gambit is a combination of psychological and technical factors designed to disrupt predictable play. Chess provides an environment to study gambits and behavioral game theory. Our theory is based on the Bellman optimality path for sequential decision-making. This allows us to calculate the Q\$\$ Q \$\$-values of a Gambit where material (usually a pawn) is sacrificed for dynamic play. On the empirical side, we study the effectiveness of a number of popular chess Gambits. This is a natural setting as chess Gambits require a sequential assessment of a set of moves (a.k.a. policy) after the Gambit has been accepted. Our analysis uses Stockfish 14.1 to calculate the optimal Bellman Q\$\$ Q \$\$-values, which fundamentally measures if a position is winning or losing. To test whether Bellman's equation holds in play, we estimate the transition probabilities to the next board state via a database of expert human play. This then allows us to test whether the Gambiteer is following the optimal path in his decision-making. Our methodology is applied to the popular Stafford and reverse Stafford (a.k.a. Boden–Kieretsky–Morphy) Gambit and other common ones including the Smith–Morra, Goring, Danish and Halloween Gambits. We build on research in human decision-making by proving an irrational skewness preference within agents in chess. We conclude with directions for future research.},
}

@inproceedings{makovec:2023:merging-neural-networks-traditional-evaluations-crazyhouse,
  title         = {Merging Neural Networks with Traditional Evaluations in Crazyhouse},
  author        = {Makovec, Anei and Pirker, Johanna and Guid, Matej},
  year          = {2023},
  booktitle     = {Advances in Computer Games: 18th International Conference, ACG 2023, Virtual Event, November 28–30, 2023, Revised Selected Papers},
  location      = {Siegen, Germany},
  publisher     = {Springer-Verlag},
  address       = {Berlin, Heidelberg},
  pages         = {15–25},
  doi           = {10.1007/978-3-031-54968-7_2},
  isbn          = {978-3-031-54967-0},
  url           = {https://doi.org/10.1007/978-3-031-54968-7_2},
  abstract      = {In the intricate landscape of game-playing algorithms, Crazyhouse stands as a complex variant of chess where captured pieces are reintroduced, presenting unique evaluation challenges. This paper explores a hybrid approach that combines traditional evaluation functions with neural network-based evaluations, seeking an optimal balance in performance. Through rigorous experimentation, including self-play, matchups against a variant of the renowned program, Go-deep experiments, and score deviations, we present compelling evidence for the effectiveness of a weighted sum of both evaluations. Remarkably, in our experiments, the combination of 75\% neural network and 25\% traditional evaluation consistently emerged as the most effective choice. Furthermore, we introduce the use of Best-Change rates, which have previously been associated with evaluation quality, in the context of Monte Carlo tree search-based algorithms.},
  numpages      = {11},
  keywords      = {Crazyhouse, chess variants, heuristic evaluation functions, neural networks, Best-Change rates, Monte Carlo tree search},
}

@inproceedings{maksim:2025:neural-network-approach-chess-cheat-detectoin,
  title         = {A Neural Network Approach to Chess Cheat Detection},
  author        = {Iavich, Maksim and Kevanishvili, Zura},
  year          = {2025},
  booktitle     = {Information and Software Technologies},
  publisher     = {Springer Nature Switzerland},
  address       = {Cham},
  pages         = {131--145},
  isbn          = {978-3-031-84263-4},
  editor        = {Lopata, Audrius and Gudonien{\.{e}}, Daina and Butkien{\.{e}}, Rita and {\v{C}}eponis, Jonas},
  abstract      = {With the development of chess engines, cheating online has never been easier, resulting in a need for more robust and accurate detection systems. This paper presents a novel approach to chess cheater detection that combines conventional chess engines and neural networks to help identify which games are authentically played by humans and which show signs of extraneous intervention. By utilizing Stockfish to measure centipawn loss and its mathematical derivatives, we can measure deviations from typical computer-generated moves much like in conventional anti-cheat systems. Additionally, the neural network Maia, designed specifically to mimic human play, transmutes centipawn loss data to highlight deviations from human style. This dual-measurement system addresses the limitations of the given traditional anti-cheat systems, which face the issue of distinguishing between strong human players and those using engines. The collected metadata is analyzed using a sequential neural network, which identifies patterns of fair play violation. Our approach offers a robust solution for maintaining the integrity of online chess by accurately detecting and preventing cheating.},
}

@article{martin:2025:re-evaluating-metamorphic-testing-chess-engines-replication-study,
  title         = {Re-evaluating metamorphic testing of chess engines: A replication study},
  author        = {Axel Martin and Djamel Eddine Khelladi and Th\'{e}o Matricon and Mathieu Acher},
  year          = {2025},
  journal       = {Information and Software Technology},
  pages         = {107679},
  doi           = {https://doi.org/10.1016/j.infsof.2025.107679},
  issn          = {0950-5849},
  url           = {https://www.sciencedirect.com/science/article/pii/S0950584925000187},
  keywords      = {Reproducibility, Replicability, Metamorphic testing, Chess engines},
  abstract      = {Context: This study aims to confirm, replicate and extend the findings of a previous article entitled ''Metamorphic Testing of Chess Engines'' that reported inconsistencies in the analyses provided by Stockfish, the most widely used chess engine, for transformed chess positions that are fundamentally identical. Initial findings, under conditions strictly identical to those of the original study, corroborate the reported inconsistencies. Objective: However, the original article considers a specific dataset (including randomly generated chess positions, end-games, or checkmate problems) and very low analysis depth (10 plies11A ply refers to a single turn taken by one player in a game. Two plies, one from each player, together constitute a complete move., corresponding to 5 moves). These decisions pose threats that limit generalizability of the results, but also their practical usefulness both for chess players and maintainers of Stockfish. Thus, we replicate the original study. Methods: We consider this time (1) positions derived from actual chess games, (2) analyses at appropriate and larger depths, and (3) different versions of Stockfish. We conduct novel experiments on thousands of positions, employing significantly deeper searches. Results: The replication results show that the Stockfish chess engines demonstrate significantly greater consistency in its evaluations. The metamorphic relations are not as effective as in the original article, especially on realistic chess positions. We also demonstrate that, for any given position, there exists a depth threshold beyond which further increases in depth do not result in any evaluation differences for the studied metamorphic relations. We perform an in-depth analysis to identify and clarify the implementation reasons behind Stockfish's inconsistencies when dealing with transformed positions. Conclusion: A first concrete result is thus that metamorphic testing of chess engines is not yet an effective technique for finding faults of Stockfish. Another result is the lessons learned through this replication effort: metamorphic relations must be verified in the context of the domain's specificities; without such contextual validation, they may lead to misleading or irrelevant conclusions; changes in parameters and input dataset can drastically alter the effectiveness of a testing method.},
}

@inproceedings{mcilroy-young:2020:aligning-superhuman-ai-human-behavior,
  title         = {Aligning Superhuman {AI} with Human Behavior: Chess as a Model System},
  author        = {Reid McIlroy{-}Young and Siddhartha Sen and Jon M. Kleinberg and Ashton Anderson},
  year          = {2020},
  booktitle     = {{KDD} '20: The 26th {ACM} {SIGKDD} Conference on Knowledge Discovery and Data Mining, Virtual Event, CA, USA, August 23-27, 2020},
  publisher     = {{ACM}},
  pages         = {1677--1687},
  doi           = {10.1145/3394486.3403219},
  url           = {https://doi.org/10.1145/3394486.3403219},
  editor        = {Rajesh Gupta and Yan Liu and Jiliang Tang and B. Aditya Prakash},
}

@article{mcilroy-young:2020:learning-personalized-models-human-behavior-chess,
  title         = {Learning Personalized Models of Human Behavior in Chess},
  author        = {Reid McIlroy{-}Young and Russell Wang and Siddhartha Sen and Jon M. Kleinberg and Ashton Anderson},
  year          = {2020},
  journal       = {CoRR},
  volume        = {abs/2008.10086},
  url           = {https://arxiv.org/abs/2008.10086},
  eprinttype    = {arXiv},
  eprint        = {2008.10086},
}

@inproceedings{mcilroy-young:2021:chess-stylometry,
  title         = {Detecting Individual Decision-Making Style: Exploring Behavioral Stylometry in Chess},
  author        = {Reid McIlroy{-}Young and Yu Wang and Siddhartha Sen and Jon M. Kleinberg and Ashton Anderson},
  year          = {2021},
  booktitle     = {Advances in Neural Information Processing Systems 34: Annual Conference on Neural Information Processing Systems 2021, NeurIPS 2021, December 6-14, 2021, virtual},
  pages         = {24482--24497},
  url           = {https://proceedings.neurips.cc/paper/2021/hash/ccf8111910291ba472b385e9c5f59099-Abstract.html},
  editor        = {Marc'Aurelio Ranzato and Alina Beygelzimer and Yann N. Dauphin and Percy Liang and Jennifer Wortman Vaughan},
}

@inproceedings{mcilroy-young:2022:learning-models-individual-behavior-chess,
  title         = {Learning Models of Individual Behavior in Chess},
  author        = {Reid McIlroy{-}Young and Russell Wang and Siddhartha Sen and Jon M. Kleinberg and Ashton Anderson},
  year          = {2022},
  booktitle     = {{KDD} '22: The 28th {ACM} {SIGKDD} Conference on Knowledge Discovery and Data Mining, Washington, DC, USA, August 14 - 18, 2022},
  publisher     = {{ACM}},
  pages         = {1253--1263},
  doi           = {10.1145/3534678.3539367},
  url           = {https://doi.org/10.1145/3534678.3539367},
  editor        = {Aidong Zhang and Huzefa Rangwala},
}

@misc{meireles:2025:practice-structure-predicts-skill-growth-online-chess-behavioral-modeling-approach,
  title         = {Practice Structure Predicts Skill Growth in Online Chess: A Behavioral Modeling Approach},
  author        = {Meireles, Lu\'{\i}s and Mendes-Neves, Tiago and Moreira, Jo\~{a}o},
  year          = {2025},
  month         = {10},
  doi           = {10.21203/rs.3.rs-7789635/v1},
  url           = {https://www.researchsquare.com/article/rs-7789635/v1},
  abstract      = {Skill acquisition is central to developing expertise, yet the behavioral mechanisms that separate more successful learners from less successful ones remain poorly understood. Using a large naturalistic dataset of about one million online chess games played by ~\hspace{0.167em}820 individuals over three years (2013–2015), we built an interpretable machine learning model to classify learners based only on behavioral features. Learners were labeled as ``fast learners'' or ``not fast learners'' based on normalized monthly Elo progression, adjusted for both starting rating and the increasing difficulty of improving at higher levels. We engineered time-sensitive features across four behavioral dimensions: practice structure, challenge level, strategic exploration (measured via move-sequence entropy), and tactical efficiency (the number of rounds needed to reach a 70\% win probability in games eventually won). A logistic regression model trained on the five strongest predictors - optimal challenge steady magnitude, optimal challenge late slope, entropy steady magnitude, optimal challenge mean, and tactical efficiency mean - achieved an F1 of 0.68 and an AUC of 0.78. Coefficients showed that average tactical efficiency was a strong predictor of fast learning, whereas the role of challenge-level features was less clear. To explore this, we fitted a linear regression with average tactical efficiency (as a proxy for expertise) as the dependent variable. This model explained 53\% of the variance (R\ensuremath{^2} = 0.53, RMSE\hspace{0.167em}=\hspace{0.167em}0.05) and revealed optimal challenge as the strongest predictor. This suggests that well-calibrated challenge levels are key to differences in chess performance.},
}

@misc{meszaros:2025:out-of-distribution-tests-reveal-compositionality-chess-transformers,
  title         = {Out-of-distribution Tests Reveal Compositionality in Chess Transformers},
  author        = {Anna M\'{e}sz\'{a}ros and Patrik Reizinger and Ferenc Husz\'{a}r},
  year          = {2025},
  url           = {https://arxiv.org/abs/2510.20783},
  eprint        = {2510.20783},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG},
  abstract      = {Chess is a canonical example of a task that requires rigorous reasoning and long-term planning. Modern decision Transformers - trained similarly to LLMs - are able to learn competent gameplay, but it is unclear to what extent they truly capture the rules of chess. To investigate this, we train a 270M parameter chess Transformer and test it on out-of-distribution scenarios, designed to reveal failures of systematic generalization. Our analysis shows that Transformers exhibit compositional generalization, as evidenced by strong rule extrapolation: they adhere to fundamental syntactic rules of the game by consistently choosing valid moves even in situations very different from the training data. Moreover, they also generate high-quality moves for OOD puzzles. In a more challenging test, we evaluate the models on variants including Chess960 (Fischer Random Chess) - a variant of chess where starting positions of pieces are randomized. We found that while the model exhibits basic strategy adaptation, they are inferior to symbolic AI algorithms that perform explicit search, but gap is smaller when playing against users on Lichess. Moreover, the training dynamics revealed that the model initially learns to move only its own pieces, suggesting an emergent compositional understanding of the game.},
  github        = {https://github.com/meszarosanna/ood\_chess},
}

@inproceedings{milosz:2024:predicting-puzzle-difficulty-transformers,
  title         = {{Predicting Chess Puzzle Difficulty with Transformers}},
  author        = {Szymon Mi{\l}osz and Pawe{\l} Kapusta},
  year          = {2024},
  booktitle     = {{IEEE} International Conference on Big Data, Big Data 2024, Washington DC, USA, December 15-18, 2024},
  publisher     = {{IEEE}},
}

@inproceedings{milosz:2025:pretraining-transformers-chess-puzzle-difficulty-prediction,
  title         = {Pretraining Transformers for Chess Puzzle Difficulty Prediction},
  author        = {Szymon Mi\l{}osz},
  year          = {2025},
  booktitle     = {Proceedings of the 20th Conference on Computer Science and Intelligence Systems (FedCSIS)},
  publisher     = {IEEE},
  series        = {Annals of Computer Science and Information Systems},
  volume        = {43},
  pages         = {831--835},
  doi           = {10.15439/2025F7603},
  url           = {http://dx.doi.org/10.15439/2025F7603},
  editor        = {Marek Bolanowski and Maria Ganzha and Leszek Maciaszek and Marcin Paprzycki and Dominik \'{S}l\k{e}zak},
  abstract      = {This paper presents our third-place solution for the FedCSIS 2025 Challenge: Predicting Chess Puzzle Difficulty - Second Edition. Building on our prior GlickFormer architecture, we develop a transformer-based approach featuring a novel multitask pretraining strategy that combines masked-square reconstruction with solution policy prediction. Our spatial-only architecture directly embeds solution moves, eliminating temporal modules, while integrating human-centric priors through Maia-2 engine solve-rate predictions. Evaluated on the Lichess puzzle corpus, our approach reduces validation MSE by 30.4\% compared to from-scratch training and achieves competitive results (test MSE: 55.9k) despite distribution shifts in the competition environment.\hspace{0.6em}},
}

@article{miranda:2025:observational-analysis-mistakes-chess-initiation-decision-trees,
  title         = {Observational Analysis of Mistakes in Chess Initiation, Using Decision Trees},
  author        = {Miranda, Jorge and Arana, Javier and Lapresa, Daniel and Anguera, M. Teresa},
  year          = {2025},
  journal       = {International Journal of Computer Science in Sport},
  volume        = {24},
  number        = {2},
  pages         = {45--60},
  doi           = {10.2478/ijcss-2025-0012},
  url           = {https://doi.org/10.2478/ijcss-2025-0012},
}

@article{mok:2021:time-online-digital-well-being,
  title         = {The Complementary Nature of Perceived and Actual Time Spent Online in Measuring Digital Well-being},
  author        = {Mok, Lillio and Anderson, Ashton},
  year          = {2021},
  month         = apr,
  journal       = {Proc. ACM Hum.-Comput. Interact.},
  publisher     = {Association for Computing Machinery},
  address       = {New York, NY, USA},
  volume        = {5},
  number        = {CSCW1},
  doi           = {10.1145/3449160},
  url           = {https://doi.org/10.1145/3449160},
  issue_date    = {April 2021},
  abstract      = {As online platforms become ubiquitous, there is growing concern that their use can potentially lead to negative outcomes in users' personal lives, such as disrupted sleep and impacted social relationships. A central question in the literature studying these problematic effects is whether they are associated with the amount of time users spend on online platforms. This is often addressed by either analyzing self-reported measures of time spent online, which are generally inaccurate, or using objective metrics derived from server logs or tracking software. Nonetheless, how the two types of time measures comparatively relate to problematic effects -- whether they complement or are redundant with each other in predicting problematicity -- remains unknown. Additionally, transparent research into this question is hindered by the literature's focus on closed platforms with inaccessible data, as well as selective analytical decisions that may lead to reproducibility issues.In this work, we investigate how both self-reported and data-derived metrics of time spent relate to potentially problematic effects arising from the use of an open, non-profit online chess platform. These effects include disruptions to sleep, relationships, school and work performance, and self-control. To this end, we distributed a gamified survey to players and linked their responses with publicly-available game logs. We find problematic effects to be associated with both self-reported and data-derived usage measures to similar degrees. However, analytical models incorporating both self-reported and actual time explain problematic effects significantly more effectively than models with either type of measure alone. Furthermore, these results persist across thousands of possible analytical decisions when using a robust and transparent statistical framework. This suggests that the two methods of measuring time spent measure contain distinct, complementary information about problematic usage outcomes and should be used in conjunction with each other.},
  articleno     = {86},
  numpages      = {27},
  keywords      = {online well-being, problematic platform use, specification curve analysis, survey methodology},
}

@phdthesis{mok:2024:measuring-digital-welfare-online-systems,
  title         = {Measuring the Digital Welfare of Online Social Systems},
  author        = {Mok, Lillio},
  year          = {2024},
  note          = {http://hdl.handle.net/1807/140863},
  school        = {University of Toronto},
  keywords      = {Computational Social Science, Data Science, Human-AI Interaction, Human-Computer Interaction, Web Science},
  annote        = {We rely on all manners of digital systems to organize and facilitate our human functions. From social networks connecting us to each other, to content providers keeping us perpetually entertained, to search engines serving each of our informational needs, to computational models informing us how healthy we are, to artificially-intelligent coaches supplementing our natural intelligence, every corner of human existence is permeated by the digital tools we create. Accompanying the boons of these systems, however, are increasingly complex risks to our digital health. Our attention is pulled into cyberspace via algorithms that use billions of datapoints to learn what we like, sometimes to the detriment of our physical wellness. Ideological rifts online threaten our societal harmony as partisans become ever more polarized, whose obsession with political content in turn feeds the underbelly of our social media ecosystem. All the while, the same data underpinning these online interactions also allow others to make finely-optimized decisions about us, often to the detriment of the disadvantaged. This thesis offers a more optimistic vision: that the same computational infrastructure powering our potentially perilous systems can be repurposed to help us understand their perils. We first outline a framework for rigorously assessing the welfare of our digital systems through the well-being of individual users, the cohesion of user communities, and whether the systems themselves deserve trust. We then utilize this framework to conduct four empirical studies measuring the extent to which digital welfare is preserved or endangered by data-driven systems. At the level of individual users, we directly measure how spending time on a large-scale chess platform, Lichess, can be perceived as detrimental to personal well-being. We find that perceived harms are explained not only by the time that people believe they spend online, but also the actual time they spend engaging with the platform. For groups of users, we quantify how partisan users on the Reddit platform are selective towards politically-congruent news outlets, thus consuming and disseminating polarized news. Despite the platform appearing polarized on aggregate, we discover that narrow, hyper-partisan communities are responsible for deeply-ingrained ideological segregation. We then extend this result by identifying whether key individuals can influence the news consumption cycle on Reddit. Through an analysis of where news about political figures is shared on Reddit and the language it attracts, we illustrate that nationally-recognizable politicians are selectively discussed more by in-group online communities than they are by in-group news outlets. Out-group communities, on the other hand, generate the most toxic and hateful commentary. At the level of problematic downstream outcomes, we further probe whether people can tell when systems like algorithmic risk assessments harm data subjects in unfair ways. We find that observers are easily distracted by who makes risk assessments rather than how equitable the assessments are, suggesting that the task of welfare measurement itself needs to be made accessible for laypeople at large. This thesis posits that the online social systems jeopardizing our collective welfare can also be used to understand the very dangers they pose. By empirically measuring how well people are doing when they use or are impacted by these systems, we in turn empirically demonstrate the feasibility of this ideal. We conclude by speculating on the imminent ubiquity of artificial intelligence in our cyber-environment and their implications for the work in this thesis.},
  type          = {Doctoral Thesis},
}

@article{mondal:2025:adaptive-decision-making-in-the-wild-case-study-chess,
  title         = {Adaptive decision making in the wild: a case study of chess},
  author        = {Supratik Mondal and Jakub Traczyk},
  year          = {2025},
  journal       = {Thinking \& Reasoning},
  publisher     = {Routledge},
  volume        = {0},
  number        = {0},
  pages         = {1--21},
  doi           = {10.1080/13546783.2025.2550306},
  url           = {https://doi.org/10.1080/13546783.2025.2550306},
  abstract      = {Chess is a game of strategic thinking and time management, where a player can lose a game on time despite making all the best moves. Finding the best move is a deliberate and energy-intensive process in a game where players are often under time pressure. Therefore, players who can balance this trade-off will have a significant advantage. The current study explores such instances where winning is contingent on how well players balance their accuracy under time pressure. We found that winning players, compared to their opponents, followed a more adaptive decision strategy--they made more theoretical best moves (i.e., accurate moves) in highly critical positions. However, the accuracy difference between the opponents was very similar in less critical positions. We conclude that winning players have a better understanding of when and how to allocate their limited resources efficiently, even when controlling for differences in skill levels, compared to their opponents.},
  keyword       = {Chess, Adaptive Decision Making, Resource Constraints, Skilled Decision Maker, Evaluation},
}

@article{morel-balbi:2025:estimation-partial-rankings-sparse-noisy-comparisons,
  title         = {Estimation of partial rankings from sparse, noisy comparisons},
  author        = {Morel-Balbi, Sebastian and Kirkley, Alec},
  year          = {2025},
  month         = {Dec},
  day           = {20},
  journal       = {Communications Physics},
  doi           = {10.1038/s42005-025-02461-y},
  issn          = {2399-3650},
  url           = {https://doi.org/10.1038/s42005-025-02461-y},
  abstract      = {Ranking items from pairwise comparisons is common in domains ranging from sports to consumer preferences. Statistical inference-based methods, such as the Bradley--Terry model, have emerged as flexible and powerful tools to tackle ranking in empirical data. However, in situations with limited and/or noisy comparisons, it is often challenging to confidently distinguish item performance based on evidence available in the data. Most ranking methods nevertheless force a complete ordering, suggesting a meaningful distinction when there is none. Here, we introduce a principled nonparametric Bayesian framework for learning partial rankings---rankings with ties---that infers distinctions between items only when supported by the evidence. We develop a fast agglomerative algorithm for Maximum a Posteriori (MAP) inference under this framework and evaluate its performance on a range of synthetic and real-world datasets, finding that it often yields a more parsimonious and reliable summary of the data than traditional ranking approaches, particularly in sparse observational settings.},
  preprint      = {https://arxiv.org/abs/2501.02505},
  github        = {https://github.com/seb310/partial-rankings},
}

@misc{morelbalbi:2025:learning-rank-estimation-partial-sparse-noisy-comparisons,
  title         = {Learning when to rank: Estimation of partial rankings from sparse, noisy comparisons},
  author        = {Sebastian Morel-Balbi and Alec Kirkley},
  year          = {2025},
  url           = {https://arxiv.org/abs/2501.02505},
  eprint        = {2501.02505},
  archiveprefix = {arXiv},
  primaryclass  = {physics.soc-ph},
}

@inproceedings{muecke:2022:check-mate-sanity-check-trustworthy-ai,
  title         = {Check Mate: {A} Sanity Check for Trustworthy {AI}},
  author        = {Sascha M{\"{u}}cke and Lukas Pfahler},
  year          = {2022},
  booktitle     = {Proceedings of the {LWDA} 2022 Workshops: FGWM, FGKD, and FGDB, Hildesheim (Germany), Oktober 5-7th, 2022},
  publisher     = {CEUR-WS.org},
  series        = {{CEUR} Workshop Proceedings},
  volume        = {3341},
  pages         = {91--103},
  url           = {https://ceur-ws.org/Vol-3341/KDML-LWDA\_2022\_CRC\_8977.pdf},
  editor        = {Pascal Reuss and Viktor Eisenstadt and Jakob Michael Sch{\"{o}}nborn and Jero Sch{\"{a}}fer},
}

@inproceedings{mujagic:2024:predictive-analysis-chess-player-performance-maching-learning,
  title         = {Predictive Analysis of Chess Player Performance: An Analysis of Factors Influencing Competitive Success Using Machine Learning Techniques},
  author        = {Mujagi{\'{c}}, Amar and Mujagi{\'{c}}, Adnan and Mehanovi{\'{c}}, D{\v{z}}elila},
  year          = {2024},
  booktitle     = {Advanced Technologies, Systems, and Applications IX},
  publisher     = {Springer Nature Switzerland},
  address       = {Cham},
  pages         = {392--408},
  isbn          = {978-3-031-71694-2},
  editor        = {Ademovi{\'{c}}, Naida and Ak{\v{s}}amija, Zlatan and Karabegovi{\'{c}}, Almir},
  abstract      = {The world of competitive chess has long been a captivating arena for intellectual competition, where human intelligence, strategic thinking, and long-term planning converge. This study delves into the intricate web of factors that influence a chess player's competitive success through the lens of predictive modeling and machine learning techniques.},
}

BibTex
@conference{munoz-hurtado:2025:mining-security-documentation-practices-openapi-descriptions,
  title         = {Mining Security Documentation Practices in OpenAPI Descriptions},
  author        = {Diana Carolina Mu{\~n}oz Hurtado and Souhaila Serbout and Cesare Pautasso},
  year          = {2025},
  month         = {March},
  booktitle     = {22nd IEEE International Conference on Software Architecture (ICSA)},
  address       = {Odense, Denmark},
  abstract      = {Security is an integral requirement of any trustworthy software architecture, particularly critical for application programming interfaces (APIs). In this paper, we survey security documentation practices, specifically API security schemes related to authentication and authorization, by mining a large collection of OpenAPI descriptions retrieved from open-source GitHub repositories. Our study focuses on detecting existing security schemes and evaluating their prevalence and positioning within API descriptions. We distinguish whether security schemes are introduced locally (at the path or operation level) or globally (for the entire API). Our analysis highlights scenarios where security schemes are featured in APIs in different proportions over time, thus tracking whether the API documentation tends to include more (or less) security details as the API evolves.},
  keywords      = {API Analytics, OpenAPI, Security},
}

@misc{narayanan:2023:improving-strength-human-models-chess,
  title         = {Improving the Strength of Human-Like Models in Chess},
  author        = {Saumik Narayanan and Kassa Korley and Chien-Ju Ho and Siddhartha Sen},
  year          = {2023},
  url           = {https://openreview.net/forum?id=fJY2iCssvIs},
}

@inproceedings{nguyen:2025:comparison-effects-model-adaptation-techniques-large-language-models-non-linguistic-tasks,
  title         = {A Comparison of the Effects of Model Adaptation Techniques on Large Language Models for Non-Linguistic and Linguistic Tasks},
  author        = {Nguyen, Khoa and Jahan, Sadia and Slavin, Rocky},
  year          = {2025},
  booktitle     = {Proceedings of the 40th ACM/SIGAPP Symposium on Applied Computing},
  location      = {Catania International Airport, Catania, Italy},
  publisher     = {Association for Computing Machinery},
  address       = {New York, NY, USA},
  series        = {SAC '25},
  pages         = {936–944},
  doi           = {10.1145/3672608.3707740},
  isbn          = {9798400706295},
  url           = {https://doi.org/10.1145/3672608.3707740},
  abstract      = {Generative large language models (LLMs) have revolutionized natural language processing (NLP) by demonstrating exceptional performance in interpreting and generating human language. There has been some exploration of their application to non-linguistic tasks, which could lead to significant advancements in fields that rely heavily on structured data and specialized knowledge. However, there has been limited direct comparison of the effects of model adaptation techniques for non-linguistic compared to linguistic tasks with LLMs. To this end, the work in this paper investigates the effects of fine-tuning and few-shot learning on pre-trained LLMs for non-linguistic tasks using chess puzzles as a case study task. We compare the impact of fine-tuning and few-shot learning on models performing the same task represented in both chess notation (i.e., non-linguistic data) and natural language descriptions of the same chess notations (i.e., natural language data). Our experiments with Mixtral-8x7B-v0.1 and Meta-Llama-3-70B resulted in a 5\% lower average increase in performance after fine-tuning for non-linguistic tasks compared to linguistic tasks. Similarly, few-shot learning on pre-trained models exhibited a 3\% lower average increase in performance for on non-linguistic tasks compared to linguistic tasks. Furthermore, few-shot learning on fine-tuned models resulted in a significant accuracy drop, particularly for Mixtral, with a 24.82\% decrease for non-linguistic tasks. These results suggest that fine-tuning and few-shot learning for generative LLMs have stronger effects on linguistic tasks and their data than for non-linguistic.},
  numpages      = {9},
  keywords      = {large language models, natural language processing, model adaptation techniques},
}

@misc{nie:2024:discovering-high-quality-chess-puzzles-offline-reinforcement-learning,
  title         = {Discovering High-Quality Chess Puzzles Through One Billion Plays with Offline Reinforcement Learning},
  author        = {Allen Nie and Anirudhan Badrinath and Nicholas Tomlin and Timothy Dai and Carissa Yip and Rose E Wang and Emma Brunskill and Christopher J Piech},
  year          = {2024},
  url           = {https://openreview.net/forum?id=YKW98Icu1X},
}

@misc{nolan:2021:online-chess-social-networks,
  title         = {Online Chess Social Networks},
  author        = {Nolan, Eva and Scognamillo, Valentin},
  year          = {2021},
  url           = {https://github.com/ornicar/lichess-db/blob/master/web/chess-social-networks-paper.pdf},
  note          = {Student project},
  school        = {Hamilton College},
  abstract      = {The goal of this research is to analyze the structure of the network of chess players that play on Lichess.org. We aim to understand the way that Lichess randomizes player pairings and how closely related players are in order to better understand the relationship between ranking and pairing systems. We will also observe the behavior of players with respect to the game types that they play to see if this influences player groupings. Another hope of this project is to do an exploratory analysis of standout players and those that choose their opponents, rather than let the algorithm choose for them.},
}

@misc{nordby:2025:soft-prompts-evaluation-measuring-conditional-distance-capabilities,
  title         = {Soft Prompts for Evaluation: Measuring Conditional Distance of Capabilities},
  author        = {Ross Nordby},
  year          = {2025},
  url           = {https://arxiv.org/abs/2505.14943},
  eprint        = {2505.14943},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG},
}

@thesis{o-rourke:2024:alternative-chess-rating-model-latent-variables,
  title         = {An alternative chess rating model based on latent variables},
  author        = {O'Rourke, Patrick},
  year          = {2024},
  note          = {http://dx.doi.org/10.13140/RG.2.2.18931.13604},
  school        = {University College Dublin},
  type          = {Master's thesis},
  annote        = {The ranking of players and particularly of chess players has been a topic of debate throughout the last 80 years. Such exploration spawned what has become the benchmark of evaluating professional chess players since the 1970s: the Elo rating model. The Elo system, the first to have a sound statistical basis, was designed by Elo (1978) from the assumption that the performance of a player in a game is a normally distributed random variable Alliot (2017). However, this ranking model is not without its limitations and such has led to extreme rating deflation of the World Chess Federation (FIDE) Standard Elo rating system Sonas (2023). Such attention on the FIDE's rating mechanism has ignited focus on the Elo system's drawbacks which we will address in this dissertation.},
}

@misc{omori:2024:chess-rating-estimation-moves,
  title         = {Chess Rating Estimation from Moves and Clock Times Using a CNN-LSTM},
  author        = {Michael Omori and Prasad Tadepalli},
  year          = {2024},
  url           = {https://arxiv.org/abs/2409.11506},
  eprint        = {2409.11506},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG},
}

@article{ong:2024:sparse-but-strategic-quantiative-insights-chess-middlegame-complexity,
  title         = {Sparse but Strategic: Quantitative Insights into Chess Middlegame Complexity},
  author        = {Ong, Justin and Bilali{\'c}, Merim and Vaci, Nemanja},
  year          = {2024},
  journal       = {Research Square},
  doi           = {https://doi.org/10.21203/rs.3.rs-5574128/v1},
  keywords      = {Chess Complexity, Move Prediction, Cognitive Modeling, Big Data Analysis, Sparse Data},
}

@inproceedings{palsson:2024:empirical-evaluation-concept-probing-game-playing-agents,
  title         = {Empirical Evaluation of Concept Probing for Game-Playing Agents},
  author        = {A{\dh}alsteinn P{\'{a}}lsson and Yngvi Bj{\"{o}}rnsson},
  year          = {2024},
  booktitle     = {{ECAI} 2024 - 27th European Conference on Artificial Intelligence, 19-24 October 2024, Santiago de Compostela, Spain - Including 13th Conference on Prestigious Applications of Intelligent Systems {(PAIS} 2024)},
  publisher     = {{IOS} Press},
  series        = {Frontiers in Artificial Intelligence and Applications},
  volume        = {392},
  pages         = {874--881},
  doi           = {10.3233/FAIA240574},
  url           = {https://doi.org/10.3233/FAIA240574},
  editor        = {Ulle Endriss and Francisco S. Melo and Kerstin Bach and Alberto Jos{\'{e}} Bugar{\'{\i}}n Diz and Jose Maria Alonso{-}Moral and Sen{\'{e}}n Barro and Fredrik Heintz},
}

@inproceedings{patria:2021:cheat-detection-online-chess,
  title         = {Cheat Detection on Online Chess Games using Convolutional and Dense Neural Network},
  author        = {Patria, Reyhan and Favian, Sean and Caturdewa, Anggoro and Suhartono, Derwin},
  year          = {2021},
  booktitle     = {2021 4th International Seminar on Research of Information Technology and Intelligent Systems (ISRITI)},
  pages         = {389--395},
  doi           = {10.1109/ISRITI54043.2021.9702792},
  keywords      = {Seminars;Neural networks;Games;Convolutional neural networks;Intelligent systems;Information technology;Engines;Cheat Detection;Online Chess Games;Convolutional Neural Network;Dense Neural Network;Neural Network},
}

@misc{patricio:2025:leveraging-systems-control-theory-social-robotics-model-based-behavioral-control-human-robot-interaction,
  title         = {Leveraging Systems and Control Theory for Social Robotics: A Model-Based Behavioral Control Approach to Human-Robot Interaction},
  author        = {Maria Mor\~{a}o Patr\'{\i}cio and Anahita Jamshidnejad},
  year          = {2025},
  url           = {https://arxiv.org/abs/2504.21548},
  eprint        = {2504.21548},
  archiveprefix = {arXiv},
  primaryclass  = {eess.SY},
}

@misc{pav:2025:inferring-piece-value-chess-variants,
  title         = {Inferring Piece Value in Chess and Chess Variants},
  author        = {Steven Pav},
  year          = {2025},
  url           = {https://arxiv.org/abs/2509.04691},
  eprint        = {2509.04691},
  archiveprefix = {arXiv},
  primaryclass  = {stat.AP},
  abstract      = {We use logistic regression to estimate the value of the pieces in standard chess and several chess variants, namely Chess 960, Atomic chess, Antichess, and Horde chess. We perform our regressions on several years of data from Lichess, the free and open-source internet chess server. We use the published player ratings to control for the confounding effect of differential player skill. We adjust for the attenuation bias in regressions due to the noise in observed ratings. We find that major piece values, relative to the value of a pawn, are fairly consistent with historical valuation systems. However we find slightly higher value to bishops than knights. We find that piece values are smaller, in absolute value, in Atomic and Antichess than standard chess. We also present approximate values of the pieces to equalize odds when players of varying skill face off.},
}

@inproceedings{pilone:2025:automatically-augmenting-github-issues-informative-user-reviews,
  title         = {Automatically Augmenting GitHub Issues with Informative User Reviews},
  author        = {Pilone, Arthur and Raglianti, Marco and Lanza, Michele and Kon, Fabio and Meirelles, Paulo},
  year          = {2025},
  booktitle     = {2025 International Conference on Software Maintenance and Evolution (ICSME)},
  abstract      = {Development teams for mobile applications can receive thousands of user reviews daily. At the same time, these developers use different communication channels, such as the GitHub issue tracker. Although GitHub issues are accessible and manageable for developers, their content often differs starkly from what users write in app reviews. Issues may lack steps to reproduce bugs or insights that justify the priority of new feature requests. The sheer volume of user reviews for a popular app, combined with their heterogeneity and varying quality, makes manual integration into issue trackers unfeasible. We present an approach that automatically augments GitHub issues with informative user reviews to bridge the gap between user feedback and developer-managed issues. Using a state-of-the-art large language model (LLM), our approach automatically retrieves user reviews with high semantic textual similarity (STS) to the issue content and suggests reviews that augment developers' understanding of the issue. In this paper, we present large-scale quantitative and qualitative analyses to assess the feasibility of enriching development workflows with user-written information. Using over 37,000 issues and 750,000 reviews from 19 popular Free/Libre/Open Source Software (FLOSS) mobile applications, our approach augments 3,017 (8\%) issues with 7,287 (1\%) potentially informative reviews. In addition to providing insights into user-reported bugs and feature requests, the information from these matches points toward a novel and promising way to leverage user reviews for concerted app evolution.},
  repository    = {https://gitlab.com/ArthurPilone/deepermatcher},
  keywords      = {Semantic Textual Similarity, User Feedback Mining, GitHub Issues, Information Retrieval, Software Repository Mining},
  dataset       = {https://figshare.com/articles/dataset/Replication\_package\_for\_the\_paper\_Automatically\_Augmenting\_GitHub\_Issues\_with\_Informative\_User\_Reviews\_/28578140},
}

@misc{poesia:2025:programmatic-representation-learning-language-models,
  title         = {Programmatic Representation Learning with Language Models},
  author        = {Gabriel Poesia and Georgia Gabriela Sampaio},
  year          = {2025},
  url           = {https://arxiv.org/abs/2510.14825},
  eprint        = {2510.14825},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG},
  github        = {https://github.com/gpoesia/leapr/},
  abstarct      = {Classical models for supervised machine learning, such as decision trees, are efficient and interpretable predictors, but their quality is highly dependent on the particular choice of input features. Although neural networks can learn useful representations directly from raw data (e.g., images or text), this comes at the expense of interpretability and the need for specialized hardware to run them efficiently. In this paper, we explore a hypothesis class we call Learned Programmatic Representations (LeaPR) models, which stack arbitrary features represented as code (functions from data points to scalars) and decision tree predictors. We synthesize feature functions using Large Language Models (LLMs), which have rich prior knowledge in a wide range of domains and a remarkable ability to write code using existing domain-specific libraries. We propose two algorithms to learn LeaPR models from supervised data. First, we design an adaptation of FunSearch to learn features rather than directly generate predictors. Then, we develop a novel variant of the classical ID3 algorithm for decision tree learning, where new features are generated on demand when splitting leaf nodes. In experiments from chess position evaluation to image and text classification, our methods learn high-quality, neural network-free predictors often competitive with neural networks. Our work suggests a flexible paradigm for learning interpretable representations end-to-end where features and predictions can be readily inspected and understood.},
}

@misc{poupart:2025:tdhook-lightweight-framework-interpretability,
  title         = {TDHook: A Lightweight Framework for Interpretability},
  author        = {Yoann Poupart},
  year          = {2025},
  url           = {https://arxiv.org/abs/2509.25475},
  eprint        = {2509.25475},
  archiveprefix = {arXiv},
  primaryclass  = {cs.AI},
  github        = {https://github.com/Xmaster6y/tdhook},
  abstract      = {Interpretability of Deep Neural Networks (DNNs) is a growing field driven by the study of vision and language models. Yet, some use cases, like image captioning, or domains like Deep Reinforcement Learning (DRL), require complex modelling, with multiple inputs and outputs or use composable and separated networks. As a consequence, they rarely fit natively into the API of popular interpretability frameworks. We thus present TDHook, an open-source, lightweight, generic interpretability framework based on `tensordict` and applicable to any `torch`' model. It focuses on handling complex composed models which can be trained for Computer Vision, Natural Language Processing, Reinforcement Learning or any other domain. This library features ready-to-use methods for attribution, probing and a flexible get-set API for interventions, and is aiming to bridge the gap between these method classes to make modern interpretability pipelines more accessible. TDHook is designed with minimal dependencies, requiring roughly half as much disk space as `transformer\_lens`, and, in our controlled benchmark, achieves up to a \texttimes{}2 speed-up over `captum` when running integrated gradients for multi-target pipelines on both CPU and GPU. In addition, to value our work, we showcase concrete use cases of our library with composed interpretability pipelines in Computer Vision (CV) and Natural Language Processing (NLP), as well as with complex models in DRL.},
}

@inproceedings{puri:2020:explain-your-move,
  title         = {Explain Your Move: Understanding Agent Actions Using Specific and Relevant Feature Attribution},
  author        = {Nikaash Puri and Sukriti Verma and Piyush Gupta and Dhruv Kayastha and Shripad V. Deshmukh and Balaji Krishnamurthy and Sameer Singh},
  year          = {2020},
  booktitle     = {8th International Conference on Learning Representations, {ICLR} 2020, Addis Ababa, Ethiopia, April 26-30, 2020},
  publisher     = {OpenReview.net},
  url           = {https://openreview.net/forum?id=SJgzLkBKPB},
}

@article{purohit:2025:metacognitive-appraisal-quitting,
  title         = {A metacognitive appraisal of quitting},
  author        = {Purohit, Hariharan and Srivastava, Nisheeth},
  year          = {2025},
  journal       = {Proceedings of the Annual Meeting of the Cognitive Science Society},
  volume        = {47},
  url           = {https://escholarship.org/uc/item/02n5p1j5},
  abstract      = {Stopping decisions are frequently modeled as decisions to switch to alternative activities once the current activity stops being adequately rewarding, such as in optimal foraging theory, as well as more recent metacognitive models. However, the sense of stopping and making decisions in such frameworks is highly platonic, with both decisions and stopping actions occurring instantaneously. In contrast, the phenomenology of quitting actions that one is undertaking appears to be temporally extended and metacognitively challenging. We study the metacognitive covariates of quitting decisions made by chess players using a large database of chess games sourced from an online chess portal. Our analysis reveals that players tend to persevere when they are playing against stronger opponents and after having played poor moves. We also find that a history of quitting games makes players more likely to quit in future games, but that having recently quit in a game offers some protective effect against quitting. Finally, we find that quitting a game makes it more likely that a player will play a game again soon. We place these results in the context of modeling quitting as a metacognitive choice affected by multiple competing goals.},
}

@misc{purohit:2025:skill-issue-quit-chess,
  title         = {'Sounds like a skill issue': what makes you quit at chess?},
  author        = {Hariharan Purohit and Nisheeth Srivastava},
  year          = {2025},
  url           = {https://www.cgs.iitk.ac.in/user/hariharan22/site/pdfs/Paper126_ACCS11_chess_quit_final.pdf},
}

@inproceedings{qian:2020:comparative-study-online-chess-educational-products,
  title         = {A Comparative Study of Chess Online Educational Products},
  author        = {Dong, Qian and Miao, Rong},
  year          = {2020},
  booktitle     = {Blended Learning. Education in a Smart Learning Environment: 13th International Conference, ICBL 2020, Bangkok, Thailand, August 24–27, 2020, Proceedings},
  location      = {Bangkok, Thailand},
  publisher     = {Springer-Verlag},
  address       = {Berlin, Heidelberg},
  pages         = {101–113},
  doi           = {10.1007/978-3-030-51968-1_9},
  isbn          = {978-3-030-51967-4},
  url           = {https://doi.org/10.1007/978-3-030-51968-1_9},
  abstract      = {With the development of technology, more and more online educational products emerge in chess, which makes it difficult for different users to choose from. It's important to develop methodologies to assist different levels chess players to learn in varies environment. List method and rubric evaluation has been conducted, and advice has been put forward based on this approach. The results show that chess online educational products were rich in content and full featured, which could be divided into four categories: overall ecology, video tutorial, tactical training, live broadcast product. However, products still need to improve in product positioning and user experience to promote the development of chess online education.},
  numpages      = {13},
  keywords      = {Chess, Online education, Products, Comparative study},
}

@inproceedings{rabii:2021:revealing-game-dynamics-word-embeddings,
  title         = {Revealing Game Dynamics via Word Embeddings of Gameplay Data},
  author        = {Youn{\`{e}}s Rabii and Michael Cook},
  year          = {2021},
  booktitle     = {Proceedings of the Seventeenth {AAAI} Conference on Artificial Intelligence and Interactive Digital Entertainment, {AIIDE} 2021, virtual, October 11-15, 2021},
  publisher     = {{AAAI} Press},
  pages         = {187--194},
  url           = {https://ojs.aaai.org/index.php/AIIDE/article/view/18907},
  editor        = {David Thue and Stephen G. Ware},
}

@inproceedings{rabii:2024:hunt-takes-hare-theming-games-through-game-word-vector-translation,
  title         = {"Hunt Takes Hare": Theming Games Through Game-Word Vector Translation},
  author        = {Rabii, Youn\`{e}s and Cook, Michael},
  year          = {2024},
  booktitle     = {Proceedings of the 19th International Conference on the Foundations of Digital Games},
  location      = {Worcester, MA, USA},
  publisher     = {Association for Computing Machinery},
  address       = {New York, NY, USA},
  series        = {FDG '24},
  doi           = {10.1145/3649921.3659851},
  isbn          = {9798400709555},
  url           = {https://doi.org/10.1145/3649921.3659851},
  abstract      = {A game's theme is an important part of its design – it conveys narrative information, rhetorical messages, helps the player intuit strategies, aids in tutorialisation and more. Thematic elements of games are notoriously difficult for AI systems to understand and manipulate, however, and often rely on large amounts of hand-written interpretations and knowledge. In this paper we present a technique which connects game embeddings, a recent method for modelling game dynamics from log data, and word embeddings, which models semantic information about language. We explain two different approaches for using game embeddings in this way, and show evidence that game embeddings enhance the linguistic translations of game concepts from one theme to another, opening up exciting new possibilities for reasoning about the thematic elements of games in the future.},
  articleno     = {74},
  numpages      = {7},
  keywords      = {automated game design, computational creativity, procedural content generation},
}

@inproceedings{rafaralahy:2024-pairwise-ltr-chess-puzzle-difficulty-prediction,
  title         = {{Pairwise Learning to Rank for Chess Puzzle Difficulty Prediction}},
  author        = {Andry Rafaralahy},
  year          = {2024},
  booktitle     = {{IEEE} International Conference on Big Data, Big Data 2024, Washington DC, USA, December 15-18, 2024},
  publisher     = {{IEEE}},
}

@article{rautalahti:2025:fluid-roles-close-knit-gaming-households-playing-digital-games,
  title         = {Fluid Roles for Close-Knit Gaming: Households Playing Digital Games},
  author        = {Rautalahti, Heidi and Ma, Rongjun and Bourdoucen, Amel and Wang, Yajing and Lindqvist, Janne},
  year          = {2025},
  month         = oct,
  journal       = {Proc. ACM Hum.-Comput. Interact.},
  publisher     = {Association for Computing Machinery},
  address       = {New York, NY, USA},
  volume        = {9},
  number        = {6},
  doi           = {10.1145/3748619},
  url           = {https://doi.org/10.1145/3748619},
  issue_date    = {October 2025},
  abstract      = {Households increasingly play and engage with video games. We examined how households play video games among 20 interviewees coming from varied and familial households. Our study focused on interactions, examining how gaming influences daily household dynamics. Previous studies have focused mainly on the impact on relationships. Looking at households led us to observe fluid role dynamics around gaming. Our findings map the stages of how households play games from gaining plausible momentum, actions, conversations, and roles taken during game sessions, and reflections after gaming. Our findings highlight a novel role of the Gamer Host leading the game session and attending to everyone's enjoyment. Our observations exemplify the supportive and positive social outcomes close-knit gaming can afford and implications for achieving harmonious gaming in households. Our findings tie to prospects on communal and social aspects on technology use providing new perspectives on user experiences in an immediate social environment.},
  articleno     = {GAMES024},
  numpages      = {35},
  keywords      = {digital games, household, media-centric, qualitative methods, social interactions},
}

@inproceedings{reyes:2025:elometrics-advanced-outcome-prediction-chess-elo-ratings-logistic-regression,
  title         = {EloMetrics: Advanced Outcome Prediction for Chess Matches with Elo Ratings and Logistic Regression},
  author        = {Reyes, Ma. Julianna Re-an DG. and Dicreto, Eirnan and Santos, Emmanuel Gabriel D. and Limbag, Daniella Franxene P. and Sampedro, Gabriel Avelino},
  year          = {2025},
  booktitle     = {2025 International Conference on Electronics, Information, and Communication (ICEIC)},
  pages         = {1--4},
  doi           = {10.1109/ICEIC64972.2025.10879733},
  keywords      = {Training;Measurement;Analytical models;Logistic regression;Accuracy;Focusing;Psychology;Games;Predictive models;Time factors;Logistic regression;machine learning;predictive modeling},
}

@thesis{Roohani2025,
  title         = {Coordination in Multi-Agent LLM Systems: The Role of a Question-Asking Agent in Guiding Collaborative Consensus},
  author        = {Roohani, Keon},
  year          = {2025},
  month         = {April},
  address       = {100 Institute Road, Worcester MA 01609-2280 USA},
  school        = {Worcester Polytechnic Institute},
  type          = {Master's thesis},
  keywords      = {Large Language Models, Chess, Expected Information Gain, Multi-Agent},
}

@misc{rosales:2024:temporal-differences-chess-adhd-neurotypical-individuals,
  title         = {The Temporal Differences in Chess Between ADHD and Neurotypical Individuals},
  author        = {Benjamin Rosales},
  year          = {2024},
  url           = {https://flatfish4u.github.io/research/2024/02/22/chess-research.html},
}

@inproceedings{rosemarin:2019:playing-chess-human-level-style,
  title         = {Playing Chess at a Human Desired Level and Style},
  author        = {Hanan Rosemarin and Ariel Rosenfeld},
  year          = {2019},
  booktitle     = {Proceedings of the 7th International Conference on Human-Agent Interaction, {HAI} 2019, Kyoto, Japan, October 06-10, 2019},
  publisher     = {{ACM}},
  pages         = {76--80},
  doi           = {10.1145/3349537.3351904},
  url           = {https://doi.org/10.1145/3349537.3351904},
  editor        = {Natsuki Oka and Tomoko Koda and Mohammad Obaid and Hideyuki Nakanishi and Omar Mubin and Kazuaki Tanaka},
  abstract      = {Human chess players prefer training with human opponents over chess agents as the latter are distinctively different in level and style than humans. Chess agents designed for human-agent play are capable of adjusting their level, however their style is not aligned with that of human players. In this paper, we propose a novel approach for designing such agents by integrating the theory of chess players' decision-making with a state-of-the-art Monte Carlo Tree Search (MCTS) algorithm. We demonstrate the benefits of our approach using two sets of analyses. Quantitatively, we establish that the agents attain their desired Elo ratings. Qualitatively, through a Turing-inspired test with a human chess expert, we show that our agents are indistinguishable from human players.},
  keywords      = {chess, game playing agents, human-agent play},
}

@inproceedings{ruoss:2024:amortized-planning-transformers-case-study-chess,
  title         = {Amortized Planning with Large-Scale Transformers: A Case Study on Chess},
  author        = {Anian Ruoss and Gregoire Deletang and Sourabh Medapati and Jordi Grau-Moya and Li Kevin Wenliang and Elliot Catt and John Reid and Cannada A. Lewis and Joel Veness and Tim Genewein},
  year          = {2024},
  booktitle     = {The Thirty-eighth Annual Conference on Neural Information Processing Systems},
  url           = {https://openreview.net/forum?id=XlpipUGygX},
}

@article{russel:2022:thinking-online-chess-computation,
  title         = {Time spent thinking in online chess reflects the value of computation},
  author        = {Russek, Evan and Acosta-Kane, Daniel and van Opheusden, Bas and Mattar, Marcelo and Griffiths, Tom},
  year          = {2022},
  journal       = {PsyArXiv},
  doi           = {10.31234/osf.io/8j9zx},
  url           = {https://doi.org/10.31234/osf.io/8j9zx},
  abstract      = {Although artificial intelligence systems can now outperform humans in a variety of domains, they still lag behind in the ability to arrive at good solutions to problems using limited resources. Recent proposals have suggested that the key to this cognitive efficiency is intelligent selection of the situations in which computational resources are spent. We tested this hypothesis in the domain of complex planning by analyzing how humans managed time available for thinking in over 12 million online chess matches. We found that players spent more time thinking in board positions where planning was more beneficial. This effect was greater in stronger players, and additionally strengthened by considering only the information available to the player at the time of choice. Finally, we found that the qualitative features of this relationship were consistent with a policy that considers the empirically-measured cost of spending time in chess. This provides evidence that human efficiency is supported by intelligent selection of when to apply computation.},
}

@thesis{russel:2025:beyond-workload-paving-road-next-generation-implicit-prefrontal-cortex-brain-computer-interface,
  title         = {Beyond Workload: Paving the Road for the Next Generation of Implicit Prefrontal Cortex Based Brain-Computer Interfaces},
  author        = {Russell, Matthew},
  year          = {2025},
  url           = {http://hdl.handle.net/10427/B2774940P},
  note          = {Second two keywords are from the defense page: https://www.cs.tufts.edu/t/colloquia/current/?event=1651},
  institution   = {Tufts University, Department of Computer Science},
  type          = {PhD thesis},
  supervisor    = {Jacob, Robert},
  keywords      = {Computer science, Human-Computer Interaction, Brain-Computer Interfaces},
  abstract      = {The rapidly evolving field of Human-Computer Interaction (HCI) faces a fundamental constraint: the limited bandwidth of information exchange between users and computing systems. One promising approach to increasing this bandwidth is implicit interaction: a paradigm in which applications modify their state based on information gleaned from users, rather than direct input. Within the context of reading such information from human neural signals, this concept is formally recognized as implicit Brain-Computer Interfaces (implicit BCI). My work focuses on implicit BCIs which measure the prefrontal cortex (PFC); early prototypes have successfully leveraged the PFC to approximate mental workload, but much is left to be understood about the full potential of this region. Through three research projects spanning two brain measurement modalities, this dissertation makes targeted contributions to this area of research. With functional Near-Infrared Spectroscopy (fNIRS), I explore two facets of PFC activation demonstrated in functional Magnetic Resonance Imaging (fMRI)-based neuroscience research which are underexplored in applied contexts: episodic memory and brain-network based classification; in the first project, I study the measurable effects of episodic and working memory within the context of using Large Language Models (LLMs), and in the second project I develop a real-time implicit BCI designed to differentiate between different brain networks. The third project benchmarks low-cost EEG in three studies which distinguish brain states based on different factors: quality of moves made during chess playing, workload levels within standard cognitive psychology tasks, and cognitive states during the tasks. For all studies I use Linear Mixed Models (LMM) to observe macro patterns in the data, and machine learning to explore potential for implicit BCI. Results indicate that, in addition to the well-understood concept of measuring singular aspects of consciousness across a gradient (e.g. workload), promising potential exists for leveraging the PFC towards classification across tasks which engage different cognitive processes, both with fNIRS and low-cost EEG. Further, careful consideration of ``noise'' in implicit BCI introduces a new idea: Human-Sensor-Computer Interaction (HSCI). Taken together, this dissertation provides relevant context to inform the next generation of Human-Sensor-Computer systems, including PFC-based interfaces stretching past workload, and beyond.},
}

@article{russell:2025:decoding-chess-puzzle-play-bci-eeg-study,
  title         = {Decoding Chess Puzzle Play and Standard Cognitive Tasks for {BCI:} {A} Low-Cost {EEG} Study},
  author        = {Matthew Russell and Samuel Youkeles and William Xia and Kenny Zheng and Aman Shah and Robert J. K. Jacob},
  year          = {2025},
  journal       = {CoRR},
  volume        = {abs/2505.07592},
  doi           = {10.48550/ARXIV.2505.07592},
  url           = {https://doi.org/10.48550/arXiv.2505.07592},
  eprinttype    = {arXiv},
  eprint        = {2505.07592},
}

@inproceedings{ruta:2024:moves-based-prediction-chess-puzzle-difficulty-convolutional-neural-networks,
  title         = {{Moves Based Prediction of Chess Puzzle Difficulty with Convolutional Neural Networks}},
  author        = {Dymitr Ruta and Ming Liu and Ling Cen},
  year          = {2024},
  booktitle     = {{IEEE} International Conference on Big Data, Big Data 2024, Washington DC, USA, December 15-18, 2024},
  publisher     = {{IEEE}},
}

@inproceedings{sabatelli:2018:learning-evaluate-chess-positions-deep-neural-networks-limited-lookahead,
  title         = {Learning to Evaluate Chess Positions with Deep Neural Networks and Limited Lookahead},
  author        = {Matthia Sabatelli and Francesco Bidoia and Valeriu Codreanu and Marco Wiering},
  year          = {2018},
  month         = jan,
  day           = {20},
  booktitle     = {7th International Conference on Pattern Recognition Applications and Methods},
  publisher     = {SciTePress},
  pages         = {276--283},
  doi           = {10.5220/0006535502760283},
  isbn          = {978-989758276-9},
  url           = {http://www.icpram.org/},
  note          = {7th International Conference on Pattern Recognition Applications and Methods ; Conference date: 16-01-2018 Through 18-01-2018},
  abstract      = {In this paper we propose a novel supervised learning approach for training Artificial Neural Networks (ANNs) to evaluate chess positions. The method that we present aims to train different ANN architectures to understand chess positions similarly to how highly rated human players do. We investigate the capabilities that ANNs have when it comes to pattern recognition, an ability that distinguishes chess grandmasters from more amateurplayers. We collect around 3,000,000 different chess positions played by highly skilled chess players and label them with the evaluation function of Stockfish, one of the strongest existing chess engines. We create 4 different datasets from scratch that are used for different classification and regression experiments. The results show how relatively simple Multilayer Perceptrons (MLPs) outperform Convolutional Neural Networks (CNNs) in all the experiments that we have performed. We also investigate two different board representations, the first one representing if a piece is present on the board or not, and the second one in which we assign a numerical value to the piece according to its strength. Our results show how the latter input representation influences the performances of the ANNs negatively in almost all experiments.},
  keywords      = {Deep Learning, COMPUTER GAMES, Machine Learning},
  language      = {English},
}

@misc{sadhuka:2025:evaluator-reliable-agent-verifiers-sequential-hypothesis-testing,
  title         = {E-valuator: Reliable Agent Verifiers with Sequential Hypothesis Testing},
  author        = {Shuvom Sadhuka and Drew Prinster and Clara Fannjiang and Gabriele Scalia and Aviv Regev and Hanchen Wang},
  year          = {2025},
  url           = {https://arxiv.org/abs/2512.03109},
  eprint        = {2512.03109},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG},
  abstract      = {Agentic AI systems execute a sequence of actions, such as reasoning steps or tool calls, in response to a user prompt. To evaluate the success of their trajectories, researchers have developed verifiers, such as LLM judges and process-reward models, to score the quality of each action in an agent's trajectory. Although these heuristic scores can be informative, there are no guarantees of correctness when used to decide whether an agent will yield a successful output. Here, we introduce e-valuator, a method to convert any black-box verifier score into a decision rule with provable control of false alarm rates. We frame the problem of distinguishing successful trajectories (that is, a sequence of actions that will lead to a correct response to the user's prompt) and unsuccessful trajectories as a sequential hypothesis testing problem. E-valuator builds on tools from e-processes to develop a sequential hypothesis test that remains statistically valid at every step of an agent's trajectory, enabling online monitoring of agents over arbitrarily long sequences of actions. Empirically, we demonstrate that e-valuator provides greater statistical power and better false alarm rate control than other strategies across six datasets and three agents. We additionally show that e-valuator can be used for to quickly terminate problematic trajectories and save tokens. Together, e-valuator provides a lightweight, model-agnostic framework that converts verifier heuristics into decisions rules with statistical guarantees, enabling the deployment of more reliable agentic systems.},
  github        = {https://github.com/shuvom-s/e-valuator},
  software      = {https://pypi.org/project/e-valuator/},
}

@article{saha:2024:valued-vision-logical-understanding-dataset,
  title         = {{VALUED} - Vision and Logical Understanding Evaluation Dataset},
  author        = {Soumadeep Saha and Saptarshi Saha and Utpal Garain},
  year          = {2024},
  journal       = {Journal of Data-centric Machine Learning Research},
  url           = {https://openreview.net/forum?id=nS9oxKyy9u},
}

@thesis{saha:2025:domain-obedient-deep-learning,
  title         = {Domain Obedient Deep Learning},
  author        = {Saha, Soumadeep},
  year          = {2025},
  url           = {https://digitalcommons.isical.ac.in/doctoral-theses/629/},
  note          = {Check if http://hdl.handle.net/10263/7608 works and replace url},
  institution   = {Computer Vision and Pattern Recognition Unit, Indian Statistical Institute},
  type          = {PhD thesis},
  supervisor    = {Garain, Utpal},
  abstract      = {Deep learning, a family of data-driven artificial intelligence techniques, has shown immense promise in a plethora of applications, and it has even outpaced experts in several domains. However, unlike symbolic approaches to learning, these methods fall short when it comes to abiding by and learning from pre-existing established principles. This is a significant deficit for deployment in critical applications such as robotics, medicine, industrial automation, etc. For a decision system to be considered for adoption in such fields, it must demonstrate the ability to adhere to specified constraints, an ability missing in deep learning-based approaches. Exploring this problem serves as the core tenet of this dissertation. This dissertation starts with an exploration of the abilities of conventional deep learning-based systems vis-\`{a}-vis domain coherence. A large-scale rule-annotated dataset is introduced to mitigate the pronounced lack of suitable constraint adherence evaluation benchmarks, and with its aid, the rule adherence abilities of vision systems are analyzed. Additionally, this study probes language models to elicit their performance characteristics with regard to domain consistency. Examination of these language models with interventions illustrates their ineptitude at obeying domain principles, and a mitigation strategy is proposed. This is followed by an exploration of techniques for imbuing deep learning systems with domain constraint information. Also, a comprehensive study of standard evaluation metrics and their blind spots pertaining to domain-aware performance estimation is undertaken. Finally, a novel technique to enforce constraint compliance in models without training is introduced, which pairs a search strategy with large language models to achieve cutting-edge performance. A key highlight of this dissertation is the emphasis on addressing pertinent real-world problems with scalable and practicable solutions. We hope the results presented here pave the way for wider adoption of deep learning-based systems in pivotal situations with enhanced confidence in their trustworthiness.},
}

@techreport{salant:2022:complexity-satisficing-theory-evidence-chess,
  title         = {Complexity and Satisficing: Theory with Evidence from Chess},
  author        = {Salant, Yuval and Spenkuch, Jorg L},
  year          = {2022},
  month         = {April},
  series        = {Working Paper Series},
  number        = {30002},
  doi           = {10.3386/w30002},
  url           = {http://www.nber.org/papers/w30002},
  institution   = {National Bureau of Economic Research},
  type          = {Working Paper},
  abstract      = {We develop a satisficing model of choice in which the available alternatives differ in their inherent complexity. We assume--and experimentally validate--that complexity leads to errors in the perception of alternatives' values. The model yields sharp predictions about the effect of complexity on choice probabilities, some of which qualitatively contrast with those of maximization-based choice models. We confirm the predictions of the satisficing model--and thus reject maximization--in a novel data set with information on hundreds of millions of real-world chess moves by highly experienced players. These findings point to the importance of complexity and satisficing for decision making outside of the laboratory.},
}

@techreport{salant:2025:memory-premium,
  title         = {The Memory Premium},
  author        = {Salant, Yuval and Spenkuch, Jorg L and Almog, David},
  year          = {2025},
  month         = {April},
  series        = {Working Paper Series},
  number        = {33649},
  doi           = {10.3386/w33649},
  url           = {http://www.nber.org/papers/w33649},
  institution   = {National Bureau of Economic Research},
  type          = {Working Paper},
  abstract      = {We explore the role of memory for choice behavior in unfamiliar environments. Using a unique data set, we document that  decision makers exhibit a "memory premium." They tend to choose in-memory alternatives over out-of-memory ones, even when the latter are objectively better. Consistent with well-established regularities regarding the inner workings of human memory, the memory premium is associative, subject to interference and repetition effects, and decays over time. Even as decision makers gain familiarity with the environment, the memory premium remains economically large. Our results imply that the ease with which past experiences come to mind plays an important role in shaping choice behavior.},
}

@article{samara:2026:machine-learning-approaches-classifying-chess-game-outcomes-comparative-analysis-player-ratings-game-dynamics,
  title         = {Machine Learning Approaches for Classifying Chess Game Outcomes: A Comparative Analysis of Player Ratings and Game Dynamics},
  author        = {Samara, Kamil and Antreassian, Aaron and Klug, Matthew and Hasan, Mohammad Sakib},
  year          = {2026},
  journal       = {Electronics},
  volume        = {15},
  number        = {1},
  doi           = {10.3390/electronics15010001},
  issn          = {2079-9292},
  url           = {https://www.mdpi.com/2079-9292/15/1/1},
  article-number = {1},
  abstract      = {Online chess platforms generate vast amounts of game data, presenting opportunities to analyze match outcomes using machine learning approaches. This study develops and compares four machine learning models to classify chess game results (White win, Black win, or Draw) by integrating player rating information with game dynamic metadata. We analyzed 11,510 complete games from the Lichess platform after preprocessing a dataset of 20,058 initial records. Seven key features were engineered to capture both pre-game skill parameters (player ratings, rating difference) and game complexity metrics (game duration, turn count). Four machine learning algorithms were implemented and optimized through grid search cross-validation: Multinomial Logistic Regression, Random Forest, K-Nearest Neighbors, and Histogram Gradient Boosting. The Gradient Boosting classifier achieved the highest performance with 83.19\% accuracy on hold-out data and consistent 5-fold cross-validation scores (83.08\% \pm{} 0.009\%). Feature importance analysis revealed that game complexity (number of turns) was the strongest correlate of the outcome across all models, followed by the rating difference between opponents. Draws represented only 5.11\% of outcomes, creating class imbalance challenges that affected classification performance for this outcome category. The results demonstrate that ensemble methods, particularly gradient boosting, can effectively capture non-linear interactions between player skill and game length to classify chess outcomes. These findings have practical applications for chess platforms in automated content curation, post-game quality assessment, and engagement enhancement strategies. The study establishes a foundation for robust outcome analysis systems in online chess environments.},
  keywords      = {chess prediction; machine learning; classification algorithms; online gaming; player rating systems; gradient boosting; game outcome forecasting},
}

@inproceedings{sandmann:2025:iterative-inference-chess-playing-neural-network,
  title         = {Iterative Inference in a Chess-Playing Neural Network},
  author        = {Elias Sandmann and Sebastian Lapuschkin and Wojciech Samek},
  year          = {2025},
  booktitle     = {Mechanistic Interpretability Workshop at NeurIPS 2025},
  url           = {https://openreview.net/forum?id=nRPQhySXJP},
  abstract      = {Do neural networks build their representations through smooth, gradual refinement, or via more complex computational processes? We investigate this by extending the logit lens to analyze the policy network of Leela Chess Zero, a superhuman chess engine. We find strong monotonic trends in playing strength and puzzle-solving ability across layers, yet policy distributions frequently follow non-smooth trajectories. Evidence for this includes correct puzzle solutions that are discovered early but subsequently discarded, move rankings that remain poorly correlated with final outputs, and high policy divergence until late in the network. These findings contrast with the smooth distributional convergence typically observed in language models.},
  github        = {https://github.com/hartigel/leela-logit-lens},
  keywords      = {Understanding high-level properties of models, Probing, logit lens, chess, iterative inference},
  tldr          = {We extended the logit lens to Post-LN to analyze Leela Chess, revealing interpretable intermediate policies with monotonic capability improvement but non-monotonic policy dynamics that contrast with smooth language model convergence},
  figshare      = {https://figshare.com/s/5342980a9ba8b26985a9},
}

@article{sanjaya:2022-non-transitivity-chess,
  title         = {Measuring the Non-Transitivity in Chess},
  author        = {Ricky Sanjaya and Jun Wang and Yaodong Yang},
  year          = {2022},
  journal       = {Algorithms},
  volume        = {15},
  number        = {5},
  pages         = {152},
  doi           = {10.3390/A15050152},
  url           = {https://doi.org/10.3390/a15050152},
}

@thesis{schmid-maag:2024:optimizing-language-models-chess-impact-custom-notation-elo-based-finetuning,
  title         = {Optimizing language models for chess : the impact of custom notation and Elo-based fine-tuning},
  author        = {Schmid, Lars and Maag, Jerome},
  year          = {2024},
  doi           = {https://doi.org/10.21256/zhaw-31999},
  url           = {https://digitalcollection.zhaw.ch/items/2ca7f5f3-535c-406a-87af-432ea6ba940b},
  type          = {Bachelor's thesis},
  school        = {Z{\"u}rcher Hochschule f{\"u}r Angewandte Wissenschaften},
  keywords      = {AI, Chess, GPT-2, LLM, Mamba, NLP, KI, Schach},
  supervisor    = {Cieliebak, Mark	and von D\"{a}niken, Pius},
  abstract      = {This research investigates the potential for large language models to learn to generate valid chess moves solely through pre-training on chess game data. The primary objective of this study is to investigate the impact of custom notation systems and tokenisation methods specifically designed for use with chess games. The study aims to improve the models' understanding of game states and move sequences by developing and implementing a custom notation system, xLAN+. This notation system incorporates additional information about captures, checks and checkmates in order to increase the performance of the models. Furthermore, the strategic gameplay capabilities of the models are to be enhanced by fine-tuning them on datasets filtered by Elo rating. This approach postulates that filtering games by skill level can help models develop a deeper understanding of strategic gameplay, thereby improving their ability to generate high-quality moves. The research uses two different architectures, Transformer, based on OpenAI's GPT-2 configuration, and Mamba, a State Space Model (SSM) optimised for long sequence processing. Initial findings indicate that the custom notation xLAN+ significantly improves the models' ability to generate valid moves and maintain game state accuracy over extended sequences. The comparison between GPT-2 and Mamba reveals that while both architectures can learn chess rules and generate plausible moves, the SSM offers slight advantages in handling long-range dependencies and maintaining game context. This project demonstrates the potential of language models to learn complex tasks like chess through data-driven approaches, paving the way for their application in other strategic and decision-making domains.},
}

@article{schroedter:2025:role-expertise-impulsivity-preference-intuition-decision-quality,
  title         = {The role of expertise, impulsivity, and preference for intuition on decision quality},
  author        = {Robin Schr\"{o}dter and Katrin Heyers and Jan Birkemeyer and Stefanie Klatt},
  year          = {2025},
  journal       = {Personality and Individual Differences},
  volume        = {240},
  pages         = {113174},
  doi           = {https://doi.org/10.1016/j.paid.2025.113174},
  issn          = {0191-8869},
  url           = {https://www.sciencedirect.com/science/article/pii/S0191886925001369},
  keywords      = {Artificial intelligence, Decision quality, Expertise, Naturalistic decision making, Individual differences},
  abstract      = {Decision-making researchers often face a trade-off when conducting controlled laboratory experiments, as these can limit the ability to identify stable relationships between decision-making quality and individual differences, such as expertise or personality traits. This study introduces an innovative paradigm that leverages the objective assessment capabilities of artificial intelligence in a naturalistic online chess setting. Ninety-four participants evaluated tactical chess positions and identified optimal moves under various time control conditions, followed by personality assessments. Expertise, measured by online Elo rating, emerged as a key predictor, accounting for 55~\% of the variance in decision quality and 61~\% in evaluation accuracy, underscoring the precision of the chosen approach. The study also highlights the significant impact of time control on decision-making. Additionally, the paradigm shows promise in examining the interplay between personality factors and decision-making processes, with a notable correlation between higher impulsivity scores and faster response times. However, high impulsivity was not associated with reduced decision quality, raising questions about the validity of this measurement. Overall, the results suggest that the chess paradigm, accessible to a broad sample due to the widespread appeal of online chess, provides a powerful tool that combines laboratory precision with real-world relevance.},
}

@inproceedings{schuett:2024:estimating-chess-puzzle-difficulty-without-past-records-using-neural-network,
  title         = {{Estimating Chess Puzzle Difficulty Without Past Game Records Using a Human Problem-Solving Inspired Neural Network Architecture}},
  author        = {Anan Sch\"{u}tt and Tobias Huber and Elisabeth Andr\'{e}},
  year          = {2024},
  booktitle     = {{IEEE} International Conference on Big Data, Big Data 2024, Washington DC, USA, December 15-18, 2024},
  publisher     = {{IEEE}},
}

@misc{schultz:2024:mastering-board-games-external-internal-planning-language-models,
  title         = {Mastering Board Games by External and Internal Planning with Language Models},
  author        = {John Schultz and Jakub Adamek and Matej Jusup and Marc Lanctot and Michael Kaisers and Sarah Perrin and Daniel Hennes and Jeremy Shar and Cannada Lewis and Anian Ruoss and Tom Zahavy and Petar Veli\v{c}kovi\'{c} and Laurel Prince and Satinder Singh and Eric Malmi and Nenad Toma\v{s}ev},
  year          = {2024},
  url           = {https://arxiv.org/abs/2412.12119},
  eprint        = {2412.12119},
  archiveprefix = {arXiv},
  primaryclass  = {cs.AI},
}

@article{schut:2025:briding-human-ai-knowledge-gap-concept-discovery-transfer-alphazero,
  title         = {Bridging the human–AI knowledge gap through concept discovery and transfer in AlphaZero},
  author        = {Lisa Schut  and Nenad Toma\v{s}ev  and Thomas McGrath  and Demis Hassabis  and Ulrich Paquet  and Been Kim},
  year          = {2025},
  journal       = {Proceedings of the National Academy of Sciences},
  volume        = {122},
  number        = {13},
  pages         = {e2406675122},
  doi           = {10.1073/pnas.2406675122},
  url           = {https://www.pnas.org/doi/abs/10.1073/pnas.2406675122},
  eprint        = {https://www.pnas.org/doi/pdf/10.1073/pnas.2406675122},
  abstract      = {As AI systems become more capable, they may internally represent concepts outside the sphere of human knowledge. This work gives an end-to-end example of unearthing machine-unique knowledge in the domain of chess. We obtain machine-unique knowledge from an AI system (AlphaZero) by a method that finds novel yet teachable concepts and show that it can be transferred to human experts (grandmasters). In particular, the new knowledge is learned from internal mathematical representations without a priori knowing what it is or where to start. The produced knowledge from AlphaZero (new chess concepts) is then taught to four grandmasters in a setting where we can quantify their learning, showing that machine-guided discovery and teaching is possible at the highest human level. AI systems have attained superhuman performance across various domains. If the hidden knowledge encoded in these highly capable systems can be leveraged, human knowledge and performance can be advanced. Yet, this internal knowledge is difficult to extract. Due to the vast space of possible internal representations, searching for meaningful new conceptual knowledge can be like finding a needle in a haystack. Here, we introduce a method that extracts new chess concepts from AlphaZero, an AI system that mastered chess via self-play without human supervision. Our method excavates vectors that represent concepts from AlphaZero's internal representations using convex optimization, and filters the concepts based on teachability (whether the concept is transferable to another AI agent) and novelty (whether the concept contains information not present in human chess games). These steps ensure that the discovered concepts are useful and meaningful. For the resulting set of concepts, prototypes (chess puzzle–solution pairs) are presented to experts for final validation. In a preliminary human study, four top chess grandmasters (all former or current world chess champions) were evaluated on their ability to solve concept prototype positions. All grandmasters showed improvement after the learning phase, suggesting that the concepts are at the frontier of human understanding. Despite the small scale, our result is a proof of concept demonstrating the possibility of leveraging knowledge from a highly capable AI system to advance the frontier of human knowledge; a development that could bear profound implications and shape how we interact with AI systems across many applications.},
  annote        = {Lichess openings cited in appendix},
}

@inproceedings{schut:2025:learning-online-chess-increases-time-thinking-diversity-experience,
  title         = {Learning in online chess increases with more time spent thinking and diversity of experience},
  author        = {Schut, Lisa and Russek, Evan and Kuperwajs, Ionatan and Mattar, Marcelo G and Ma, Wei Ji and Griffiths, Tom},
  year          = {2025},
  journal       = {Proceedings of the Annual Meeting of the Cognitive Science Society},
  volume        = {47},
  url           = {https://escholarship.org/uc/item/5c76v07h},
  abstract      = {What factors of our learning experiences enable us to best acquire complex skills? Recent ideas from artificial intelligence point to two such factors: (1) a balance of real experience with simulated experience acquired during planning itself, and (2) appropriate diversity in training examples. To test whether these factors influence the development of human expertise, we analyzed data from 1,873 chess players on the online platform Lichess, each of whom played hundreds to thousands of games over months to years. We found that both the time spent planning before moves and the diversity of opening positions encountered predict skill improvement over time. These findings suggest that principles shaping the development of expertise in artificial intelligence systems may also apply to human learning.},
}

@inproceedings{schwarzschild:2021:can-you-learn-algorithm-easy-hard-examples,
  title         = {Can You Learn an Algorithm? Generalizing from Easy to Hard Problems with Recurrent Networks},
  author        = {Avi Schwarzschild and Eitan Borgnia and Arjun Gupta and Furong Huang and Uzi Vishkin and Micah Goldblum and Tom Goldstein},
  year          = {2021},
  booktitle     = {Advances in Neural Information Processing Systems 34: Annual Conference on Neural Information Processing Systems 2021, NeurIPS 2021, December 6-14, 2021, virtual},
  pages         = {6695--6706},
  url           = {https://proceedings.neurips.cc/paper/2021/hash/3501672ebc68a5524629080e3ef60aef-Abstract.html},
  editor        = {Marc'Aurelio Ranzato and Alina Beygelzimer and Yann N. Dauphin and Percy Liang and Jennifer Wortman Vaughan},
}

@article{schwarzschild:2021:datasets-easy-hard-examples,
  title         = {Datasets for Studying Generalization from Easy to Hard Examples},
  author        = {Avi Schwarzschild and Eitan Borgnia and Arjun Gupta and Arpit Bansal and Zeyad Emam and Furong Huang and Micah Goldblum and Tom Goldstein},
  year          = {2021},
  journal       = {CoRR},
  volume        = {abs/2108.06011},
  url           = {https://arxiv.org/abs/2108.06011},
  eprinttype    = {arXiv},
  eprint        = {2108.06011},
}

@inproceedings{sekar:2025:human-aligned-chess-ai-multitask-transformer-humanlike-decision-making,
  title         = {Human-Aligned Chess AI: A Multitask Transformer for Humanlike Decision-Making},
  author        = {Hari Sekar, Easwar Gnana and Jin, Roger},
  year          = {2025},
  booktitle     = {2025 IEEE Conference on Artificial Intelligence (CAI)},
  pages         = {1230--1234},
  doi           = {10.1109/CAI64502.2025.00213},
  keywords      = {Fans;Ethics;Education;Games;Learning (artificial intelligence);Transformers;Cognition;Logic;Artificial intelligence;Engines;Artificial Intelligence;Human-AI Interaction;Chess;Transformer;Move Prediction;Multitask Learning;AI Alignment;Human Cognition},
}

@article{serpell:2025:stress-strategic-decision-making,
  title         = {Stress and Strategic Decision Making},
  author        = {Serpell, Benjamin G. and Crewther, Blair T. and Fourie, Phillip J. and Goodman, Stephen P. J. and Cook, Christian J.},
  year          = {2025},
  month         = {Jun},
  day           = {27},
  journal       = {Adaptive Human Behavior and Physiology},
  volume        = {11},
  number        = {3},
  pages         = {12},
  doi           = {10.1007/s40750-025-00264-7},
  issn          = {2198-7335},
  url           = {https://doi.org/10.1007/s40750-025-00264-7},
  keywords      = {Testosterone, Cortisol, Stress, Decision-making},
  abstract      = {Psychology and social science research offer some promising work in the field of decision-making science. However, given the qualitative nature of much of this research, understanding some physiological bases of decision-making may assist by providing more objectivity. The purpose of this study, therefore, was to explore hormonal and neurophysiological biomarkers of stress relative to strategic decision making, with and without an accompanying exercise stress.},
}

@article{setiawan:2018:analysis-chess-skills-mathematics-learning,
  title         = {Analysis of Chess Playing Skills on Mathematics Learning Outcomes Junior Athletes Raja Kombi Trenggalek Chess Club},
  author        = {Setiawan, Andika Yogi and Pratama, Henri Gunawan},
  year          = {2018},
  journal       = {PHEDHERAL},
  volume        = {18},
  number        = {1},
  pages         = {37--46},
  doi           = {10.20961/phduns.v18i1.51318},
  url           = {https://doi.org/10.20961/phduns.v18i1.51318},
  keywords      = {Analysis, Chess Skills, Mathematics Learning Outcomes},
  abstract      = {
    This study aims to determine the results of the analysis of chess playing skills on mathematics learning outcomes for junior athletes of the Raja Kombi Trenggalek chess club. The research method used is a qualitative descriptive method with a quantitative approach. Participants in this study were 8 junior athletes of Raja Kombi Trenggalek chess club. Data collection techniques using interviews, skills results and documentation. The data analysis in this study used the mean and percentage formula.

    After analyzing the data, the results of this study concluded that in this study, the average score of playing chess skills was 85.00, then the average score of mathematics learning outcomes was 86.25. This is of course the higher the level of achievement of skills or intellectual intelligence, the higher the level of problem solving such as in learning mathematics. This is also influenced by motor and psychological aspects as a support for intelligence skills that affect the thinking of athletes. Then from the data analysis it can be said that the higher the level of achievement of chess playing skills, the higher the level of problem solving as in learning mathematics
  },
}

@misc{siji:2025:seqret-mining-rule-sets-event-sequences,
  title         = {Seqret: Mining Rule Sets from Event Sequences},
  author        = {Aleena Siji and Joscha C\"{u}ppers and Osman Ali Mian and Jilles Vreeken},
  year          = {2025},
  url           = {https://arxiv.org/abs/2505.06049},
  eprint        = {2505.06049},
  archiveprefix = {arXiv},
  primaryclass  = {cs.AI},
}

@misc{skidanov:2025:behavior-based-knowledge-representation-improves-prediction-player-moves,
  title         = {A Behavior-Based Knowledge Representation Improves Prediction of Players' Moves in Chess by 25\%},
  author        = {Benny Skidanov and Daniel Erbesfeld and Gera Weiss and Achiya Elyasaf},
  year          = {2025},
  url           = {https://arxiv.org/abs/2504.05425},
  eprint        = {2504.05425},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG},
}

@inproceedings{soliman:2026:caissa-ai-neuro-symbolic-chess-agent-explainable-move-suggestion-grounded-commentary,
  title         = {Ca{\"i}ssa AI: A Neuro-Symbolic Chess Agent for~Explainable Move Suggestion and~Grounded Commentary},
  author        = {Soliman, Mazen and Ehab, Nourhan},
  year          = {2026},
  booktitle     = {KI 2025: Advances in Artificial Intelligence},
  publisher     = {Springer Nature Switzerland},
  address       = {Cham},
  pages         = {148--160},
  isbn          = {978-3-032-02813-6},
  editor        = {Braun, Tanya and Paa{\ss}en, Benjamin and Stolzenburg, Frieder},
  abstract      = {Despite the impressive generative capabilities of large language models (LLMs), their lack of grounded reasoning and susceptibility to hallucinations limit their reliability in structured domains such as chess. We present Ca{\"i}ssa AI, a neuro-symbolic chess agent that augments LLM-generated move commentary with symbolic reasoning, knowledge graph integration, and verification modules. Ca{\"i}ssa AI combines a fine-tuned chess-specific LLM with a Prolog-based rule engine encoding chess tactics and rules, along with a dynamically constructed Neo4j knowledge graph representing the current board state. This hybrid architecture enables the system to generate not only accurate move suggestions but also coherent, strategically grounded commentary. A LangGraph-based verification module cross-checks LLM outputs against symbolic logic to ensure consistency and correctness, effectively mitigating hallucinations. By aligning data-driven generation with formal domain knowledge, Ca{\"i}ssa AI enhances both trustworthiness and explainability. Our results demonstrate that this tight neuro-symbolic integration produces verifiable, high-quality commentary and serves as a generalizable blueprint for AI systems requiring real-time, interpretable decision support.},
  keywords      = {Neuro-Symbolic AI, Chess Agents, Explainable Reasoning},
}

@article{song:2023:investigation-sicilian-defense,
  title         = {Investigation of the Sicilian Defense: Winning rates and strategic discrimination},
  author        = {Song, Ziming},
  year          = {2023},
  journal       = {Interdisciplinary Humanities and Communication Studies},
  volume        = {1},
  number        = {4},
}

@misc{song:2025:beyond-accuracy-geometric-stability-analysis-large-language-models-chess-evaluation,
  title         = {Beyond Accuracy: A Geometric Stability Analysis of Large Language Models in Chess Evaluation},
  author        = {Xidan Song and Weiqi Wang and Ruifeng Cao and Qingya Hu},
  year          = {2025},
  url           = {https://arxiv.org/abs/2512.15033},
  eprint        = {2512.15033},
  archiveprefix = {arXiv},
  primaryclass  = {cs.AI},
  keywords      = {Large Language Models, Geometric Stability, Chess Evaluation, Robustness Analysis, AI Reasoning, Evaluation Metrics},
  abstract      = {The evaluation of Large Language Models (LLMs) in complex reasoning domains typically relies on performance alignment with ground-truth oracles. In the domain of chess, this standard manifests as accuracy benchmarks against strong engines like Stockfish. However, high scalar accuracy does not necessarily imply robust conceptual understanding. This paper argues that standard accuracy metrics fail to distinguish between genuine geometric reasoning and the superficial memorization of canonical board states. To address this gap, we propose a Geometric Stability Framework, a novel evaluation methodology that rigorously tests model consistency under invariant transformations-including board rotation, mirror symmetry, color inversion, and format conversion. We applied this framework to a comparative analysis of six state-of-the-art LLMs including GPT-5.1, Claude Sonnet 4.5, and Kimi K2 Turbo, utilizing a dataset of approximately 3,000 positions. Our results reveal a significant Accuracy-Stability Paradox. While models such as GPT-5.1 achieve near-optimal accuracy on standard positions, they exhibit catastrophic degradation under geometric perturbation, specifically in rotation tasks where error rates surge by over 600\%. This disparity suggests a reliance on pattern matching over abstract spatial logic. Conversely, Claude Sonnet 4.5 and Kimi K2 Turbo demonstrate superior dual robustness, maintaining high consistency across all transformation axes. Furthermore, we analyze the trade-off between helpfulness and safety, identifying Gemini 2.5 Flash as the leader in illegal state rejection (96.0\%). We conclude that geometric stability provides an orthogonal and essential metric for AI evaluation, offering a necessary proxy for disentangling reasoning capabilities from data contamination and overfitting in large-scale models.},
}

@inproceedings{spinnato:2025:towards-piece-by-piece-explanations-chess-positions-shap,
  title         = {Towards Piece-by-Piece Explanations for Chess Positions with {SHAP}},
  author        = {Spinnato, Francesco},
  year          = {2025},
  booktitle     = {Proceedings of AI4HGI 2025, the First Workshop on Artificial Intelligence for Human-Game Interaction at the 28th European Conference on Artificial Intelligence (ECAI 2025)},
  url           = {https://ai4hgi.github.io/paper13.pdf},
  github        = {https://github.com/fspinna/chessplainer},
  abstract      = {Contemporary chess engines offer precise yet opaque evaluations, typically expressed as centipawn scores. While effective for decision-making, these outputs obscure the underlying contributions of individual pieces or patterns. In this paper, we explore adapting SHAP (SHapley Additive exPlanations) to the domain of chess analysis, aiming to attribute a chess engines evaluation to specific pieces on the board. By treating pieces as features and systematically ablating them, we compute additive, per-piece contributions that explain the engines output in a locally faithful and human-interpretable manner. This method draws inspiration from classical chess pedagogy, where players assess positions by mentally removing pieces, and grounds it in modern explainable AI techniques. Our approach opens new possibilities for visualization, human training, and engine comparison. We release accompanying code and data to foster future research in interpretable chess AI.},
  keywords      = {chess, explainable AI, shap},
}

@misc{stanek:2024:bad-crypto-chessography-weak-randomness-chess-games,
  title         = {Bad Crypto: Chessography and Weak Randomness of Chess Games},
  author        = {Martin Stanek},
  year          = {2024},
  url           = {https://arxiv.org/abs/2412.09742},
  eprint        = {2412.09742},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CR},
}

@inproceedings{stockl:2021:watching-language-model-learning-chess,
  title         = {Watching a Language Model Learning Chess},
  author        = {St{\"o}ckl, Andreas},
  year          = {2021},
  month         = sep,
  booktitle     = {Proceedings of the International Conference on Recent Advances in Natural Language Processing (RANLP 2021)},
  publisher     = {INCOMA Ltd.},
  address       = {Held Online},
  pages         = {1369--1379},
  url           = {https://aclanthology.org/2021.ranlp-1.153},
  editor        = {Mitkov, Ruslan  and Angelova, Galia},
  abstract      = {We analyse how a transformer-based language model learns the rules of chess from text data of recorded games. We show how it is possible to investigate how the model capacity and the available number of training data influence the learning success of a language model with the help of chess-specific metrics. With these metrics, we show that more games used for training in the studied range offers significantly better results for the same training time. However, model size does not show such a clear influence. It is also interesting to observe that the usual evaluation metrics for language models, predictive accuracy and perplexity, give no indication of this here. Further examination of trained models reveals how they store information about board state in the activations of neuron groups, and how the overall sequence of previous moves influences the newly-generated moves.},
}

@inproceedings{tang:2024:maia-2-unified-model-human-ai-alignment-chess,
  title         = {Maia-2: a unified model for human-AI alignment in chess},
  author        = {Tang, Zhenwei and Jiao, Difan and McIlroy-Young, Reid and Kleinberg, Jon and Sen, Siddhartha and Anderson, Ashton},
  year          = {2025},
  booktitle     = {Proceedings of the 38th International Conference on Neural Information Processing Systems},
  location      = {Vancouver, BC, Canada},
  publisher     = {Curran Associates Inc.},
  address       = {Red Hook, NY, USA},
  series        = {NeurIPS '24},
  isbn          = {9798331314385},
  abstract      = {There are an increasing number of domains in which artificial intelligence (AI) systems both surpass human ability and accurately model human behavior. This introduces the possibility of algorithmically-informed teaching in these domains through more relatable AI partners and deeper insights into human decision-making. Critical to achieving this goal, however, is coherently modeling human behavior at various skill levels. Chess is an ideal model system for conducting research into this kind of human-AI alignment, with its rich history as a pivotal testbed for AI research, mature superhuman AI systems like AlphaZero, and precise measurements of skill via chess rating systems. Previous work in modeling human decision-making in chess uses completely independent models to capture human style at different skill levels, meaning they lack coherence in their ability to adapt to the full spectrum of human improvement and are ultimately limited in their effectiveness as AI partners and teaching tools. In this work, we propose a unified modeling approach for human-AI alignment in chess that coherently captures human style across different skill levels and directly captures how people improve. Recognizing the complex, non-linear nature of human learning, we introduce a skill-aware attention mechanism to dynamically integrate players' strengths with encoded chess positions, enabling our model to be sensitive to evolving player skill. Our experimental results demonstrate that this unified framework significantly enhances the alignment between AI and human players across a diverse range of expertise levels, paving the way for deeper insights into human decision-making and AI-guided teaching tools. Our implementation is available https://github.com/CSSLab/maia2.},
  articleno     = {659},
  numpages      = {26},
  github        = {https://github.com/CSSLab/maia2},
  keywords      = {Human-AI Alignment, Action Prediction, Chess, Skill-aware Attention},
}

@misc{tang:2025:is-elo-rating-reliable-study-under-model-misspecification,
  title         = {Is Elo Rating Reliable? A Study Under Model Misspecification},
  author        = {Shange Tang and Yuanhao Wang and Chi Jin},
  year          = {2025},
  url           = {https://arxiv.org/abs/2502.10985},
  eprint        = {2502.10985},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG},
}

@inproceedings{tang:2025:seam-semantically-equivalent-modalities-benchmark-vlm-vision-language-models,
  title         = {{SEAM}: Semantically Equivalent Across Modalities Benchmark for Vision-Language Models},
  author        = {Zhenwei Tang and Difan Jiao and Blair Yang and Ashton Anderson},
  year          = {2025},
  booktitle     = {Second Conference on Language Modeling},
  url           = {https://openreview.net/forum?id=lI4LgGv4sX},
  abstract      = {Evaluating whether vision-language models (VLMs) reason consistently across representations is challenging because modality comparisons are typically confounded by task differences and asymmetric information. We introduce SEAM, a benchmark that pairs semantically equivalent inputs across four domains that have existing standardized textual and visual notations. By employing distinct notation systems across modalities, in contrast to OCR-based image-text pairing, SEAM provides a rigorous comparative assessment of the textual-symbolic and visual-spatial reasoning capabilities of VLMs. Across 21 contemporary models, we observe systematic modality imbalance: vision frequently lags language in overall performance, despite the problems containing semantically equivalent information, and cross-modal agreement is relatively low. Our error analysis reveals two main drivers: textual perception failures from tokenization in domain notation and visual perception failures that induce hallucinations. We also show that our results are largely robust to visual transformations. SEAM establishes a controlled, semantically equivalent setting for measuring and improving modality-agnostic reasoning.},
  github        = {https://github.com/CSSLab/SEAM},
  huggingface   = {https://huggingface.co/datasets/lilvjosephtang/SEAM-Benchmark},
  annote        = {https://lilv98.github.io/SEAM-Website/},
}

@inproceedings{tay:2023:social-status-competitors-cause-decision-maker-errors,
  title         = {Can higher social status of competitors cause decision makers to commit more errors?},
  author        = {Tay, Li Qian},
  year          = {2023},
  booktitle     = {Proceedings of the Annual Meeting of the Cognitive Science Society},
  volume        = {45},
  url           = {https://escholarship.org/uc/item/85d620jz},
}

@inproceedings{tijhuis:2023:predicting-chess-rating-single-game,
  title         = {Predicting Chess Player Rating Based on a Single Game},
  author        = {Tim Tijhuis and Paris Mavromoustakos Blom and Pieter Spronck},
  year          = {2023},
  booktitle     = {{IEEE} Conference on Games, CoG 2023, Boston, MA, USA, August 21-24, 2023},
  publisher     = {{IEEE}},
  pages         = {1--8},
  doi           = {10.1109/COG57401.2023.10333133},
  url           = {https://doi.org/10.1109/CoG57401.2023.10333133},
}

@book{urcan:2025:east-meets-east-inside-2024-world-chess-championship-singapore,
  title         = {East Meets East: Inside The 2024 World Chess Championship In Singapore},
  author        = {Urcan, Olimpiu G},
  year          = {2025},
  publisher     = {World Scientific Publishing Company},
  doi           = {10.1142/14303},
  isbn          = {9789819812820},
  url           = {https://www.worldscientific.com/worldscibooks/10.1142/14303},
  abstract      = {This book presents a compelling account of the historic FIDE world chess championship match between Ding Liren of China and Gukesh Dommaraju of India, held in Singapore from November 25 to December 13, 2024. Sponsored by Google, the 14-game match marked several significant milestones: the first All-Asian world chess championship, the first to be hosted in Singapore, and the momentous crowning of the youngest undisputed world chess champion in history. Through detailed reports, in-depth analyses of each game, and a curated collection of over a hundred quality photographs, the book explores the players' remarkable journeys, offering insights into their distinct playing styles, rigorous preparation, and the psychological challenges they faced both on and off the board. Set against the dynamic cultural backdrop of Singapore, it also examines the growing prominence of Asia in the world of chess. Combining strategic depth, expert commentary, and behind-the-scenes perspectives, this work provides an engaging narrative of resilience, rivalry, and excellence, making it an indispensable read for chess enthusiasts and sports aficionados.},
}

@misc{veeriah:2025:evaluating-silico-creativity-expert-review-ai-chess-competitions,
  title         = {Evaluating In Silico Creativity: An Expert Review of AI Chess Compositions},
  author        = {Vivek Veeriah and Federico Barbero and Marcus Chiam and Xidong Feng and Michael Dennis and Ryan Pachauri and Thomas Tumiel and Johan Obando-Ceron and Jiaxin Shi and Shaobo Hou and Satinder Singh and Nenad Toma\v{s}ev and Tom Zahavy},
  year          = {2025},
  url           = {https://arxiv.org/abs/2510.23772},
  eprint        = {2510.23772},
  archiveprefix = {arXiv},
  primaryclass  = {cs.AI},
  abstract      = {The rapid advancement of Generative AI has raised significant questions regarding its ability to produce creative and novel outputs. Our recent work investigates this question within the domain of chess puzzles and presents an AI system designed to generate puzzles characterized by aesthetic appeal, novelty, counter-intuitive and unique solutions. We briefly discuss our method below and refer the reader to the technical paper for more details. To assess our system's creativity, we presented a curated booklet of AI-generated puzzles to three world-renowned experts: International Master for chess compositions Amatzia Avni, Grandmaster Jonathan Levitt, and Grandmaster Matthew Sadler. All three are noted authors on chess aesthetics and the evolving role of computers in the game. They were asked to select their favorites and explain what made them appealing, considering qualities such as their creativity, level of challenge, or aesthetic design.},
}

@thesis{vikstrom:2019:convolutional-neural-network-cnn-evaluate-chess-positions,
  title         = {Training a Convolutional Neural Network to Evaluate Chess Positions},
  author        = {Vikstr{\"o}m, Joel},
  year          = {2019},
  series        = {TRITA-EECS-EX},
  number        = {2019:377},
  pages         = {18},
  type          = {Bachelor's thesis},
  supervisor    = {Markidis, Stefano},
  school        = {KTH, School of Electrical Engineering and Computer Science (EECS)},
  abstract      = {Convolutional neural networks are typically applied to image analysis problems. We investigate whether a simple convolutional neural network can be trained to evaluate chess positions by means of predicting Stockfish (an existing chess engine) evaluations. Publicly available data from lichess.org was used, and we obtained a final MSE of 863.48 and MAE of 12.18 on our test dataset (with labels ranging from -255 to +255). To accomplish better results, we conclude that a more capable model architecture must be used.},
}

@inproceedings{wang:2025:explore-reasoning-capability-llms-chess-testbed,
  title         = {Explore the Reasoning Capability of {LLM}s in the Chess Testbed},
  author        = {Wang, Shu  and Ji, Lei  and Wang, Renxi  and Zhao, Wenxiao  and Liu, Haokun  and Hou, Yifan  and Wu, Ying Nian},
  year          = {2025},
  month         = apr,
  booktitle     = {Proceedings of the 2025 Conference of the Nations of the Americas Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 2: Short Papers)},
  publisher     = {Association for Computational Linguistics},
  address       = {Albuquerque, New Mexico},
  pages         = {611--622},
  doi           = {10.18653/v1/2025.naacl-short.52},
  isbn          = {979-8-89176-190-2},
  url           = {https://aclanthology.org/2025.naacl-short.52/},
  editor        = {Chiruzzo, Luis  and Ritter, Alan  and Wang, Lu},
  website       = {https://mate-chess.github.io/},
  huggingface   = {https://huggingface.co/OutFlankShu/MATE},
  dataset       = {https://huggingface.co/datasets/OutFlankShu/MATE\_NAACL2025\_Explore-the-Reasoning-Capability-of-LLMs-in-the-Chess-Testbed},
  abstract      = {Reasoning is a central capability of human intelligence. In recent years, with the advent of large-scale datasets, pretrained large language models have emerged with new capabilities, including reasoning. However, these models still struggle with long-term, complex reasoning tasks, such as playing chess. Based on the observation that expert chess players employ a dual approach combining long-term strategic play with short-term tactical play along with language explanation, we propose improving the reasoning capability of large language models in chess by integrating annotated strategy and tactic. Specifically, we collect a dataset named MATE, which consists of 1 million chess positions with candidate moves annotated for strategy and tactics. We finetune the LLaMA-3-8B model and compare it against state-of-the-art commercial language models in the task of selecting better chess moves. Our experiments show that our models perform better than GPT, Claude, and Gemini models. We find that language explanations can enhance the reasoning capability of large language models.},
}

@inproceedings{weissenberger:2025:massively-parallel-inverse-block-sorting-transforms-bzip2-decompression-gpu,
  title         = {Massively Parallel Inverse Block-sorting Transforms for bzip2 Decompression on GPUs},
  author        = {Wei{\ss}enberger, Andr{\'e} and Schmidt, Bertil},
  year          = {2024},
  booktitle     = {Proceedings of the 53rd International Conference on Parallel Processing},
  location      = {Gotland, Sweden},
  publisher     = {Association for Computing Machinery},
  address       = {New York, NY, USA},
  series        = {ICPP '24},
  pages         = {856–865},
  doi           = {10.1145/3673038.3673067},
  isbn          = {9798400717932},
  url           = {https://doi.org/10.1145/3673038.3673067},
  abstract      = {Lossless data compression has evolved into an indispensable tool for reducing data transfer times in heterogeneous systems. However, performing decompression on host systems can create performance bottlenecks. Accelerator libraries, such as nvCOMP, address this problem by providing custom GPU-enabled versions of some general-purpose compression methods, including Snappy, ZStandard and gzip. However, popular bzip-like compression schemes, which rely on block-sorting transforms have not yet been integrated since their fine-grained parallelization is challenging. With a focus on decompression, we propose novel techniques for fine-grained parallelization of inverse Burrows-Wheeler transform (iBWT) and inverse Move-to-Front (iMTF) transform on GPUs, which enable efficient processing of bzip2-based archives on CUDA-enabled accelerators for the first time. Consequently, we present the first fully GPU-enabled bzip2 decompression pipeline as a use case for the proposed algorithms. Our experimental results reveal speedups of up to 6.1x over a multicore CPU implementation for iBWT, and throughput rates of up to 2400 MB/s for combined iBWT and iMTF on an A100 GPU. For decompression of bzip2 archives, a throughput of over 11.62 GB/s is achieved on a DGX H100 server. The source code of our parallel decoder implementation is available at https://github.com/weissenberger/bzip2gpu.},
  numpages      = {10},
  keywords      = {Burrows-Wheeler transform, CUDA, GPU, Move-to-front transform, accelerators, bzip2, data compression},
}

@misc{wen:2025:chessqa-evaluating-large-language-models-chess-understanding,
  title         = {ChessQA: Evaluating Large Language Models for Chess Understanding},
  author        = {Qianfeng Wen and Zhenwei Tang and Ashton Anderson},
  year          = {2025},
  url           = {https://arxiv.org/abs/2510.23948},
  note          = {submitted here: https://openreview.net/forum?id=gBz9NMbvYS},
  eprint        = {2510.23948},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG},
  abstract      = {Chess provides an ideal testbed for evaluating the reasoning, modeling, and abstraction capabilities of large language models (LLMs), as it has well-defined structure and objective ground truth while admitting a wide spectrum of skill levels. However, existing evaluations of LLM ability in chess are ad hoc and narrow in scope, making it difficult to accurately measure LLM chess understanding and how it varies with scale, post-training methodologies, or architecture choices. We present ChessQA, a comprehensive benchmark that assesses LLM chess understanding across five task categories (Structural, Motifs, Short Tactics, Position Judgment, and Semantic), which approximately correspond to the ascending abstractions that players master as they accumulate chess knowledge, from understanding basic rules and learning tactical motifs to correctly calculating tactics, evaluating positions, and semantically describing high-level concepts. In this way, ChessQA captures a more comprehensive picture of chess ability and understanding, going significantly beyond the simple move quality evaluations done previously, and offers a controlled, consistent setting for diagnosis and comparison. Furthermore, ChessQA is inherently dynamic, with prompts, answer keys, and construction scripts that can evolve as models improve. Evaluating a range of contemporary LLMs, we find persistent weaknesses across all five categories and provide results and error analyses by category. We will release the code, periodically refreshed datasets, and a public leaderboard to support further research.},
  dataset       = {https://huggingface.co/datasets/wieeii/ChessQA-Benchmark},
}

@inproceedings{wieczerzak:2022:dataset-experimental-investigation-chess-position-evaluation-neural-network,
  title         = {Dataset Related Experimental Investigation of Chess Position Evaluation Using a Deep Neural Network},
  author        = {Dawid Wieczerzak and Pawel Czarnul},
  year          = {2022},
  booktitle     = {Parallel Processing and Applied Mathematics - 14th International Conference, {PPAM} 2022, Gdansk, Poland, September 11-14, 2022, Revised Selected Papers, Part {I}},
  publisher     = {Springer},
  series        = {Lecture Notes in Computer Science},
  volume        = {13826},
  pages         = {429--440},
  doi           = {10.1007/978-3-031-30442-2\_32},
  url           = {https://doi.org/10.1007/978-3-031-30442-2\_32},
  editor        = {Roman Wyrzykowski and Jack J. Dongarra and Ewa Deelman and Konrad Karczewski},
}

@inproceedings{woodruff:2024:predicting-chess-puzzle-difficulty,
  title         = {{The bread emoji Team's Submission to the IEEE BigData 2024 Cup: Predicting Chess Puzzle Difficulty Challenge}},
  author        = {Tyler Woodruff and Oleg Filatov and Marco Cognetta},
  year          = {2024},
  booktitle     = {{IEEE} International Conference on Big Data, Big Data 2024, Washington DC, USA, December 15-18, 2024},
  publisher     = {{IEEE}},
}

@inproceedings{xiao:2025:multi-source-feature-fusion-neural-embedding-predicting-chess-puzzle-difficulty,
  title         = {Multi-Source Feature Fusion and Neural Embedding for Predicting Chess Puzzle Difficulty},
  author        = {Haitao Xiao and Daiyuan Yu and Xuegang Wen and Le Chen and Kun Fu},
  year          = {2025},
  booktitle     = {Proceedings of the 20th Conference on Computer Science and Intelligence Systems (FedCSIS)},
  publisher     = {IEEE},
  series        = {Annals of Computer Science and Information Systems},
  volume        = {43},
  pages         = {843--848},
  doi           = {10.15439/2025F2456},
  url           = {http://dx.doi.org/10.15439/2025F2456},
  editor        = {Marek Bolanowski and Maria Ganzha and Leszek Maciaszek and Marcin Paprzycki and Dominik \'{S}l\k{e}zak},
  abstract      = {Estimating the difficulty of chess puzzles provides a rich testbed for studying human–computer interaction and adaptive learning. Building on recent advances and the FedCSIS 2025 Challenge, we address the task of predicting chess puzzle difficulty ratings using a multi-source representation approach. Our approach integrates pre-trained neural embeddings of board states, solution move sequences, and engine-derived success probabilities. These heterogeneous features are fused via dedicated embedding and projection layers, followed by a multi-layer perceptron regressor. Post-processing calibration and model ensemble further enhance robustness and generalization. Experiments on the FedCSIS 2025 dataset demonstrate that our method effectively leverages both structural and empirical information, achieving strong predictive performance. Our approach achieved fifth place on the final official leaderboard, highlighting the effectiveness of combining neural representations with domain-specific probabilistic features for robust chess puzzle difficulty prediction.},
}

@inproceedings{yamada:2023:estimating-online-ratings-decision-tree,
  title         = {A Method for Estimating Online Chess Game Player Ratings with Decision Tree},
  author        = {Habuki Yamada and Nobuko Kishi and Masato Oguchi and Miyuki Nakano},
  year          = {2023},
  booktitle     = {{IEEE} International Conference on Big Data and Smart Computing, BigComp 2023, Jeju, Republic of Korea, February 13-16, 2023},
  publisher     = {{IEEE}},
  pages         = {320--321},
  doi           = {10.1109/BIGCOMP57234.2023.00066},
  url           = {https://doi.org/10.1109/BigComp57234.2023.00066},
  editor        = {Hyeran Byun and Beng Chin Ooi and Katsumi Tanaka and Sang{-}Won Lee and Zhixu Li and Akiyo Nadamoto and Giltae Song and Young{-}Guk Ha and Kazutoshi Sumiya and Yuncheng Wu and Hyuk{-}Yoon Kwon and Takehiro Yamamoto},
}

@misc{yang:2025:mixture-experts-intrinsically-interpretable,
  title         = {Mixture of Experts Made Intrinsically Interpretable},
  author        = {Xingyi Yang and Constantin Venhoff and Ashkan Khakzar and Christian Schroeder de Witt and Puneet K. Dokania and Adel Bibi and Philip Torr},
  year          = {2025},
  url           = {https://arxiv.org/abs/2503.07639},
  eprint        = {2503.07639},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG},
}

@inproceedings{ye:2025:implicit-search-discrete-diffusion-study-chess,
  title         = {Implicit Search via Discrete Diffusion: {A} Study on Chess},
  author        = {Jiacheng Ye and Zhenyu Wu and Jiahui Gao and Zhiyong Wu and Xin Jiang and Zhenguo Li and Lingpeng Kong},
  year          = {2025},
  booktitle     = {The Thirteenth International Conference on Learning Representations, {ICLR} 2025, Singapore, April 24-28, 2025},
  publisher     = {OpenReview.net},
  url           = {https://openreview.net/forum?id=A9y3LFX4ds},
  abstract      = {In the post-AlphaGo era, there has been a renewed interest in search techniques such as Monte Carlo Tree Search (MCTS), particularly in their application to Large Language Models (LLMs). This renewed attention is driven by the recognition that current next-token prediction models often lack the ability for long-term planning. Is it possible to instill search-like abilities within the models to enhance their planning abilities without relying on explicit search? We propose DiffuSearch , a model that does \textit{implicit search} by looking into the future world via discrete diffusion modeling. We instantiate DiffuSearch on a classical board game, Chess, where explicit search is known to be essential. Through extensive controlled experiments, we show DiffuSearch outperforms both the searchless and explicit search-enhanced policies. Specifically, DiffuSearch outperforms the one-step policy by 19.2\% and the MCTS-enhanced policy by 14\% on action accuracy. Furthermore, DiffuSearch demonstrates a notable 30\% enhancement in puzzle-solving abilities compared to explicit search-based policies, along with a significant 540 Elo increase in game-playing strength assessment. These results indicate that implicit search via discrete diffusion is a viable alternative to explicit search over a one-step policy. All codes are publicly available at \href{https://github.com/HKUNLP/DiffuSearch}{https://github.com/HKUNLP/DiffuSearch}},
  tldr          = {We propose a model that does implicit search by looking into the future world via discrete diffusion modeling.},
  keywords      = {discrete diffusion model, search, planning, chess, MCTS},
  github        = {https://github.com/HKUNLP/DiffuSearch},
  huggingface   = {https://huggingface.co/datasets/jiacheng-ye/chess10k},
}

@inproceedings{yohanes:2024:chess-piece-image-recognition-nn-cnn,
  title         = {Chess Piece Image Recognition Using Transfer Learning, Simple Neural Network, and Convolutional Neural Network},
  author        = {Yohanes, Gabriel and Nursalim, Mario and Nicholas and Kurniadi, Felix Indra},
  year          = {2023},
  booktitle     = {2023 4th International Conference on Artificial Intelligence and Data Sciences (AiDAS)},
  pages         = {160--164},
  doi           = {10.1109/AiDAS60501.2023.10284718},
  keywords      = {Training;Image recognition;Computational modeling;Transfer learning;Neural networks;Software;Real-time systems;Chess Pieces;CNN;Transfer Learning;Simple Neural Network;Image Recognition},
}

@misc{yu:2025:biological-processing-units-leveraging-insect-connectome-pioneer-biofidelic-neural-architectures,
  title         = {Biological Processing Units: Leveraging an Insect Connectome to Pioneer Biofidelic Neural Architectures},
  author        = {Siyu Yu and Zihan Qin and Tingshan Liu and Beiya Xu and R. Jacob Vogelstein and Jason Brown and Joshua T. Vogelstein},
  year          = {2025},
  url           = {https://arxiv.org/abs/2507.10951},
  eprint        = {2507.10951},
  archiveprefix = {arXiv},
  primaryclass  = {cs.NE},
}

@article{zahavy:2023:diversifying-ai-towards-creative-chess-alphazero,
  title         = {Diversifying {AI:} Towards Creative Chess with AlphaZero},
  author        = {Tom Zahavy and Vivek Veeriah and Shaobo Hou and Kevin Waugh and Matthew Lai and Edouard Leurent and Nenad Tomasev and Lisa Schut and Demis Hassabis and Satinder Singh},
  year          = {2023},
  journal       = {CoRR},
  volume        = {abs/2308.09175},
  doi           = {10.48550/ARXIV.2308.09175},
  url           = {https://doi.org/10.48550/arXiv.2308.09175},
  eprinttype    = {arXiv},
  abstract      = {In recent years, Artificial Intelligence (AI) systems have surpassed human intelligence in a variety of computational tasks. However, AI systems, like humans, make mistakes, have blind spots, hallucinate, and struggle to generalize to new situations. This work explores whether AI can benefit from creative decision-making mechanisms when pushed to the limits of its computational rationality. In particular, we investigate whether a team of diverse AI systems can outperform a single AI in challenging tasks by generating more ideas as a group and then selecting the best ones. We study this question in the game of chess, the so-called drosophila of AI. We build on AlphaZero (AZ) and extend it to represent a league of agents via a latent-conditioned architecture, which we call AZ\_db. We train AZ\_db to generate a wider range of ideas using behavioral diversity techniques and select the most promising ones with sub-additive planning. Our experiments suggest that AZ\_db plays chess in diverse ways, solves more puzzles as a group and outperforms a more homogeneous team. Notably, AZ\_db solves twice as many challenging puzzles as AZ, including the challenging Penrose positions. When playing chess from different openings, we notice that players in AZ\_db specialize in different openings, and that selecting a player for each opening using sub-additive planning results in a 50 Elo improvement over AZ. Our findings suggest that diversity bonuses emerge in teams of AI agents, just as they do in teams of humans and that diversity is a valuable asset in solving computationally hard problems.},
  eprint        = {2308.09175},
}

@article{zaidi:2024:predicting-user-perception-move-brilliance-chess,
  title         = {Predicting User Perception of Move Brilliance in Chess},
  author        = {Kamron Zaidi and Michael Guerzhoy},
  year          = {2024},
  journal       = {CoRR},
  volume        = {abs/2406.11895},
  doi           = {10.48550/ARXIV.2406.11895},
  url           = {https://doi.org/10.48550/arXiv.2406.11895},
  eprinttype    = {arXiv},
  eprint        = {2406.11895},
}

@thesis{zelek:2022:topological-data-analysis-chess,
  title         = {Topological Data Analysis in chess},
  author        = {Zelek, Jakub},
  year          = {2022},
  note          = {https://ruj.uj.edu.pl/xmlui/handle/item/295689},
  school        = {Jagiellonian University},
  type          = {Master's thesis},
  keywords      = {Chess, Topological Data Analysis, Design Patterns, Data modeling, Modules, Category theory, Topology},
  annote        = {This thesis uses Topological Data Analysis to examine the data collectedfrom the lichess.org portal. The analysis was based on the games of players playing at different levels. The purpose of the analysis was to distinguish groups of players and players with the highest ranking from eachother. Each player's game is represented by a multidimensional vectorthat encodes information about the course of the game. There are threeapproaches to creating this vector, allowing us to focus on different aspects of the chess game. The proposed analysis was carried out with theintention of verifying the Topological Data Analysis as a tool for analyzing chess games. As a result, it was shown that Topological Data Analysiscan be a potential tool for recognizing the quality of a given player, if wehave enough number of his games, and to reconstruct player rankings. Asignificant result is also the potential for further research for which this thesis could be the foundation.},
}

@inproceedings{zhang:2024:transcendence-generative-models-can-outperform-experts-that-train-them,
  title         = {Transcendence: Generative Models Can Outperform The Experts That Train Them},
  author        = {Edwin Zhang and Vincent Zhu and Naomi Saphra and Anat Kleiman and Benjamin L. Edelman and Milind Tambe and Sham M. Kakade and Eran Malach},
  year          = {2024},
  booktitle     = {Advances in Neural Information Processing Systems 38: Annual Conference on Neural Information Processing Systems 2024, NeurIPS 2024, Vancouver, BC, Canada, December 10 - 15, 2024},
  url           = {http://papers.neurips.cc/paper\_files/paper/2024/hash/9e3bba153aa362f961dc43de5cababac-Abstract-Conference.html},
  editor        = {Amir Globersons and Lester Mackey and Danielle Belgrave and Angela Fan and Ulrich Paquet and Jakub M. Tomczak and Cheng Zhang},
  keywords      = {theory, foundations, generative modelling, sequence modelling},
  tldr          = {We theoretically and empirically demonstrate that generative models can outperform the experts that train them by low-temperature sampling},
  github        = {https://github.com/KempnerInstitute/chess-research},
  dataset       = {https://github.com/KempnerInstitute/chess-data},
  huggingface   = {https://huggingface.co/datasets/ezipe/lichess-models/},
  abstract      = {Generative models are trained with the simple objective of imitating the conditional probability distribution induced by the data they are trained on. Therefore, when trained on data generated by humans, we may not expect the artificial model to outperform the humans on their original objectives. In this work, we study the phenomenon of transcendence: when a generative model achieves capabilities that surpass the abilities of the experts generating its data. We demonstrate transcendence by training an autoregressive transformer to play chess from game transcripts, and show that the trained model can sometimes achieve better performance than all players in the dataset. We theoretically prove that transcendence can be enabled by low-temperature sampling, and rigorously assess this claim experimentally. Finally, we discuss other sources of transcendence, laying the groundwork for future investigation of this phenomenon in a broader setting.},
  website       = {https://transcendence.eddie.win/},
}

@misc{zhang:2025:general-search-techniques-common-knowledge-imperfect-information-games-fog-of-war-chess,
  title         = {General search techniques without common knowledge for imperfect-information games, and application to superhuman Fog of War chess},
  author        = {Brian Hu Zhang and Tuomas Sandholm},
  year          = {2025},
  url           = {https://arxiv.org/abs/2506.01242},
  eprint        = {2506.01242},
  archiveprefix = {arXiv},
  primaryclass  = {cs.GT},
}

@inproceedings{zhang:2025:human-aligned-chess-bit-of-search,
  title         = {Human-Aligned Chess With a Bit of Search},
  author        = {Yiming Zhang and Athul Paul Jacob and Vivian Lai and Daniel Fried and Daphne Ippolito},
  year          = {2025},
  booktitle     = {The Thirteenth International Conference on Learning Representations, {ICLR} 2025, Singapore, April 24-28, 2025},
  publisher     = {OpenReview.net},
  url           = {https://openreview.net/forum?id=bc2H72hGxB},
  abstract      = {Chess has long been a testbed for AI's quest to match human intelligence, and in recent years, chess AI systems have surpassed the strongest humans at the game. However, these systems are not human-aligned; they are unable to match the skill levels of all human partners or model human-like behaviors beyond piece movement. In this paper, we introduce Allie, a chess-playing AI designed to bridge the gap between artificial and human intelligence in this classic game. Allie is trained on log sequences of real chess games to model the behaviors of human chess players across the skill spectrum, including non-move behaviors such as pondering times and resignations In offline evaluations, we find that Allie exhibits humanlike behavior: it outperforms the existing state-of-the-art in human chess move prediction and ponders at critical positions. The model learns to reliably assign reward at each game state, which can be used at inference as a reward function in a novel time-adaptive Monte-Carlo tree search (MCTS) procedure, where the amount of search depends on how long humans would think in the same positions. Adaptive search enables remarkable skill calibration; in a large-scale online evaluation against players with ratings from 1000 to 2600 Elo, our adaptive search method leads to a skill gap of only 49 Elo on average, substantially outperforming search-free and standard MCTS baselines. Against grandmaster-level (2500 Elo) opponents, Allie with adaptive search exhibits the strength of a fellow grandmaster, all while learning exclusively from humans.},
  keywords      = {chess, alignment, adaptive MCTS, inference-time scaling},
}

@misc{zhong:2025:predicting-human-chess-moves-ai-assisted-analysis-chess-games-skill-group-specific-ngram-language-models,
  title         = {Predicting Human Chess Moves: An AI Assisted Analysis of Chess Games Using Skill-group Specific n-gram Language Models},
  author        = {Daren Zhong and Dingcheng Huang and Clayton Greenberg},
  year          = {2025},
  url           = {https://arxiv.org/abs/2512.01880},
  eprint        = {2512.01880},
  archiveprefix = {arXiv},
  primaryclass  = {cs.AI},
  abstract      = {Chess, a deterministic game with perfect information, has long served as a benchmark for studying strategic decision-making and artificial intelligence. Traditional chess engines or tools for analysis primarily focus on calculating optimal moves, often neglecting the variability inherent in human chess playing, particularly across different skill levels. To overcome this limitation, we propose a novel and computationally efficient move prediction framework that approaches chess move prediction as a behavioral analysis task. The framework employs n-gram language models to capture move patterns characteristic of specific player skill levels. By dividing players into seven distinct skill groups, from novice to expert, we trained separate models using data from the open-source chess platform Lichess. The framework dynamically selects the most suitable model for prediction tasks and generates player moves based on preceding sequences. Evaluation on real-world game data demonstrates that the model selector module within the framework can classify skill levels with an accuracy of up to 31.7\% when utilizing early game information (16 half-moves). The move prediction framework also shows substantial accuracy improvements, with our Selector Assisted Accuracy being up to 39.1\% more accurate than our benchmark accuracy. The computational efficiency of the framework further enhances its suitability for real-time chess analysis.},
}

@inproceedings{zysko:2024:predicting-chess-puzzle-difficulty,
  title         = {{IEEE Big Data Cup 2024 Report: Predicting Chess Puzzle Difficulty at KnowledgePit.ai}},
  author        = {Jan Zy\'sko and Maciej \'Swiechowski and Sebastian Stawicki and Katarzyna Jagie{\l}a and Andrzej Janusz and  Dominik \'{S}l\k{e}zak},
  year          = {2024},
  booktitle     = {{IEEE} International Conference on Big Data, Big Data 2024, Washington DC, USA, December 15-18, 2024},
  publisher     = {{IEEE}},
}

@inproceedings{zysko:2025:fedcis-2025-competition-predicting-chess-puzzle-difficulty-part-2-step-toward-uncertainty-contests,
  title         = {FedCSIS 2025 knowledgepit.ai Competition: Predicting Chess Puzzle Difficulty Part 2 \& A Step Toward Uncertainty Contests},
  author        = {Jan Zy\'{s}ko and Micha\l{} \'{S}l\k{e}zak and Dominik \'{S}l\k{e}zak and Maciej \'{S}wiechowski},
  year          = {2025},
  booktitle     = {Proceedings of the 20th Conference on Computer Science and Intelligence Systems (FedCSIS)},
  publisher     = {IEEE},
  series        = {Annals of Computer Science and Information Systems},
  volume        = {43},
  pages         = {849--854},
  doi           = {10.15439/2025F5937},
  url           = {http://dx.doi.org/10.15439/2025F5937},
  editor        = {Marek Bolanowski and Maria Ganzha and Leszek Maciaszek and Marcin Paprzycki and Dominik \'{S}l\k{e}zak},
  abstract      = {We summarize the results of the FedCSIS 2025 machine learning competition organized on the knowledgepit.ai platform. We recall the competition's goals corresponding to estimations of the chess puzzle difficulty levels, we refer to the winning solutions, and we also compare the scope of this year's competition (and particularly the data available to competition participants) with its previous edition associated with the IEEE BigData 2024 conference. Finally, we discuss the new functionality of the knowledgepit.ai platform, which enables competition participants to submit additional "uncertainty masks" reflecting their assessment of test cases that are mostly problematic for their machine learning models.},
}
